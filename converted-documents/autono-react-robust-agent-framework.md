---
title: "Autono ReAct Robust Agent Framework"
original_file: "./Autono_ReAct_Robust_Agent_Framework.pdf"
document_type: "research"
conversion_date: "2025-11-29"
topics: ["prompt-engineering", "llm", "rag", "chain-of-thought", "react"]
keywords: ["agent", "task", "tasks", "step", "multi", "framework", "agents", "action", "memory", "its"]
summary: "<!-- Page 1 -->

∗
Autono: A ReAct-Based Highly Robust Autonomous Agent Framework

### Zihao Wu †

Fujian University of Technology
April 9, 2025

### Abstract

This paper proposes a highly robust autonomous agent framework based on the ReAct paradigm, designed to solve
complextasksthroughadaptivedecisionmakingandmulti-agentcollaboration. Unliketraditionalframeworksthatrely
onfixedworkflowsgeneratedbyLLM-basedplanners,thisframeworkdynamicallygeneratesnextactionsduringagent
executionbasedonpriortr"
related_documents: []
---

# Autono ReAct Robust Agent Framework

<!-- Page 1 -->

∗
Autono: A ReAct-Based Highly Robust Autonomous Agent Framework

### Zihao Wu †

Fujian University of Technology
April 9, 2025

### Abstract

This paper proposes a highly robust autonomous agent framework based on the ReAct paradigm, designed to solve
complextasksthroughadaptivedecisionmakingandmulti-agentcollaboration. Unliketraditionalframeworksthatrely
onfixedworkflowsgeneratedbyLLM-basedplanners,thisframeworkdynamicallygeneratesnextactionsduringagent
executionbasedonpriortrajectories,therebyenhancingitsrobustness. Toaddresspotentialterminationissuescaused
byadaptiveexecutionpaths,Iproposeatimelyabandonmentstrategyincorporatingaprobabilisticpenaltymechanism.
Formulti-agentcollaboration,Iintroduceamemorytransfermechanismthatenablessharedanddynamicallyupdated
memory among agents. The framework’s innovative timely abandonment strategy dynamically adjusts the probability
oftaskabandonmentviaprobabilisticpenalties,allowingdeveloperstobalanceconservativeandexploratorytendencies
in agent execution strategies by tuning hyperparameters. This significantly improves adaptability and task execution
efficiency in complex environments. Additionally, agents can be extended through external tool integration, supported
by modular design and MCP protocol compatibility, which enables flexible action space expansion. Through explicit
divisionoflabor,themulti-agentcollaborationmechanismenablesagentstofocusonspecifictaskcomponents,thereby
significantly improving execution efficiency and quality.
Keywords: ReAct, Robustness, Autonomous Agent, Multi-Agent

### I Introduction

In recent years, the rapid advancement of artificial intelligence technology has revolutionized the field of natural language processing (NLP), enabling the development of increasingly sophisticated autonomous agent frameworks. These
frameworks aim to solve complex tasks by leveraging the capabilities of large language models (LLMs) and multi-agent
collaboration mechanisms. Starting with the introduction of the Transformer model[1], which laid the foundation for
modern deep learning architectures, the field has witnessed groundbreaking innovations such as the pre-trained BERT
model[2], chain-of-thought (CoT) prompting[3], and the ReAct paradigm[4]. Each of these advancements has contributed
significantly to enhancing the reasoning, adaptability, and efficiency of AI systems in handling complex tasks.
Despite these achievements, existing autonomous agent frameworks still face several limitations in flexibility, robustness,andmulti-agentcollaboration[5]. Traditionalframeworks,suchasAutoGenandLangChain,oftenrelyonpredefined
workflows generated by LLM-based planners[6]. While these approaches work well in structured environments, they
struggletoadapttouncertaintiesanddynamicchangesincomplexandreal-worldscenarios. Thisrigiditycanleadtosuboptimal performance, resource inefficiencies, and even task failures when faced with unexpected challenges. Furthermore,
multi-agent collaboration mechanisms in existing frameworks often lack effective mechanisms for information sharing and
dynamic coordination, limiting their ability to handle complex tasks that require seamless interaction among multiple
agents.
To address these limitations, this paper proposes a highly robust autonomous agent framework based on the ReAct
paradigm. The ReAct paradigm[4], which integrates reasoning and action in an iterative process, has demonstrated
significant advantages in reducing hallucinations[7] and improving task accuracy by allowing agents to interact with their
environmentandrefinetheirreasoninginrealtime. Bydynamicallygeneratingnextactionsduringagentexecutionbased
onpriortrajectories,myframeworkenhancesflexibilityandadaptability,enablingagentstorespondeffectivelytodynamic
task requirements and environmental feedback.
A key innovation of this framework is the introduction of a timely abandonment strategy with a probabilistic penalty
mechanism. This strategy dynamically adjusts the probability of task abandonment based on task progress and resource
consumption, ensuring timely termination of unproductive or overly resource-intensive tasks. By tuning hyperparameters
∗Repo: https://github.com/vortezwohl/Autono
†Email: vortez.wohl@gmail.com
1
5202
rpA
8
]AM.sc[
2v05640.4052:viXra

<!-- Page 2 -->

such as abandonment probability and penalty coefficient, developers can balance conservative and exploratory tendencies
in agent execution strategies, thereby improving adaptability and task efficiency in complex environments.
Additionally, the framework implements a memory transfer mechanism that enables agents to share and dynamically
update information during multi-agent collaboration. This mechanism allows agents to focus on specific task components
while maintaining a shared understanding of the overall task context, significantly improving execution efficiency and
quality. Furthermore, the framework adopts a modular design approach, enabling users to customize and optimize agent
behaviors according to specific requirements. This design enhances the framework’s applicability and practicality while
reducing development and deployment complexity.
The proposed framework also supports the Model Context Protocol (MCP)[8], an open specification designed to standardize how context is passed between LLMs and applications. By providing a structured framework for communication,
MCP enhances reliability, security, and functionality, enabling seamless integration with various tools and data sources.
This compatibility further extends the framework’s versatility and applicability in diverse scenarios.
In summary, this paper aims to address the limitations of existing agent frameworks by proposing a novel and highly
robust autonomous agent framework. By leveraging the ReAct paradigm, timely abandonment strategy, memory transfer
mechanism, and MCP compatibility, the framework is designed to enhance adaptability, robustness, and efficiency in
solving complex tasks. The contributions of this paper are expected to advance the state of the art in autonomous agent
frameworks.

### II Related Work

In the flourishing field of artificial intelligence, language models have achieved remarkable advances in natural language
processing. Starting with the groundbreaking Transformer model, the field has seen a series of innovations, including
the pre-trained BERT model, chain-of-thought (CoT) prompting, the ReAct paradigm, and multi-agent collaboration
mechanisms.
Chain-of-Thought (CoT) prompting[3] is a technique that enables reasoning capabilities through intermediate steps.
It helps large language models (LLMs) improve their performance in tasks requiring logical progression, such as mathematical and logical problems[3]. By explicitly describing intermediate reasoning steps, CoT enhances the transparency
andprecisionofAI’sthoughtprocessandcanbecombinedwithfew-shotprompting[9]forbetterresultsoncomplextasks
with limited examples.
ReAct (Reasoning + Acting)[4] is a prompt engineering method that integrates reasoning and action in an iterative
process. It allows AI to interact with an environment, learn from new data, and refine its reasoning in real time. The
method works by generating reasoning about a problem, interacting with an environment (e.g., querying APIs, searching
theweb),andusingtheresultstoinformthenextreasoningstep,creatingafeedbackloop. ThiscombinationofCoTwith
aconnectiontoexternalinformationsourcessignificantlyreduceshallucinations, makingReActagentsmoreaccurateand
trustworthy.
Multi-AgentCollaborationMechanisms[5]havealsoevolvedtoaddresscomplextasksthatrequirecoordinationamong
multiple agents. These mechanisms enable agents to work together, share information, and achieve common goals.
Notably,theAutoGenframework[10],designedasanadvancedmulti-agentdialoguesystem,supportsthecreationand
collaboration of multiple agents. However, its task termination depends primarily on preset maximum steps or human
feedback, lacking a flexible, adaptive task termination mechanism.
Similarly,theCrewAIframework[11]emphasizesrole-playingandcollaborationamongagentsbutfallsshortindynamic
task execution, struggling to respond effectively to sudden changes during task execution. The LangChain framework[12]
offers fine-grained control but is also limited in dynamically adjusting execution paths based on real-time task status.
TheSwarmframework[13],primarilyusedforeducationalpurposes,islightweightbutlacksproduction-gradefeaturesand
flexibility, making it insufficient for real-world complex tasks. The Magnetic-One framework[14] explores a novel multiagent collaboration architecture to overcome the limitations of single large models in handling complex tasks but faces
challenges in practical applications, such as the need for efficient communication and coordination mechanisms among
agents, and potential computational and communication bottlenecks in large-scale multi-agent systems.
Moreover, none of the above frameworks supports the Model Context Protocol (MCP). MCP is an open specification
designed to standardize how context is passed between LLMs and applications[8]. MCP provides a structured framework that improves reliability, security, and functionality by addressing challenges such as standardizing communication,
enhancing context management, improving security, enabling complex workflows, and promoting interoperability. MCP
definesastructuredmessageformat[8]thatseparatesdifferenttypesofinformationbeingsenttoandfromlanguagemodels,includingsystemmessages,usermessages,assistantmessages,toolmessages,andmetadata. Thisstructuredapproach
allowsforclearerdelineationofrolesandresponsibilitieswithinthecommunicationflow,reducingambiguityandpotential
confusion for the model.
One of the key advantages of MCP is its plug-and-play characteristic, platform independence, and technology stack
independence. MCP acts as a universal interface, enabling developers to avoid the fragmentation of maintaining separate
2

<!-- Page 3 -->

integrations. Once an application supports MCP, it can connect to any number of services through a single mechanism.
This dramatically reduces the manual setup required each time you want your AI to use a new API. Teams can focus on
higher-level logic rather than reinventing connection code for the 10th time. MCP replaces fragmented integrations with
a simpler, more reliable single protocol for data access[8], allowing AI applications to seamlessly connect to various tools
and data sources without the need for custom coding each from scratch.
To address these limitations, this paper proposes a highly robust autonomous agent framework based on the ReAct
paradigm. The framework introduces several innovative mechanisms to enhance adaptability and robustness in complex
environments. One of the key innovations of this framework is its compatibility with the MCP protocol, which enables
seamlessintegrationwithvarioustoolsanddatasources,enhancingtheframework’sversatilityandapplicabilityindiverse
scenarios.

### III Key Concepts

This framework is built around two key concepts: Agent and Tool.
An agent is defined as an autonomous artificial intelligence entity with the following properties:

## Autonomy: Agents can execute tasks independently without human intervention, capable of self-action and selfcorrection.


## Goal-Driven: All actions of the agent are ultimately aimed at achieving specific goals.


## Extensible: The agents’ capabilities can be directly extended without modifying its underlying structure.


## Limited Action Space: An agent only executes actions within its defined action space.


## InfiniteStateSpace: Theagents’statesarederivedfromactionfeedback,whichisdeterminedbytheenvironment.


## Observable: The agents’ operations are observable and modifiable, allowing users to intervene in its action trajectory.


## MemoryCapability: Theagentscanrememberitstrajectories,anddifferentagentinstancescanshareandtransfer

memories, enabling multi-agent collaboration.

## Controllable Behavior: An agent’s behavior tendencies can be controlled, which allowing users to adjust the

agent’s inclination toward cautiousness or exploration.
A tool is an encapsulated action logic that the agent can invoke, with the following properties:

## Descriptive: Tools have descriptive metadata, such as name, description, parameter requirements, and return

description.

## Parameterized: Tools can receive input parameters that define their execution manner and conditions.


## Semantic Feedback: Theresponseofatoolissemanticallyrich,typicallyintheformoftextorastring,indicating

the execution result and environmental feedback.
Tools are divided into general tools and handoff tools. General tools are common tools an agent can use, while handoff
tools enable task handover and memory transfer between agents. When an agent encounters a subtask it cannot solve, it
checks its handoff tools and passes the task to another agent with the appropriate capabilities.
3

<!-- Page 4 -->


### IV System Design


### Figure 1: Components of an Agent

Figure 1 shows the architecture design of the agent. An agent consists of the following components:

## Thought Engine: The brain of the agent, typically a fine-tuned general language model.


## Tools: Encapsulated action logic that defines the agent’s action space.


## Step Estimator: Estimates the number of steps required to complete a task based on the agent’s action space.


## Penalty: Implements the probabilistic penalty mechanism for the timely abandonment strategy.


## Memory: Stores the agent’s execution trajectories and state changes, enabling short-term memory and memory

transfer between agents.

## Request Resolver: Understands tasks, decomposes subtasks, and extracts goals.


## Next Move Scheduler: Estimates the next action based on the agent’s action trajectories and state changes,

selecting the appropriate ability and generating corresponding parameters.

## Executor: Executes the actions, analyzes the results and environmental feedback, and updates the agent’s trajectory.


## Introspection: Summarizes the agent’s actions and extracts task results after the agent reaches its final state or

exits due to the timely abandonment strategy.
Figure 2: Task Execution Workflow of an Agent
4

<!-- Page 5 -->

Figure 2 illustrates the process of a task execution workflow. It involves three entities: Human, Agent, and Tool. The
process begins with the Human assigning tasks to the Agent. Upon receiving the task, the Agent uses a Tool to perform
the task. After the Tool completes the task, it sends feedback to the Agent. Finally, the Agent responds to the Human
with the results of the task execution. This sequence of actions demonstrates how an agent interacts with humans and
tools to accomplish tasks.

### Figure 3: Task Execution Workflow Involving Multiple Agents

Figure 3 illustrates the process of a task execution workflow involving multiple agents. It involves four entities: Human,
Agent1, Tool1, HandoffTool, Agent2, and Tool2. The process begins with the Human assigning a task to Agent1. Upon
receiving the task, Agent1 uses Tool1 to perform the task. After Tool1 completes its part, it sends feedback to Agent1.
However, when Agent1 encounters a subtask that it cannot solve (e.g., Tool2 is inaccessible to Agent1), it uses the
HandoffTooltopassthetaskanditsmemoriestoAgent2. Agent2receivesthetaskandmemories, usesTool2tocomplete
the task, and sends feedback to Agent1. Finally, Agent1 responds to the Human with the overall results of the task
execution. This sequence demonstrates how multiple agents interact with humans, tools, and handoff mechanisms to
collaboratively accomplish complex tasks.

### V MCP Compatibility

To ensure compatibility with the MCP protocol, I design and implement an MCP tool adapter and session management
mechanism. The MCP protocol, a standardized communication protocol, aims to address the interaction challenges
between large language models and external tools, providing flexible tool invocation capabilities for agents.
ToolAdapter ThecoreideaoftheMCPtooladapteristoencapsulateMCP-definedtoolinterfacesintotoolsthatagents
can directly invoke. The adapter parses the tool description information defined by the MCP protocol to dynamically
generate metadata for tools, including tool names, parameter types, and descriptions. This encapsulation allows agents
toinvoketoolsfromdifferentsources inaunifiedmannerwithoutconcerningthemselveswiththespecificimplementation
details of the tools.
Clients TheMCPclientisresponsibleforestablishingconnectionswithMCPserversandmanagingthecommunication
process. Iimplementmultipleclientadapters,includingthosebasedonstandardinput/output,Server-SentEvents(SSE),
5

<!-- Page 6 -->

and WebSocket, to support different types of MCP servers. The client design adopts a modular approach, dynamically
selecting the appropriate communication method based on the specific MCP server type.
Session Management To ensure efficient and reliable communication between agents and MCP servers, I implement
the session persistence mechanism, which maintains session states, allowing agents to seamlessly switch tool invocations
across different task executions without re-establishing connections.

### VI Algorithms


### VI.I ReAct Based Action Strategy

Algorithm 1 is designed to dynamically determine the next move of an agent based on its prior trajectory and available
tool set.

### Algorithm 1 ReAct Based Action Strategy

Input:User request r, Trajectory j, Current state s, Tools t

### Output:Next move (t”, a’)

1: Extract events related to r from j and s in chronological order, denoted as e
2: if r is completed according to e then
3: return success ▷ Goal achieved, reaching the final state
4: else
5: Analyze and extract the remaining subtasks, denoted as u
6: if t contains tools capable of completing u then
7: Select a subset of relevant tools t′
8: else
9: return failure ▷ Goal determined to be unachievable, reaching the final state
10: end if
11: Plan the next action m based on e
12: Select the tool t′′ from t′ for executing m
13: Generate arguments a′ required for t′′ according to m
14: return t′′, a′
15: end if
This approach enables the agent to adaptively adjust its actions in response to changing task requirements and environmentalfeedback,ensuringefficientprogresstowardtheultimategoal. Byleveragingchain-of-thought(CoT)reasoningand
toolmatchinganalysis,thealgorithmenhancestheagent’sdecision-makingcapabilitiesandensuresrobusttaskexecution.
The algorithm consists of several key steps, including relevant event extraction, task completion status determination,
tool matching analysis, next move estimation, and action execution with state updates. Each step is carefully designed to
optimize the agent’s performance in complex and dynamic environments. The main steps of the algorithm are as follows:
Relevant Event Extraction Extract events related to the task goal from the trajectory. This step uses a language
model to identify and extract relevant events, which are then sorted chronologically.
Task Completion Status Determination Analyze the extracted events to determine whether the task goal has been
achieved. This step uses chain-of-thought (CoT) to optimize the accuracy of the judgment.
Tool Matching Analysis Analyzetheagent’stoolsettodetermineiftherearesuitabletoolstoadvancethetaskgoal.
This step also uses CoT to ensure the judgment is strictly based on the extracted events.
Next Move Estimation and Tool Selection Estimate the next move based on the prior trajectory and task goal,
select the appropriate tool, and generate the corresponding arguments.
Action Execution and State Update Execute the next move just estimated, obtain the result and environmental
feedback, then update the agent’s trajectory.
6

<!-- Page 7 -->


### VI.II Timely Abandonment Strategy

Algorithm 2 is designed to dynamically control the agent’s task execution steps, allowing it to abandon tasks when they
become unproductive or excessively resource-consuming.
Algorithm 2 Timely Abandonment Strategy

### Input:


### User request r;

Abandonment probability p;
Penalty coefficient β;

### Step estimator E;

Next move estimator N;

### Executor X;


### Output:Task result

1: s←E(r) ▷ Estimate required steps using the step estimator
2: c←0 ▷ Initialize step count
3: while True do
4: m←N(r,...) ▷ Estimate the next action
5: X(m) ▷ Execute the next action
6: if r is completed then
7: return success ▷ Task successfully completed
8: else if r is confirmed to be unattainable then
9: return failure ▷ Task failed
10: end if
11: if c>s then ▷ Current steps exceed estimated steps
12: rand∼Uniform(0,1)
13: if rand>p then ▷ Continue the task with probability 1−p
14: p←(β×p) mod 1 ▷ Apply penalty
15: else ▷ Abandon the task with probability p
16: return failure ▷ Abandoned, task failed
17: end if
18: end if
19: c++ ▷ Increment step count
20: end while
This algorithm introduces two hyperparameters: abandonment probability p and penalty coefficient β, which
together regulate the agent’s tendency to abandon tasks.
Abandonment Probability p prepresentstheprobabilitythattheagentwillabandonthetaskwhenthecurrentsteps
exceed the estimated steps. A higher p makes the agent more likely to abandon tasks early, reflecting a more cautious
behavior. A lower p encourages the agent to persist longer, reflecting a more exploratory behavior.
Penalty Coefficient β β is used to amplify the abandonment probability p when the agent continues executing the
task beyond estimated steps. A higher β increases the penalty more rapidly, forcing the agent to abandon tasks sooner.
A lower β allows the agent to continue exploring for longer before abandoning the task.
How p and β Work Together When an agent’s current steps exceed the estimated steps, it enters a probabilistic
decision-making phase. If the agent continues (with probability 1 - p), the abandonment probability p is penalized with
equation 1, which increases the likelihood of abandonment in subsequent steps.
p=(β×p) mod 1 (1)
The algorithm consists of several key steps, including step estimation, action execution, task completion status determination, and probabilistic abandonment. This ensures that the agent dynamically balances exploration and caution,
adapting its behavior based on task complexity and environmental feedback.
7

<!-- Page 8 -->


### VI.III Memory Storage and Sharing Mechanism

In multi-agent collaboration scenarios, memory storage and sharing mechanisms are crucial for achieving information
synchronization and effective collaboration among agents. The following sections detail the multi-agent memory sharing
mechanism implemented in this paper from three aspects: memory storage, memory update, and memory transfer.
Memory Storage Inthismechanism, eachagentisdesignedwithitsownmemorystoragestructuretosavetheexperience and knowledge accumulated during task execution. Memories are stored in the form of an ordered dictionary, a data
structure that preserves the insertion order of memories, facilitating subsequent retrieval and processing in chronological
order. The content of each memory includes timestamps, agent identifiers, action executions, and action summaries.
Timestamps indicate when the memory was created, agent identifiers specify which agent generated the memory, action
summariesconciselydescribethecorecontentoftheactionanditsfeedback,andactionexecutionsdetailtheactionstaken
bytheagentandtheirassociatedparameters. Thisstructuredstorageapproachensuresthatmemoriesarewell-organized
and readable, providing a foundation for subsequent memory transfer and fusion.
Memory Update After each action, the agent records the result as a new memory and adds it to its memory storage.
When estimating the next move, the agent retrieves its action trajectory and current state from memory to guide its
subsequent actions. Once a task is completed or a termination condition is met, the agent resets its memory to prepare
for the next task.
Memory Transfer Memory transfer is a critical step in multi-agent collaboration. When an agent needs assistance
from other agents or needs to delegate a task, it passes its memories to the target agent. This allows the target agent to
understand the current task status and existing experience of the source agent. Upon receiving the memories, the target
agentmergesthemwithitsexistingmemories. Thismechanismenablesrapidinformationsharingamongagents,avoiding
redundant exploration and enhancing system efficiency. For example, if Agent A encounters a complex task and lacks
specific knowledge or capabilities, it can transfer its task context and accumulated experience to Agent B via the memory
transfer mechanism. With this information, Agent B can better understand the task requirements and effectively assist
Agent A in completing the task.

### VII Experiment

The primary objective of this experiment is to evaluate the performance of three frameworks: autono (the proposed
framework), autogen, and langchain, in handling tasks of varying complexity. Specifically, the experiment aims to assess
their adaptability and robustness as task complexity increases. Based on task complexity, the experimental tasks are
categorized into three types:

## Single-Step Tasks: Simple tasks that can be completed with a single action.


## Multi-Step Tasks: Tasks that require a sequence of actions to complete.


## Multi-Step Tasks with Possible Failures: Themostcomplexcategory, thesetasksinvolveactionsthatmayfail

duringexecution,necessitatingerrorcorrectionandretrymechanisms. Thiscategorysimulatesreal-worldproduction
environments with uncertainties and failures, posing higher requirements for algorithm robustness and adaptability.
To comprehensively and objectively evaluate the performance of each framework, success rate is selected as the evaluation metric. Success rate is calculated as the percentage of tasks executed successfully as requested relative to the total
number of tasks. The success rate of each framework is computed for each task type to facilitate an intuitive comparison
of their performance differences. To ensure the reproducibility of the experiment, the experimental environment has been
pushed to a public GitHub repository at https://github.com/vortezwohl/experiment-03-22-2025. Anyone can use
this repository to reproduce the experiment.

### VII.I Experimental Results and Analysis

Single-Step Tasks The results indicate that autono performs exceptionally well in single-step tasks. With GPT-4omini as the thought engine, it achieves a success rate of 96.7%. When using Qwen-plus and DeepSeek-v3, the success
rate reaches 100%. This demonstrates that autono is highly stable and effective in handling simple tasks. In contrast,
autogenshowsslightlyinferiorperformanceinsingle-steptasks, achievinga90%successratewithbothGPT-4o-miniand
Qwen-plus. DeepSeek-v3 is unsupported in autogen, making evaluation impossible (marked as N/A). Langchain achieves
successratesof73.3%(GPT-4o-mini),73.3%(Qwen-plus),and76.7%(DeepSeek-v3)insingle-steptasks. Whilelangchain
can complete most single-step tasks, its success rate is significantly lower than that of autono and autogen.
8

<!-- Page 9 -->

Framework Version Model Single-Step Tasks Multi-Step Tasks Multi-Step Tasks with Possible Failures
autono 1.0.0 GPT-4o-mini 96.7% 100% 76.7%
autono 1.0.0 Qwen-plus 100% 96.7% 93.3%
autono 1.0.0 DeepSeek-v3 100% 100% 93.3%
autogen 0.4.9.2 GPT-4o-mini 90% 53.3% 3.3%
autogen 0.4.9.2 Qwen-plus 90% 0% 3.3%
autogen 0.4.9.2 DeepSeek-v3 N/A N/A N/A
langchain 0.3.21 GPT-4o-mini 73.3% 13.3% 10%
langchain 0.3.21 Qwen-plus 73.3% 13.3% 13.3%
langchain 0.3.21 DeepSeek-v3 76.7% 13.3% 6.7%

### Table 1: Experimental Results

Multi-Step Tasks Inmulti-steptasks,autonocontinuestolead,achievingsuccessratesof100%(GPT-4o-mini),96.7%
(Qwen-plus), and 100% (DeepSeek-v3). This highlights its robust capability in handling complex tasks. Autogen’s
performance in multi-step tasks is notably inconsistent. With GPT-4o-mini, the success rate is 53.3%, while with Qwenplus, it drops to 0%. DeepSeek-v3 is unsupported. This indicates that autogen’s compatibility with third-party models is
suboptimal,anditstrugglestoeffectivelyexecutecomplextasks. Langchain’ssuccessrateinmulti-steptasksisuniformly
low at 13.3% across all three models, reflecting significant limitations in handling complex task execution scenarios.
Multi-Step Tasks with Possible Failures Formulti-steptaskswithpossiblefailures,autonoremainshighlyeffective.
WithGPT-4o-mini, itachievesa76.7%successrate, and93.3%withbothQwen-plusandDeepSeek-v3. Thisunderscores
its strong adaptability and robustness, as it can automatically correct errors and leverage past experiences to ensure task
success. Autogencontinuestounderperforminthesetasks,achievingonlya3.3%successratewithbothGPT-4o-miniand
Qwen-plus. DeepSeek-v3isunsupported. Thisfurtherhighlightsautogen’slimitationsinhandlingcomplexanduncertain
tasks, lacking effective error-handling mechanisms and retry logic. Langchain achieves success rates of 10% (GPT-4omini), 13.3% (Qwen-plus), and 6.7% (DeepSeek-v3) in multi-step tasks with failures, indicating insufficient robustness in
handling complex and uncertain tasks.

### VII.II Experimental Conclusion

Overall, autono demonstrates superior performance across all task types, particularly in multi-step and multi-step tasks
withpossiblefailures. Thisdemonstratesitssuperioradaptabilityandrobustnessinhandlingcomplextasks,underscoring
its advantages in complex task processing and validating the effectiveness of its ReAct-based action strategy and timely
abandonmentstrategy,andmeetingdiversescenariorequirementsandprovidingreliablesolutionsfordevelopers. Autogen
performs adequately in single-step tasks but sees a significant drop in success rate in multi-step and multi-step tasks with
possible failures, especially when using non-OpenAI third-party models. Langchain consistently shows lower success
rates across all task types, particularly struggling with multi-step and multi-step with possible failures, revealing notable
limitationsinmulti-stepexecution,adaptability,androbustness. Differentmodelsexhibithighperformancewithinautono,
indicating excellent compatibility with mainstream models.

### VIII Conclusion and Future Work

ThepaperproposesahighlyrobustautonomousagentframeworkbasedontheReActparadigm,designedtosolvecomplex
tasksthroughReAct-basedactionstrategiesandtimelyabandonmentstrategies. Theframework’skeyinnovationsinclude:
ReAct-based action strategies, timely abandonment strategies, and compatibility with the MCP protocol. Experimental
results demonstrate that the framework achieves high success rates in single-step tasks, multi-step tasks, and multi-step
tasks with potential failures, showcasing strong adaptability and robustness in complex and uncertain environments.
Thelimitationsoftheframeworkareprimarilyreflectedinthefollowingaspects: First,therobustnessoftheframework
relies heavily on ReAct-based action strategies and timely abandonment strategies, which may still be insufficient to
handleextremecomplexityordynamicallychangingenvironments. Second,whilethemulti-agentcollaborationmechanism
supports memory sharing, it does not deeply explore how to optimize communication efficiency and coordination among
agents,whichcouldbecomeabottleneckinlarge-scalemulti-agentsystems. Additionally,theexperimentalsectionfocuses
mainly on task success rates, but does not sufficiently address the optimization of task execution efficiency and resource
consumption.
Future work could explore several directions: First, further optimizing the timely abandonment strategy to enable
smarter judgments of task feasibility and reduce unnecessary resource waste. Second, investigating more efficient communication and coordination mechanisms for multi-agent systems to support large-scale complex task collaboration. Third,
expanding the framework’s applicability, particularly in real-time task scenarios, to validate its performance. Fourth,
integrating reinforcement learning techniques to enhance the agents’ adaptability and decision-making efficiency. Overall,
9

<!-- Page 10 -->

the framework proposed in this paper provides a new perspective for designing intelligent agents in complex tasks, but
there is still room for improvement, and future research can build on this foundation to further refine the framework.

### References

[1] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and
Illia Polosukhin. Attention is all you need. arXiv preprint, 2017.
[2] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional
transformers for language understanding. arXiv preprint, 2018.
[3] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, and
Denny Zhou. Chain-of-thought prompting elicits reasoning in large language models. In Conference on Neural
Information Processing Systems (NeurIPS), 2022.
[4] ShunyuYao,JeffreyZhao,DianYu,NanDu,IzhakShafran,KarthikNarasimhan,andYuanCao. React: Synergizing
reasoning and acting in language models. arXiv preprint, 2022.
[5] Yashar Talebirad and Amirhossein Nadiri. Multi-agent collaboration: Harnessing the power of intelligent llm agents.
arXiv preprint, 2023.
[6] Xu Huang, Weiwen Liu, Xiaolong Chen, Xingmei Wang, Hao Wang, Defu Lian, Yasheng Wang, Ruiming Tang, and
Enhong Chen. Understanding the planning of llm agents: A survey. arXiv preprint, 2024.
[7] Lei Huang et al. A survey on hallucination in large language models: Principles, taxonomy, challenges, and open
questions. arXiv preprint, 2023.
[8] XinyiHou,YanjieZhao,ShenaoWang,andHaoyuWang. Modelcontextprotocol(mcp): Landscape,securitythreats,
and future research directions. arXiv preprint, 2025.
[9] Morteza Bahrami, Muharram Mansoorizadeh, and Hassan Khotanlou. Few-shot learning with prompting methods.
In 2023 6th International Conference on Pattern Recognition and Image Analysis (IPRIA), pages 1–5, 2023.
[10] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun
Zhang, Jiale Liu, et al. Autogen: Enabling next-gen llm applications via multi-agent conversation. arXiv preprint,
2023.
[11] CrewAI Team. CrewAI: Framework for orchestrating role-playing, autonomous AI agents. https://github.com/
crewAIInc/crewAI, March 2023.
[12] Harrison Chase. LangChain: Build context-aware reasoning applications. https://github.com/langchain-ai/
langchain, October 2022.
[13] OpenAI Solution Team. Swarm: Educational framework exploring ergonomic, lightweight multi-agent orchestration.
https://github.com/openai/swarm, October 2024.
[14] Adam Fourney, Gagan Bansal, Hussein Mozannar, Cheng Tan, Eduardo Salinas, Erkang Zhu, Friederike Niedtner,
Grace Proebsting, Griffin Bassman, Jack Gerrits, et al. Magentic-one: A generalist multi-agent system for solving
complex tasks. arXiv preprint, 2024.
10

## Tables

**Table (Page 9):**

| Framework | Version | Model | Single-Step Tasks | Multi-Step Tasks | Multi-Step Tasks with Possible Failures |
|---|---|---|---|---|---|
| autono | 1.0.0 | GPT-4o-mini | 96.7% | 100% | 76.7% |
| autono | 1.0.0 | Qwen-plus | 100% | 96.7% | 93.3% |
| autono | 1.0.0 | DeepSeek-v3 | 100% | 100% | 93.3% |
| autogen | 0.4.9.2 | GPT-4o-mini | 90% | 53.3% | 3.3% |
| autogen | 0.4.9.2 | Qwen-plus | 90% | 0% | 3.3% |
| autogen | 0.4.9.2 | DeepSeek-v3 | N/A | N/A | N/A |
| langchain | 0.3.21 | GPT-4o-mini | 73.3% | 13.3% | 10% |
| langchain | 0.3.21 | Qwen-plus | 73.3% | 13.3% | 13.3% |
| langchain | 0.3.21 | DeepSeek-v3 | 76.7% | 13.3% | 6.7% |
