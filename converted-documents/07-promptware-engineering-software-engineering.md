---
title: "Promptware Engineering Software Engineering"
original_file: "./07_Promptware_Engineering_Software_Engineering.pdf"
document_type: "research"
conversion_date: "2025-11-29"
topics: ["prompt-engineering", "llm", "rag", "chain-of-thought", "agents"]
keywords: ["prompt", "page", "llm", "vol", "article", "publicationdate", "additionally", "promptwareengineering", "llms", "engineering"]
summary: "<!-- Page 1 -->

Promptware Engineering: Software Engineering for LLM

### Prompt Development

ZHENPENGCHEN,NanyangTechnologicalUniversity,Singapore

### CHONGWANG,NanyangTechnologicalUniversity,Singapore

WEISONGSUN,NanyangTechnologicalUniversity,Singapore

### GUANGYANG,Microsoft,China


### XUANZHELIU,PekingUniversity,China


### JIEM.ZHANG,King’sCollegeLondon,UnitedKingdom


### YANGLIU,NanyangTechnologicalUniversity,Singapore

LargeLanguageModels(LLMs)areincreasinglyintegratedintosoftwareap"
related_documents: []
---

# Promptware Engineering Software Engineering

<!-- Page 1 -->

Promptware Engineering: Software Engineering for LLM

### Prompt Development

ZHENPENGCHEN,NanyangTechnologicalUniversity,Singapore

### CHONGWANG,NanyangTechnologicalUniversity,Singapore

WEISONGSUN,NanyangTechnologicalUniversity,Singapore

### GUANGYANG,Microsoft,China


### XUANZHELIU,PekingUniversity,China


### JIEM.ZHANG,King’sCollegeLondon,UnitedKingdom


### YANGLIU,NanyangTechnologicalUniversity,Singapore

LargeLanguageModels(LLMs)areincreasinglyintegratedintosoftwareapplications,withpromptsserving
as the primary ‘programming’ interface to guide their behavior. As a result, a new software paradigm,
promptware,hasemerged,usingnaturallanguagepromptstointeractwithLLMsandenablingcomplex
taskswithouttraditionalcoding.Unliketraditionalsoftware,whichreliesonformalprogramminglanguages
anddeterministicruntimeenvironments,promptwareisbasedonambiguous,unstructured,andcontextdependentnaturallanguageandoperatesonLLMsasruntimeenvironments,whichareprobabilisticandnondeterministic.Thesefundamentaldifferencesintroduceuniquechallengesinpromptdevelopment.Inpractice,
promptdevelopmentislargelyadhocandexperimental,relyingonatime-consumingtrial-and-errorprocess
—achallengewetermthe‘promptwarecrisis.’Toaddressthis,weproposepromptwareengineering,anew
methodologythatadaptsestablishedsoftwareengineeringprinciplestotheprocessofpromptdevelopment.
Buildingondecadesofsuccessintraditionalsoftwareengineering,weenvisionasystematicframeworkthat
includespromptrequirementsengineering,design,implementation,testing,debugging,andevolution.Unlike
traditionalsoftwareengineering,ourframeworkisspecificallytailoredtotheuniquecharacteristicsofprompt
development.Thispaperoutlinesacomprehensiveroadmapforpromptwareengineering,identifyingkey
researchdirectionsandofferingactionableinsightstoadvanceLLM-basedsoftwaredevelopment.
AdditionalKeyWordsandPhrases:PromptwareEngineering,SoftwareEngineering,Prompt,LargeLanguage

### Model

1 Introduction
LargeLanguageModels(LLMs),suchasGPT[7],LLaMA[40],andDeepSeek[10],areincreasingly
integratedintosoftwareapplicationsacrossdiversedomains[15,29,44].Majortechnologycompanies,includingMicrosoft,Google,Amazon,andApple,haveallintegratedLLMsintotheirsoftware
products[34],reachingmillionsofusers.
InLLM-basedsoftware,promptsserveastheprimary‘programming’interface,directlyshapingthebehaviorandoutputsofLLMs[39].Recognizingtheircentralrole,researchershavedescribedLLM-basedsoftwareasprompt-poweredsoftware[30],whilepractitionershaveintroduced
template-basedapproaches,suchastheLiquidprompttemplate[4]andLangChainprompttemplate[3],tosupportpromptprogramming.Thisshifthasledtotheemergenceofpromptware[23],
anewparadigmwherenaturallanguagepromptsreplacetraditionalcode,enablingcomplextasks
tobeexecutedthroughdirectinteractionwithLLMs.AsLLMscontinuetoadvance,promptware
is likely to become the dominant paradigm in software development, with prompts replacing
traditionalcodingastheprimarymethodforcreatingandmanagingLLM-basedsoftware.
Authors’ContactInformation:ZhenpengChen,zhenpeng.chen@ntu.edu.sg,NanyangTechnologicalUniversity,Singapore;
ChongWang,chong.wang@ntu.edu.sg,NanyangTechnologicalUniversity,Singapore;WeisongSun,weisong.sun@ntu.edu.
sg,NanyangTechnologicalUniversity,Singapore;GuangYang,guangyang@microsoft.com,Microsoft,China;Xuanzhe
Liu,liuxuanzhe@pku.edu.cn,PekingUniversity,China;JieM.Zhang,jie.zhang@kcl.ac.uk,King’sCollegeLondon,United
Kingdom;YangLiu,yangliu@ntu.edu.sg,NanyangTechnologicalUniversity,Singapore.
,Vol.1,No.1,Article.Publicationdate:March2025.
5202
raM
4
]ES.sc[
1v00420.3052:viXra

<!-- Page 2 -->

2 Chenetal.
Promptwarefundamentallydiffersfromtraditionalsoftwareintwokeyaspects:languageand
runtimeenvironment.Unlikestructuredprogramminglanguageswithstrictsyntaxanddeterministicbehavior,promptsarewritteninnaturallanguage,whichisflexible,context-dependent,and
ambiguous.Thismakesformalizingpromptconstructionandanalysischallenging.Additionally,
whiletraditionalsoftwaretypicallyreliesondeterministicruntimeenvironments,promptwareuses
probabilistic,non-deterministicLLMsasruntimeenvironments,introducinguniquechallengessuch
ashuman-likebehaviors,unclearcapabilityboundaries,undefinederrorhandling,anduncertain
executioncontrol.Thesecomplexitiesmakepromptdevelopmentparticularlydifficult.
Promptengineeringhasbeenawidelyadoptedsolutionforpromptdevelopment[38].OpenAI
defines it as ‘designing and optimizing input prompts to effectively guide a language model’s
responses’ [5]; Meta calls it ‘a technique used in natural language processing to improve the
performanceofthelanguagemodelbyprovidingmorecontextandinformationaboutthetaskat
hand’[6].Theseorganizationshavepublishedofficialguidelinestosupportpromptengineering[1,
6],buttheyshareacriticallimitation:theyareoutput-centricandlacksystematicmethodologies
forpromptdevelopment.
In practice, prompt engineering often relies on ad hoc, experimental approaches [17, 24, 30,
33,34,36,39],especiallyasLLM-basedsoftwarebecomesincreasinglycomplex—whatwerefer
to as the ‘promptware crisis.’ Existing studies [17, 30, 33, 36] show that prompt engineering is
largelytrial-and-error,time-consuming,andchallenging,withevenexperiencedengineersfacing
difficulties.Thishighlightstheurgentneedforasystematic,development-centricframeworkto
movebeyondtheadhocapproachesandaddressthegrowingchallengesofthepromptwarecrisis.
Inthispaper,weintroducepromptwareengineering,anewmethodologythatappliessoftware
engineering(SE)principlestopromptdevelopment.Thisvisionisdrivenbytwokeyrationales:
(1)AsLLMsbecomeintegraltoanexpandingrangeofsoftwareapplications,promptshaveemerged
ascrucialsoftwarecomponents.Thus,promptwarehassurfacedasanevolvingsoftwareparadigm,
with prompt development increasingly recognized as a new form of programming [30]. This
shift positions prompt development as a vital aspect of SE. (2) Current prompt development
practicesareoftenadhocandexperimental,drivenbyuniquecomplexities.However,decadesofSE
advancementshighlightthevalueofsystematicapproachestomanagecomplexity,ensurequality,
andsupportiterativeimprovements,underscoringthepotentialtotransformpromptdevelopment
fromanexperimentalpracticeintoastructuredanddisciplinedprocess.
RealizingthevisionofpromptwareengineeringrequiresintegratingcoreSEactivities,specificallytailoredtotheuniquedemandsofpromptdevelopment.Theseactivitiesincludeprompt
requirementsengineering,design,implementation,testing,debugging,andevolution.Tosupport
them,weemphasizetheneedforinnovativeresearch,tools,andautomationthroughouttheprompt
development lifecycle. This paper discusses key challenges and highlights promising research
opportunitiesinpromptwareengineering.
2 Preliminaries
Thissectiondefineskeyterminologiesandsituatesourvisionwithinthecontextofexistingresearch.
2.1 Terminologies
LLM. LLMs are advanced computational models designed to understand and generate human
language,distinguishedbytheirmassiveparametersizesandabilitytolearnfromlargeanddiverse
datasets[12].CommonexamplesincludeGPT[7],LLaMA[40],Claude[2],andDeepSeek[10].
LLM-basedsoftware.LLM-basedsoftwarereferstosoftwareapplicationsthatintegrateLLMs
ascomponentstoperformdiversetasks[33].IttypicallyincludesoneormoreLLMs,promptsfor
interactingwiththem,andadditionalsupportingcodeandcomponents.
,Vol.1,No.1,Article.Publicationdate:March2025.

<!-- Page 3 -->

PromptwareEngineering:SoftwareEngineeringforLLMPromptDevelopment 3
Prompt.PromptsarenaturallanguageinstructionsorqueriesgiventoLLMsthatdefinethecontext,
task,orexpectedbehavior[39].TheyallowLLMstoperformdownstreamtaskswithoutmodifying
theirparametersandareessentialcomponentsofLLM-basedsoftware.
Promptware.Promptwareisasoftwareparadigmthatusesnaturallanguagepromptstointeract
withLLMs[23],enablingcomplextaskswithouttraditionalcoding.
Promptwareengineering.PromptwareengineeringisthemethodologyofapplyingSEprinciples
tothedevelopmentofprompts.
ItcanbeviewedasanewmethodologythatbridgespromptengineeringandSE.Itextendsprompt
engineeringbyspecifyingtheengineeringprinciplesthatguidepromptdevelopment,offeringa
systematicframeworkforcreatingeffectiveandreliableinteractionswithLLMs.Simultaneously,it
broadensthescopeofSEbyintroducingpromptsasanewsoftwarecomponentinthecontextof
emergingLLM-basedsoftware.
2.2 RelatedWork
TherehasbeennumerousresearchcombiningpromptengineeringandSE.Mostoftheseworks
focusonpromptengineeringforSE.ThewidespreadadoptionofLLMsinSEtaskshassparked
significantinterestinpromptengineeringtechniquesaimedatimprovingtheeffectivenessofLLMs
in these scenarios. Wang et al. [43] conducted a comprehensive survey on the use of LLMs in
softwaretesting,acriticalSEactivity.Theirfindingsrevealedthatabouttwo-thirdsofstudiesin
thisdomainemploypromptengineering.Fanetal.[18]andHouetal.[25]extendedthescope
of the surveys to encompass the entire SE lifecycle. Fan et al. [18] reviewed common prompt
engineeringstrategiesappliedtotaskssuchascodegeneration,softwaretesting,andmaintenance.
Houetal.[25]identifiedeightpromptengineeringtechniquescurrentlyemployedintheLLM
forSEdomain.Alshahwanetal.[8]proposedavisionforassuredLLM-basedSE,outlininghow
search-basedSEapproachescanbeleveragedtooptimizepromptsinSEactivities.Recently,therise
ofLLM-basedagentsinSEhasfurtherhighlightedtheimportanceofpromptengineering.These
techniqueshavebeenwidelyadoptedinconstructingagentstoenhancetheirperformanceacross
variousSEtasks[31].
Incontrast,SEforpromptengineeringhasnotbeenwellexplored.Existingstudiesprimarilyfocus
onempiricalinvestigationsintothechallengessoftwareengineersfaceduringpromptengineering.
Mailachetal.[33]andParninetal.[36]studiedchallengesfacedbysoftwarepractitionersindevelopingLLM-basedapplications,andidentifiedpromptengineeringasakeyconcern.Practitioners
highlightedissuessuchastheexperimentalnatureofprompting,aswellaschallengesrelatedto
contextlength,computationalcosts,andunpredictablechangesinprompts[33].Theyalsonoted
thatdesigningandmanagingpromptsefficientlyistime-consumingandresource-constrained[36].
Similarly,Dolataetal.[17]foundfreelancersstrugglewithtrial-and-errorpromptingcycles.They
reportedthatsubtledifferencesinpromptsresultedininconsistentoutputsandidentifiedchallenges
in managing experimentation costs. Liang et al. [30] conceptualized prompts as a new type of
programandconductedinterviewstounderstandhowdevelopersintegratethemintosoftware.
Theirfindingsrevealedthatpromptprogrammingisarapid,unsystematicprocess,significantly
differentfromtraditionalsoftwaredevelopment.Tafreshipouretal.[39]studiedpromptevolutionin
real-worldprojectsandreportedthatonly21.9%ofpromptchangesaredocumented.Thesechanges
oftenresultinlogicalinconsistenciesandmisalignmentsbetweenpromptsandLLMresponses.
Nahar et al. [34] interviewed product teams at Microsoft and confirmed numerous challenges
inLLM-basedsoftwaredevelopment,includingthosespecificallyrelatedtopromptengineering.
Thesestudiesemphasizethepressingneedtotransitionfromthecurrentexperimentalapproachto
asystematicframeworkforpromptdevelopment.Recently,Hassanetal.[24]identifiedcrafting
effectivepromptsasoneofthetenkeySEchallengesandproposedpromptIDEsasapotential
,Vol.1,No.1,Article.Publicationdate:March2025.

<!-- Page 4 -->

4 Chenetal.
Fig.1. Comparisonofthetraditionalsoftwareparadigmandpromptware.
Table1. Traditionalprogramminglanguagevs.naturallanguage.

### Aspect ProgrammingLanguage NaturalLanguage

C1.Structureand Highlystructuredwithrigoroussyntaxand Unstructured,flexible,andopen-ended.
Formalism well-definedsemantics.
C2. Explicitness Explicit;deterministicbehavior. Ambiguousandcontext-dependent;probabilisticbeandDeterminism havior.
C3. Correctness Explicitcorrectnessdefinedbyformalspec- Nouniversalcorrectness;typosorgrammaticalerrors
andQuality ifications;syntaxerrorsarefatal. maynotcausefailuresbutcansubtlyaltermeaning.
solution.Incontrast,thispaperpresentsavisionforpromptwareengineering,encompassingthe
entireSElifecycleforpromptdevelopment.
3 TraditionalSoftwareParadigmvs.Promptware
Beforeexploringtheresearchopportunitiesinpromptwareengineering,wefirstcomparepromptwarewiththetraditionalsoftwareparadigmtohighlightitsuniquecharacteristics.
Figure1illustratesthecomparison.Traditionally,softwareengineerswritecodeusingprogramminglanguagessuchasC,Java,andPython.Dependingonthelanguage,acompilerorinterpreter
translatesthecodeintomachinecode,bytecode,oranintermediaterepresentation.Thetranslated
codeisthenexecutedwithinaruntimeenvironment,whichtypicallyincludescomponentssuch
asexecutionengines,runtimelibraries,memorymanagementsystems,andexceptionhandling
mechanisms.
Incontrast,promptwareengineerswritepromptsprimarilyusingnaturallanguage,eliminating
the need for traditional compilation or interpretation. Instead, an LLM serves as the runtime
environment, interpreting the input prompt and generating responses based on probabilistic
reasoningandpre-trainedknowledge,ofteninreal-time.
Thiscomparisonindicatesthattheuniquecharacteristicsofpromptwareprimarilyarisefromthe
distinctnatureofitslanguageandruntimeenvironment.Inthefollowing,weoutlinethesespecific
characteristics,labeledasC1,C2,...,C10.Asummaryofthecomparisonbetweenpromptware
and the traditional software paradigm in terms of language is presented in Table 1, while the
comparisonregardingtheruntimeenvironmentissummarizedinTable2.
3.1 TraditionalProgrammingLanguagevs.NaturalLanguage
C1.StructureandFormalism:Traditionalprogramminglanguagesarehighlystructured,with
rigoroussyntaxandwell-definedsemanticsthatenforceprecisecodingrules.Incontrast,natural
language is inherently unstructured, flexible, and open-ended, making it difficult to establish
formalizedrulesforpromptconstruction.
,Vol.1,No.1,Article.Publicationdate:March2025.

<!-- Page 5 -->

PromptwareEngineering:SoftwareEngineeringforLLMPromptDevelopment 5
Table2. Traditionalruntimeenvironmentvs.LLM-as-runtimeenvironment.
Aspect TraditionalRuntimeEnvironment LLM-as-RuntimeEnvironment
C4.Determinism Sameinputtypicallyyieldsthesameoutput. Samepromptcanyielddifferentoutputs.
C5. Human-Like Executescodemechanicallyfollowingpre- Exhibitshuman-likecharacteristics(e.g.,contextual
Characteristics definedlogic. reasoningandsocialintelligence).
C6. Capability Well-defined capability boundaries; engi- Unclear,evolvingcapabilityboundaries;execution
Boundaries neersunderstandexecutionrules. functionsasablackbox.
C7. Error Han- Deterministicerrorhandling,withclearer- Implicitandunpredictablefaulttolerance,without
dling rormessages,stacktraces,debuggingmech- expliciterrorsignals.
anisms.
C8. Execution Precise execution control: step through Indirectcontrol:adjustpromptsheuristicallyexperi-
Control code,inspectvariables,usedebuggers. mentally.
C9. Access Con- Strictaccesscontrol:permissions,memory Limitedaccesscontrol:vulnerabletosecurityrisks,
trol protections,sandboxing. lackofrigidexecutionboundaries.
C10. Memory Explicitmemorymanagement:directcon- Nopersistentmemory:contextualprocessingwith-
Management troloverallocationanddeallocation. out long-term memory unless external memory
mechanismsareused.
C2.ExplicitnessandDeterminism:Traditionalprogramminglanguagesareexplicitanddeterministic,meaningthesamecodetypicallyproducesthesameoutput.Thisdeterminismenables
well-establishedtechniquesforanalyzingaspectssuchasdataflow,controlflow,anddependencies.
Incontrast,naturallanguageisambiguousandcontext-dependent,relyingonpriorknowledge,
pragmatics,andcontextualcuesratherthanrigidrules.Itsprobabilisticnaturemakesitdifficultto
ensureconsistentandreliablepromptoutcomes,aswellastosystematicallyanalyzehowprompts
influencemodeloutputs.
C3. Correctness and Quality: In traditional programming, correctness is explicitly defined
throughformalspecifications,andbothfunctionalandnon-functionalqualityattributescanbe
systematicallymeasured.Evenminorsyntaxerrorscanleadtofailuresorbugs.Incontrast,natural
languagelacksauniversalstandardforcorrectnessbutfollowsconventionsandguidelines(such
asgrammarrulesandclarityofintent)thataffectaprompt’seffectiveness.Whileminortypos
orgrammaticalinconsistenciesmaynotalwayscauseimmediatefailures,theycansubtlyalter
meaning,potentiallyleadingtounpredictableorundesiredoutcomes.
3.2 TraditionalRuntimeEnvironmentvs.LLM-as-RuntimeEnvironment
C4.Determinism:Traditionalruntimeenvironmentsaredeterministic,meaningthesameinput
typicallyproducesthesameoutputunderidenticalconditions.Executionfollowswell-definedrules
dictatedbytheprogramminglanguage,systemarchitecture,andcompilerorinterpreterbehavior.
Incontrast,LLMsgenerateresponsesprobabilisticallybasedonlearnedstatisticalpatterns,resulting
ininherentnon-determinism.Thesamepromptcanproducedifferentoutputsacrossexecutions,
posingchallengesforreproducibility,reliability,andconsistencyinpromptwareengineering.
C5.Human-LikeCharacteristics:Traditionalruntimeenvironmentsexecutecodemechanically
withoutsubjectiveinterpretation.Incontrast,LLMsexhibithuman-likecharacteristics,suchas
contextualreasoning,emotionalalignment,andsocialintelligence.Whilethesetraitsenhance
flexibility,theyintroducechallengesincontrol,intentalignment,andreliability.LLMsmaygenerate
responsesinfluencedbybiases,emotionaltone,orimplicitassumptions,makingpromptwareharder
tostabilize,predict,andinterpret.
C6. Capability Boundaries: Traditional runtime environments have well-defined capability
boundaries,withexecutiongovernedbyexplicitrulesandformalmodels.Engineerscananalyze
andpredictsystembehaviorbasedonwell-documentedspecifications.Incontrast,LLMshave
,Vol.1,No.1,Article.Publicationdate:March2025.

<!-- Page 6 -->

6 Chenetal.
unclearandevolvingcapabilityboundaries,oftenexhibitingemergentbehaviors.Moreover,LLM
executionfunctionsasablackbox—developerslackdirectvisibilityintohowpromptsareinternally
processed,makingitdifficulttopredict,control,orexplainoutcomes.
C7.ErrorHandling:Traditionalruntimeenvironmentshandleerrorsdeterministically,providing
well-definederrormessagesandstacktraces.Errorsareexplicitandfollowstricthandlingprotocols.
Incontrast,LLMsexhibitimplicitandunpredictablefaulttolerance.Insteadofproducingexplicit
errormessages,theyattempttogeneratearesponse,whichmaybemisleading,subtlyincorrect,or
entirelyhallucinated.Thisabsenceofstricterrorsignalingcomplicatespromptwaredebugging
andreliabilityassessment.
C8.ExecutionControl:Traditionalruntimeenvironmentsprovidepreciseexecutioncontrol,
allowingengineerstostepthroughcodelinebyline,inspectvariablestates,andutilizedebugging
tools. In contrast, LLM execution is opaque—engineers can only influence behavior indirectly
throughpromptmodifications.Debuggingisheuristicandexperimental,oftenrelyingoniterative
promptadjustmentsratherthanstructureddebuggingtools.Thislackofsystematicexecution
controlmakesdiagnosingandfixingundesiredbehaviorsmorechallenging.
C9.AccessControl:Traditionalruntimeenvironmentsenforcestrictaccesscontrolsthrough
permissions, memory protections, and sandboxing. In contrast, LLMs lack fine-grained access
control mechanisms, making them vulnerable to security risks such as prompt injection and
unintendedleakageofsensitiveinformation.Ensuringsecurityinpromptwareischallengingdue
toLLMs’inabilitytoenforcerigidexecutionboundariesorrestrictunauthorizeddataaccess.
C10. Memory Management: In traditional runtime environments, memory management is
explicit,withdirectcontroloverallocation,deallocation,andgarbagecollection,ensuringefficient
resourcehandling.Incontrast,LLMslackpersistentmemoryintheconventionalsenseandprocess
inputscontextually,meaningtheydonotretainstateacrossinteractionsunlessexternalmemory
mechanisms(e.g.,databases)areused.Forpromptware,thiscreatesachallengeinmaintaining
continuityandcoherenceacrossprompts,especiallyfortasksrequiringlong-termdependency
trackingorsustainedcontextacrossmultipleinteractions.
4 PromptwareEngineering:Roadmap
Thissectionpresentsaroadmapforpromptwareengineering(asshowninFigure2),coveringkey
SEactivitiesincludingrequirementsengineering,design,implementation,testing,debugging,and
evolution.Foreachactivity,weidentifypromisingresearchopportunities.Tofacilitatereference,
eachopportunityisuniquelylabeledwithacounter,e.g.,O1.Additionally,wespecifywhichaspects
ofpromptware’scharacteristics(C1toC10)needtobeconsideredineachopportunity.
4.1 PromptRequirementsEngineering
Requirementsengineering(RE)servesasthefoundationofsoftwaredevelopment,focusingon
translatinguserneedsintoclear,actionablespecifications.Intherealmofpromptwareengineering,
REinvolvesidentifyingtherequirementsanddefiningthespecificationsforprompts.
O1:LLM-drivenpromptRE(C4,C5,C6,C9).IntraditionalRE,requirementsareprimarily
derivedfromuserneeds.However,inpromptwareengineering,requirementsmustalsoaccountfor
LLMcapabilitiesandconstraints,whichinfluencehowpromptsaredesigned,refined,andvalidated.
First,promptrequirementsmustalignwithanLLM’sreasoningability,languagecomprehension,
anddomainexpertise.However,LLMs’capabilityboundaries(C6)areunpredictableandevolve,
necessitatingadaptiverequirementsthatcanbeiterativelyrefined.Additionally,LLMsexhibitnondeterministicexecution(C4),meaningthesamepromptcanproducedifferentoutputs,complicating
thedefinitionofconsistentandtestablerequirements.
,Vol.1,No.1,Article.Publicationdate:March2025.

<!-- Page 7 -->

PromptwareEngineering:SoftwareEngineeringforLLMPromptDevelopment 7

### O1:LLM-drivenpromptRE C4/C5/C6/C9

O2:Functionalandnon-functionalpromptrequirements C1/C2/C3/C5/C7/C9
PromptRequirements

### Engineering

O3:Multi-objectivepromptrequirementstrade-off C4/C5/C8/C9

### O4:Ambiguity-resilientpromptspecifications C2

O5:Formalizedpromptdesignpatterns C1/C2/C3/C6/C7/C10
O6:Promptdesigntools C1

### PromptDesign


### O7:Promptdesignmetrics C1/C4/C5/C7/C10


### O8:Promptpatternrepositories C3/C6/C9/C10

O9:Prompt-centricprogramminglanguages C1/C2/C3/C5/C7

### O10:Promptcompilation C1/C2/C9


### O11:Prompt-centricIDEs C2/C3/C4/C7/C10


### PromptImplementation O12:Promptoptimization C1/C2/C3

PromptwareEngineering O13:Onlinepromptimplementation C2/C6/C10

### O14:Role-playinginprompts C5/C6

O15:PromptlibrariesandAPIs C1/C2/C9

### O16:Flakytestofprompts C2/C4/C5

O17:Testinputgenerationinprompttesting C1/C4/C5/C6)
O18:Testoracleinprompttesting C1/C2/C3/C4

### PromptTestingand

O19:Testadequacyinprompttesting C1

### Debugging

O20:Unittestingandintegrationtestingofprompts C4/C8

### O21:Non-functionaltesting C5/C9


### O22:Promptdebugging C4/C6/C7/C8/C10

O23:Promptevolutiondrivenbycode,LLM,and

## C1/C4/C5/C6

userfeedback

### PromptEvolution


### O24:Versioningandtraceability C2/C3/C4/C6/C8/C9

Fig. 2. Roadmap for promptware engineering, highlighting key activities alongside associated research
opportunities(O1,O2,etc.)andtherelevantpromptwarecharacteristics(C1toC10)tobeconsideredfor
eachopportunity.
Second, LLMs exhibit human-like characteristics (C5), such as personality [21], biases [42],
emotionalalignment[26],andcontextualreasoning[19].Thesecharacteristicsmustbeexplicitly
accountedforinpromptrequirements,especiallyinculturallysensitiveorethicalapplications.For
example,requirementsshoulddefinetone,formality,andethicalsafeguardstoensureappropriate
andunbiasedinteractions.
Furthermore, prompt requirements must also consider security risks of LLMs (C9). Poorly
designedpromptsmayinadvertentlyexposesensitiveinformationorbevulnerabletoadversarial
manipulation.
Todefineeffectivepromptrequirements,REinpromptwareengineeringcanintegrateinsights
frombothcomputerandsocialsciences,fosteringinterdisciplinarycollaborationamongcomputer
scientists,linguists,andpsychologists.
O2: Functional and non-functional prompt requirements (C1, C2, C3, C5, C7, C9). In
traditionalSE,functionalrequirementsdefinetheexplicittasksasystemmustperform,whilenonfunctionalrequirementsdescribequalityattributessuchasperformance,security,androbustness.
,Vol.1,No.1,Article.Publicationdate:March2025.

<!-- Page 8 -->

8 Chenetal.
Thisdistinctionremainsessentialinpromptwareengineeringbutrequiresadaptationduetothe
open-endedandambiguousnatureofnaturallanguageprompts(C1,C2).
Functional prompt requirements need to ensure clarity, specificity, and context-awareness.
Promptsshouldbedesignedtoexplicitlycommunicatetaskobjectiveswhileminimizingambiguities
(C1,C2).Althoughdeterministiccorrectnessforpromptsisinfeasible,ensuringreliabilityremains
acoreobjective(C3).
Non-functionalrequirements,incontrast,ensurethatpromptsproducesecure,fair,efficient,and
robustbehaviors.Promptsshouldberesistanttobiasamplification,adversarialmanipulation,and
ethicalrisks(C5,C9).Additionally,performanceconstraints,suchasresponselatencyandtoken
efficiency,mustbebalancedagainstqualityandinterpretability.AsLLMsdonotfollowtraditional
error-handlingmechanisms(C7),promptrobustnessmustbeevaluatedunderadversarialconditions
topreventfailuresthatmightotherwisegounnoticed.
DuetotheprobabilisticandevolvingnatureofLLMs,thedefinition,scope,andprioritizationof
functionalandnon-functionalrequirementsmustremainadaptableandbecontinuouslyrefined
throughempiricalvalidation.
O3:Multi-objectivepromptrequirementstrade-off(C4,C5,C8,C9).Promptwareengineering
oftenrequiresbalancingcompetingobjectives,makingtrade-offanalysisacriticalaspectofRE.
Forinstance,role-playingtechniques,whichguideLLMstoassumespecificroles,canenhance
responserelevancebutmayalsoamplifypre-existingbiases[28](C5).Similarly,improvingprompt
clarityandspecificitybyprovidingdetailedinstructionsenhancesoutputqualitybutincreases
tokenconsumption,impactingcomputationalefficiencyandcost.
Addressingthesetrade-offsnecessitatesastructuredframeworkforsystematicallyevaluating
competingpriorities.SinceLLMexecutionisinherentlynon-deterministic(C4)andlacksdirect
executioncontrol(C8),trade-offdecisionsneedtorelyonempiricaltestinganditerativerefinement
ratherthanformalverification.Additionally,promptsecurity(C9)mustbeintegratedintotrade-off
considerationstopreventusabilityandperformanceoptimizationsfromintroducingvulnerabilities
suchaspromptinjectionattacks.
Developingsystematicmethodologiesforbalancingmultiplepromptobjectivesremainsakey
researchchallenge,requiringtheintegrationofmulti-objectiveoptimizationtechniquesintopromptwareengineeringworkflows.
O4:Ambiguity-resilientpromptspecifications(C2).Naturallanguagepromptsareinherently
ambiguous(C2),yetprecisespecificationiscrucialforachievingpredictableandreliableperformance.Traditionalsoftwarespecificationtechniquesareinadequateforpromptwareengineering
becausetheyrelyonformalsyntaxandsemantics,whereaspromptsdependonnaturallanguage,
whichlackstherigornecessaryfordeterministicvalidation.Thischallengehighlightstheneedfor
newspecificationapproachesthatmitigateambiguitywhilepreservingtheadaptabilityrequired
foreffectivepromptdesign.
Onepotentialdirectionisthedevelopmentofsemi-formalorformalspecificationlanguages
specificallytailoredforprompts.Theselanguagescouldintegratestructuredtemplateswithnatural
languageannotationstoimproveclarityandreduceambiguity.Forexample,structuredelements
coulddefinetaskobjectives,constraints,andcontextualdependencies,whilenaturallanguage
annotationsprovideflexibilityandinterpretability.Ahybridapproachlikethiscouldenableautomatedvalidationandconsistencychecks,ensuringthatpromptsadheretodefinedrequirements
andperformreliablyacrossvaryingconditionsandusecases.
,Vol.1,No.1,Article.Publicationdate:March2025.

<!-- Page 9 -->

PromptwareEngineering:SoftwareEngineeringforLLMPromptDevelopment 9
4.2 PromptDesign
Softwaredesigndefinesthearchitecture,components,interfaces,andcharacteristicsofasystemto
ensureitmeetsspecifiedrequirements.Inthecontextofpromptwareengineering,designfocuses
onstructuringandorganizingpromptstoachieveeffectivemodelinteractions.
Current prompt design has primarily been driven by the AI community. Common prompt
structures,suchaszero-shotprompting(directquerieswithoutexamples)[45],few-shotprompting
(providingin-contextexamples)[11],Chain-of-Thought(CoT)prompting(breakingdownreasoning
intointermediatesteps)[46],andRetrieval-AugmentedGeneration(RAG)(incorporatingexternal
knowledgeretrieval)[27],arewidelyusedbutdevelopedempiricallyratherthansystematically.
SEhasalonghistoryofformalizingdesignpatterns,i.e.,reusablesolutionstocommondesign
problems.Adesignpatternprovidesahigh-leveltemplateforaddressingspecificchallengesrather
thanarigidimplementationstructure.Thisconceptcanbeextendedtopromptwareengineering,
whererecurringpromptstructuresandstrategiescanbeclassifiedas‘promptdesignpatterns,’
offeringsystematicframeworksfordesigningeffectiveprompts.
O5:Formalizedpromptdesignpatterns(C1,C2,C3,C6,C7,C10).TheSEcommunitycan
collaboratewithAIresearcherstoformalizeexistingpromptstructuresintowell-defineddesign
patterns.Forexample,few-shotpromptingparallelstheFactorypatterninSE,wherecontextual
examplesactastemplatesforgeneratingoutputs.Similarly,CoTpromptingresemblestheBuilder
pattern,asintermediatestepsareincrementallyconstructedbeforeproducingafinaloutput.
Formalizingthesepatternspromotesstandardization(C1),ensuringconsistentpracticesacross
thefield.Italsoenablessystematicoptimization,improvingpromptqualityandreducingambiguity
(C2,C3).Additionally,standardizationcanhelpdelineateLLMcapabilityboundaries(C6),clarifying
whatdifferentpromptstructurescanandcannotachieve.
Beyondformalizingexistingpatterns,thereisanopportunitytoidentifynewpromptdesign
patternsthroughsystematicexperimentation,empiricalevaluation,andbestpracticedocumentation.Forinstance,recursiveprompting,wheretheoutputofoneiterationservesasinputfor
thenext,couldemergeasadistinctpatternfortasksrequiringsustainedmemorytracking(C10).
Furthermore,integratingfailure-resilientpromptpatternscouldhelpmitigatehallucinationsand
improvefaulttolerance(C7).
O6:Promptdesigntools(C1).JustasSEprovidestoolssuchasUMLdiagramstosupportthe
implementationofdesignpatterns,theSEcommunitycandevelopspecializedtoolsforprompt
design.Thesetoolscouldassistpromptengineersinvisualizing,assembling,andvalidatingprompt
structures(C1),streamliningthedevelopmentprocessandenhancingprompteffectiveness.
O7:Promptdesignmetrics(C1,C4,C5,C7,C10).IntraditionalSE,designqualityistypically
assessed using metrics such as cohesion, coupling, and complexity. Applying similar metrics
topromptdesigncouldestablishastructuredandrigorousevaluationframeworkforprompts.
Cohesioncouldmeasurehoweffectivelythecomponentsofapromptworktogethertoachieve
thedesiredoutcome.Couplingmightevaluatetheextenttowhichapromptdependsonexternal
systems, such as retrieval-based components in RAG. Complexity could assess the structural
intricacyofaprompt(C1)andthecognitiveloaditimposesontheLLM(C5).
Additional prompt-specific metricscould furtherenhanceevaluation.A memory evaluation
metriccouldquantifyhowwellapromptmaintainscontextacrossmultipleturns,ensuringcritical
information persists throughout an interaction (C10). A probabilistic determinism score could
measureoutputvarianceforthesameinput,assessingreliabilityacrossdifferentLLMversions
andtemperaturesettings(C4).Moreover,error-handlingmetricscouldevaluatehoweffectivelya
promptminimizeshallucinationsandambiguousresponses(C7).
,Vol.1,No.1,Article.Publicationdate:March2025.

<!-- Page 10 -->

10 Chenetal.
O8: Prompt pattern repositories (C3, C6, C9, C10). A shared repository of prompt design
patterns,akintothedesignpatterncataloginSE,couldenhanceinnovationandstandardizationin
promptwareengineering.Sucharepositorywouldprovidepromptwareengineerswithacollection
of well-documented, reusable solutions for common challenges, facilitating faster adaptation
anditeration.Byreducingrelianceontrial-and-errorapproaches,thisresourcewouldpromote
consistencyandimprovepromptquality(C3).
Additionally,therepositorycouldincludecapability-awarepromptpatterns,documentingwhich
designsarebestsuitedforspecificLLMfunctionalities(C6).
Securityshouldalsobeacorecomponentofthisrepository(C9).Adedicatedsectiononadversarialrobustnesspatternscouldcatalogtechniquesformitigatingpromptinjectionandunintended
informationleakage.
Finally,patternsforlong-termdependencytracking(e.g.,summarizationpromptsthatmaintain
context across multiple exchanges) could help address LLM statelessness, a key limitation in
multi-turninteractions(C10).
4.3 PromptImplementation
IntraditionalSE,theimplementationphasefocusesonwritingprogramsthattranslatespecifications
intocode.Inthecontextofpromptwareengineering,implementationinvolvescraftingpromptsas
naturallanguageinstructionstobeprocessedbyLLMs.DrawingfromestablishedSEpractices,we
highlightseveralresearchdirectionsthatcouldenhancetheimplementationofprompts.
O9: Prompt-centric programming languages (C1, C2, C3, C5, C7). A key opportunity in
promptwareengineeringisthedevelopmentofprompt-centricprogramminglanguagesdesigned
to structure, manipulate, and manage prompts systematically. While existing frameworks like
LangChainandLiquidprompttemplatessupportchainingandtemplating,theylackformalprogrammingfeaturessuchastypesystems,staticanalysis,anderrorhandling(C1,C3,C7).Traditional
languages,ontheotherhand,arenotwell-suitedforhandlingthenuancesofnaturallanguage.
Aprompt-centriclanguagecouldbridgethisgapbyformalizingpromptconstructsandcontextual
dependencies,reducingambiguity,andimprovingoutputconsistency(C2).Itcouldalsoincorporate
mechanisms for error detection and handling (C7) and support modular prompt creation (C1),
enablingreusablecomponentsthatintegrateseamlesslyintolargersoftwaresystems.Bycombining
human-like interaction with deterministic engineering principles (C5), such a language would
enhancethereliability,scalability,andmaintainabilityofpromptware.
O10:Promptcompilation(C1,C2,C9).Naturallanguageisambiguousandcontext-dependent
(C2),makingitdifficultforLLMstointerpretpromptswithprecision.Thischallengeresembles
a well-known problem in SE, where high-level programming languages must be transformed
intostructured,optimizedmachinecodetoensurereliableexecution.Intraditionalcomputing,
compilersaddressthisissuebysystematicallyanalyzing,refining,andrestructuringcodebeforeit
reachestheprocessor.Inspiredbythisconcept,weenvisionpromptcompilation,aprocessthat
translateshuman-writtenpromptsintowell-defined,optimizedrepresentationsthatLLMscan
processmoreeffectively.
Promptcompilationcaninvolvemultiplestagestoensurethatapromptisbothinformationdenseandlogicallystructured.First,thepromptundergoeslexicalandsyntacticanalysis,whereit
istokenizedandparsedtoextractkeyconcepts,tasks,anddependencies.Thenextstepinvolves
creatingapromptintermediaterepresentation,astructured,language-agnosticformatthatserves
asanintermediarybetweenrawpromptsandLLMexecution.Thisrepresentationenablessystematicanalysisandtransformationoftheprompt,ensuringthatitislogicallysoundandfree
from ambiguity (C2). After the creation of prompt intermediate representation, semantic optimizationrefinesthestructurefurther(C1),makingimplicitlogicexplicit,reorganizingsub-tasks,
,Vol.1,No.1,Article.Publicationdate:March2025.

<!-- Page 11 -->

PromptwareEngineering:SoftwareEngineeringforLLMPromptDevelopment 11
andconvertingnaturallanguageinstructionsintoaclearexecutionplan.Toimproveefficiency,
tokencompressioneliminatesredundancies,reformatsexpressionsforclarity,and,whennecessary,
translatesthepromptintoamorecompactformtoreducecomputationaloverhead.Finally,as
partofthecompilationprocess,securityenhancementsintroduceconstraintsandsafeguards(C9).
Thesepreventpromptinjectionattacksandunintendedoutputs,ensuringthatthepromptisnot
onlyefficientandlogicallysoundbutalsosecureduringexecution,muchlikehowcompilersensure
thatthemachinecodeisrobustandfreefromerrorsbeforeitrunsontheprocessor.
O11:Prompt-centricIDEs(C2,C3,C4,C7,C10).IntraditionalSE,IntegratedDevelopment
Environments (IDEs) facilitate coding, debugging, and testing. A similar opportunity exists in
promptwareengineeringtodevelopprompt-centricIDEs,whichisalsodiscussedinarecentpaper[24].Thesespecializedtoolscouldofferfeatureslikereal-timefeedbackonpromptperformance,
automaticgenerationofpromptvariations,andintegrationwithpromptevaluationmetrics(C3).
Bystreamliningpromptcreationandrefinement,suchtoolscouldsignificantlyreducethetime
andeffortrequiredtoimplementhigh-qualityprompts.
Giventhenon-deterministicnatureofLLMoutputs(C4),theIDEcouldincorporatefeatures
thatassessprobabilisticconsistencyacrosspromptoutputs,helpingengineerstrackvariability
andensurereproducibility.TheIDEcouldalsointegratecontextualcheckstoidentifyambiguities
inprompts(C2),offeringerrormessagestoinformpotentialissues(C7)andsuggestionstomake
themmoreexplicitanddeterministic.Additionally,integrationwithexternalmemorymechanisms
(C10)wouldhelpmaintainthecoherenceofpromptsovertime,especiallyinlong-terminteractions
O12: Prompt optimization (C1, C2, C3). Prompt optimization is a significant challenge in
promptwareengineering.Unliketraditionalsoftwarecode,whichbenefitsfromestablishedanalysis
and optimization tools, prompts are highly context-sensitive (C2), requiring a more nuanced
approachtooptimization.Theoutputsofpromptscanbeinfluencedbysubtlevariationsinwording
(C3),context,andstructure,makingitdifficulttoensureconsistencyandeffectivenessacrossa
broadrangeoftasks.Inpromptoptimization,factorssuchasstructure,tone,contextualinformation,
andtask-specificinstructionsmustbefine-tunedtoimproveoutputs(C1,C2).
Toaddressthesechallenges,search-basedsoftwareengineering(SBSE)methodologies[22]offer
promisingsolutions.SBSEtechniques,suchasgeneticalgorithms,canautomaticallyexploreand
evaluatedifferentpromptconfigurationstoidentifytheoptimalcombinationofelements(suchas
wording,structure,andcontext)thatmaximizeseffectivenessacrossvarioustasks.Byiterating
throughdiversevariations,thesemethodsenhancerobustnessandmitigatetheimpactofsubtle
promptdifferences.Additionally,context-awareoptimizationalgorithmscandynamicallyadjust
thepromptelementsinreal-time,ensuringthatthepromptremainseffectiveevenascontextor
taskrequirementschange.Furthermore,multi-objectiveoptimizationframeworkscanhelpbalance
competingfactorssuchasaccuracy,consistency,andefficiency,providingacomprehensivesolution
forpromptoptimization.
O13:Onlinepromptimplementation(C2,C6,C10).Promptdevelopmentfrequentlyrequires
onlineimplementation,whereresponsesaregeneratedinrealtimewithminimaldelaytoensure
promptuserfeedback[8].Theneedforonlinepromptsstemsfromthedynamicruntimeenvironment(C6),whichcontrastswiththemorerigid,controlledsetupoftraditionalofflinesystems.
Whileonlinesystemsarepreferredfortheirresponsiveness,thetransitionfromofflinetoonline
frameworksisnotalwaysfeasibleduetothecontinuousadaptabilityrequiredinreal-timecontexts.
Theprimarychallengeofonlinepromptimplementationliesineffectivelybalancingreal-time
adaptabilitywithcontextualcoherenceandresponseaccuracy.Unlikeofflinesystemsthatrely
on static prompts, online systems must continuously evolve in response to user input, system
behavior,andfluctuatingenvironmentalfactors.Thisinherentdynamismintroducesdifficultiesin
maintainingtherelevanceandconsistencyofprompts,particularlywhenhandlinglarge-scaleor
,Vol.1,No.1,Article.Publicationdate:March2025.

<!-- Page 12 -->

12 Chenetal.
complexinteractions.Thisareapresentssignificantresearchopportunities,especiallyindeveloping
algorithmscapableoflearningfromreal-timeinteractions.Keyavenuesofexplorationinclude
adaptivepromptgeneration,improvingcontext-awarelanguageunderstanding(C2),andadvancing
long-term memory mechanisms that allow models to retain and recall context across multiple
sessions(C10).
O14:Role-playinginprompts(C5,C6).Role-playingisawidely-adoptedpromptingstrategyfor
enhancingtheutilityofLLMsbysimulatingreal-worldroles[41].Akeychallengeinrole-playing
promptsisspecifyingoptimalroles,whichrequiresadeepunderstandingoftheLLM’shuman-like
characteristicsanditscapabilitiesinrole-playing(C5).Thisunderstandingiscrucialforensuring
bettercontextualunderstandingandengagement.Definingtheserolesalsodemandsabalance
betweenclarityandflexibility—toorigidarolecanlimitthemodel’sresponses,whiletoovaguea
rolecanleadtolossofcontext.Additionally,therolemustbetailoredtotheLLM’scapabilities
(C6),ensuringthatitcaneffectivelyhandlecomplexanddynamicinteractions.
Specifyingsocialrolesinpromptscanalsointroducebiaseslinkedtostereotypespresentin
trainingdata[28].Thisraisesasignificantissue:howcanweuserole-playingtoimproveinteraction
whileminimizingbias?Solutionscouldincluderefiningroledefinitions,applyingbias-mitigation
techniques,andcontinuouslyevaluatingpromptsacrossdiversedemographicandculturalcontexts.
Ethicalguidelinesandfairness-awaremechanismsshouldbeintegratedtoensurerole-playingadds
valuewithoutreinforcingharmfulstereotypes.
O15:PromptlibrariesandAPIs(C1,C2,C9).InSE,reusablecodelibrarieshavesignificantly
enhanceddevelopmentefficiency.Asimilarapproachinpromptwareengineeringcouldinvolve
curatedlibrariesofreusableprompttemplatesforcommontaskssuchassummarization,question
answering,andtranslation.Theselibrarieswouldprovidebaselinepromptsthatengineerscould
easilyadapttosuitspecificneeds.Toensurestandardization,theselibrarieswouldneedtofollow
consistentstructures(C1)andallowforeasycustomizationwhileminimizingambiguity(C2).
However,similartotheopen-sourcesoftwareecosysteminSE,promptengineeringmustaddress
challengesrelatedtocopyrightandlicensing.Recentresearch[37,47]hashighlightedtheneedfor
frameworksthatcandefine,detect,andresolveintellectualpropertyissues.Developinglicensing
modelsthatstrikeabalancebetweenopenaccess,commercialuse,andethicalconsiderationswill
becrucialforthesustainablegrowthofpromptwareengineering.
Standardized prompt APIs for interacting with prompts and LLMs could further streamline
integrationintolargersoftwareecosystems.TheseAPIscouldincludemethodsforpromptassembly
andoutputvalidation,enablingmodular,maintainable,andscalableprompt-basedapplications.To
ensurethesecurityofpromptexecutionandprotectsensitivedata,theseAPIsshouldincorporate
accesscontrolmechanisms(C9)thatdefinewhocanmodifyoraccessspecificpromptconfigurations.
Additionally,thesestandardizedAPIscouldsupportdependencytrackingacrossreusableprompts,
improvingboththemodularityandtraceabilityofthepromptwareengineeringprocess.
4.4 PromptTestingandDebugging
Softwaretestingverifieswhethersoftwarebehavesasexpected,whiledebuggingidentifiesand
resolves issues. In promptware engineering, prompt testing and debugging detect and correct
undesiredbehaviorstriggeredbyprompts.Unliketraditionaltestinganddebugging,whichfocus
ondeterministiccode,prompttestinganddebuggingmusthandlenon-deterministicoutputsand
ambiguousspecifications,introducinguniquechallenges.
O16: Flaky test of prompts (C2, C4, C5). In SE, a flaky test refers to a test that produces
inconsistent results, yielding failures or successes unpredictably across multiple runs without
changestotheunderlyingcode[32].Thisissueisparticularlyprevalentinprompttesting,where
,Vol.1,No.1,Article.Publicationdate:March2025.

<!-- Page 13 -->

PromptwareEngineering:SoftwareEngineeringforLLMPromptDevelopment 13
theprobabilisticnatureofnaturallanguage(C2),combinedwiththenon-deterministicoutputsof
LLMs(C4),createschallengesinensuringconsistenttestresults.
Todeterminewhetheratestpassesorfails,multipleattemptsmaybenecessary,relyingonaggregatedorconsensus-basedassessmentstodistinguishbetweenrandomfluctuationsandgenuine
promptflaws.Onepotentialsolutionistomovebeyondthetraditionalbinarypass/failapproach,
introducing a success threshold (e.g., requiring outputs to be highly similar in at least 80% of
testruns).Whilethisreducestheimpactofrandomvariations,itdoesnotentirelyeliminatethe
uncertaintyassociatedwithflakytests.
Tomitigaterandomness,researchersoftenadjustthetemperatureparameter,whichinfluences
thelevelofcreativityandvariabilityinthegeneratedtext[35].Atemperatureofzerominimizes
randomness, yielding more deterministic outputs. However, even with this setting, LLMs still
exhibitsomedegreeofvariability[35].Moreover,real-worldapplicationstypicallyrequirehigher
temperature settings to encourage more dynamic and creative responses (C5). Testing with a
temperatureofzeromaynotfullyrepresentreal-worldscenarios,leavingflakytestinprompt
testingasasignificantchallenge.Flakytestmethodsforpromptsremainsanopenproblem,and
furtherresearchisneededtodevelopmoredependablesolutions.
O17:Testinputgenerationinprompttesting(C1,C4,C5,C6).Testinputforprompttesting
referstothespecificvaluesassignedtodifferentelements(i.e.,variables)withinaprompt.Inpractice,
promptsmayreceiveinputsfrombothLLMsandothersoftwarecomponents.Forexample,ina
codegenerationscenario,apromptmightincludeataskdescriptionprovidedbyothercomponents,
aswellasfeedbackorcontextualinformationfrompriorLLM-generatedoutputs.Thisinteraction
introduceschallengesfortestinputgenerationinprompttesting.
Specifically,itbecomesdifficulttogeneraterepresentativeandcomprehensivetestdatathat
coverstherangeofpossibleinputsthepromptmightencounterduringactualusage(C1).The
dynamicnatureofinputs,suchaschangingtaskdescriptionsorevolvingcontextfrompriorLLM
outputs(C6),meansthattestinputsmustaccountforawidevarietyofconditions.Additionally,
theinterdependencebetweenpromptsandexternalsoftwarecomponentsaddsanotherlayerof
complexity,astestingrequiresensuringthatboththepromptandthesurroundingsystembehave
cohesivelyandpredictably.
Furthercomplicatingmatters,thevariabilityintroducedbypreviousLLMoutputs(whichmay
differslightlyeachtime,duetofactorslikerandomness)makesithardtoensureconsistenttest
coverage (C4). Test inputs need to be designed to capture this stochastic behavior while still
allowingforreliableevaluationoftheprompt’sfunctionality.Thisdynamicandmultifacetednature
ofprompttestingdemandsrobustinputgenerationstrategiesthatcanhandletheunpredictability
ofreal-worldinteractions.
O18:Testoracleinprompttesting(C1,C2,C3,C4).Thetestoracleproblem,whichinvolves
determiningthecorrectbehaviorinresponsetoaninput,isawell-knownchallengeinsoftware
testing[9].Inprompttesting,atestoracleisamechanismorreferencethatassesseswhetherthe
outputtriggeredbyapromptwithagiventestinputiscorrectoracceptable.Unliketraditional
testing,wheretheexpectedoutputistypicallyclearanddeterministic,prompttestingfacesagreater
challengeduetotheinherentsubjectivityandopen-endednatureofmanyLLMprompts(C1,C2).
Forexample,promptsmightaskthemodeltoprovidehelpfulorpoliteresponsesorelicitcreative
problem-solving.Thesespecificationsareoftenvagueandcontext-dependent,complicatingthe
determinationofa‘correct’output(C3).
Incurrentpromptwarepractices,manualevaluationisoftenusedtoassessoutputcorrectness[34].
Whileeffective,thismethodistime-consumingandsusceptibletohumanbiases.Techniqueslike
multi-reviewerconsensusordouble-blindevaluationscanmitigatethesebiasesbyofferingmore
balanced judgments. An alternative, the LLM-as-a-judge approach, uses one LLM to evaluate
,Vol.1,No.1,Article.Publicationdate:March2025.

<!-- Page 14 -->

14 Chenetal.
another’soutput[13].Whilethismethodcanexpeditetestingbyfilteringoutclearlyincorrect
or inappropriate responses, it may amplify biases if the models share similar training data or
limitations.Therefore,humanoversightremainsessential,particularlyinhigh-stakescontexts.
Metamorphictestingisacommontechniqueusedtoaddressthetraditionaltestoracleproblem.Thismethoddefinesrelationships,knownasmetamorphicrelations,betweenvariationsin
inputandexpectedoutputconsistency[14].Forexample,whentestingapromptforcodegeneration,rephrasingthetaskdescriptionshouldresultinconsistentmodelresponsesiftheprompt
iswell-constructed.Ifsignificantdiscrepanciesarisebetweentherephrasedinputsandoutputs,
it may indicate a flaw in the prompt. However, because LLMs often exhibit non-deterministic
behavior—producingdifferentoutputsforthesameprompt(C4),itisdifficulttoassesswhetherthe
variationisduetopromptinconsistenciesormodelbehavior.Toaddressthis,researchcanfocus
ondevelopingmetamorphictestingtechniquesspecificallydesignedtotesthowsmall,controlled
changesininputinfluenceoutputs,ensuringthatexpectedbehaviorremainsconsistentacross
variations.
O19:Testadequacyinprompttesting(C1).Testadequacyisakeyconceptintraditionalsoftware
testing,usedtoassessthecoverageprovidedbyexistingtests[20].Inthiscontext,itmeasureshow
thoroughlyvariousaspectsofthesoftware,suchasdifferentcodepathsorfunctionalareas,are
tested.Inprompttesting,adequacyshiftsfocustoevaluatinghowwelldifferentcomponentsofa
prompt,suchastaskdescriptions,context,examples,andformattingrequirements,arecovered.
Unliketraditionaltesting,whichoftenreliesonmetricslikebranchcoverage,thesemethodsare
notdirectlyapplicabletoprompttestingduetotheunstructuredandflexiblenatureofnatural
language.Onewaytoimprovetestadequacyisbydevelopingformalizedstructures(C1)forprompt
components,whichwouldprovideaclearerbasisforestablishingcoveragemetrics.
O20:Unittestingandintegrationtestingofprompts(C4,C8).Unittestinginvolvesevaluating
individual prompts or closely related sets of prompts in isolation to ensure that each prompt
functionsasintended.Thisapproachverifiesthateachpromptmeetsitsspecificrequirements
withoutinterferencefromotherpromptsorexternalcontexts.However,incomplexLLM-based
softwre,promptsareoftenchainedtogether[30],asinconversationflowswhereeachresponse
dependsonpreviousinputs.Integrationtestingensuresthattheseinterconnectedpromptsproduce
coherent,accurate,andcontextuallyconsistentoutputswhenusedtogether.Errorsthatmaygo
undetectedduringunittestingcansurfaceonlywhenpromptsinteractinreal-worldconditions,
highlightingtheimportanceofintegrationtestingtoverifythesystem’soverallbehavior.Since
determinismandexecutioncontrolareoftendifficulttoguaranteeinLLMs(C4,C8),enhancing
integrationtestingmightinvolvedevelopingtoolsthatgivedevelopersmorecontrolovertheflow
ofexecution,includingdebuggingtoolsthatmakeinternalprocessesmoreobservable.Thiswill
helpidentifywhereunexpectedresultsemergeduringpromptinteractions.
O21:Non-functionaltesting(C5,C9):AsLLM-basedsystemsareincreasinglyadoptedinhumancentric applications, ensuring that non-functional requirements such as fairness, security, and
privacyaremetisbecomingcriticallyimportant.Non-functionaltestinghelpsverifythatthese
aspectsareaddressedthoroughly.
Fairnesstesting.SinceLLMsexhibithuman-likecharacteristics(C5),theymayalsodisplayhumanlikesocialbiasesordiscriminatorytendencieswhenpromptedwithinappropriateinputs[28,42].
Thesebiasescanleadtotheunfairtreatmentofspecificgroupsorperpetuateharmfulstereotypes
related to various roles. If left unchecked, the repeated use of biased responses can normalize
thesestereotypes,subtlyinfluencingpublicperceptionandreinforcingsocialinequalities.Fairness
testingaimstoidentifybiasescausedbyprompts.
,Vol.1,No.1,Article.Publicationdate:March2025.

<!-- Page 15 -->

PromptwareEngineering:SoftwareEngineeringforLLMPromptDevelopment 15
Securitytesting.Securitytestingaimstoidentifyvulnerabilitiesthatcouldcompromisethesafety
andintegrityofLLM-basedsystems.Forexample,adversarialattackslikepromptinjection(C9)
exploitweaknessesbycraftingmaliciousinputstomanipulatetheLLMorbypasssafeguards[16].
Privacytesting.GiventhatLLM-basedsoftwareoftenhandlessensitiveinformation,ensuring
privacy is crucial. Prompts must undergo rigorous testing to ensure they do not inadvertently
exposeprivateorconfidentialdata(C9).Forexample,ifapromptpromptsanLLMtodisclose
sensitiveinformation,whetherfromuserinputorinternaltrainingdata,itconstitutesaserious
privacybreach.
O22:Promptdebugging(C4,C6,C7,C8,C10).Poorlyconstructedorambiguouspromptsmay
resultinincorrectorundesirableoutputs.Promptdebuggingfocusesonidentifyingandresolving
theseissues.
Aprimarychallengeinpromptdebuggingisreproducingbugs,asLLMsoftenexhibitflakiness,
i.e., identical prompts can produce inconsistent outputs (C4). This variability complicates bug
reproduction,especiallywhencontext,recentinteractions,ormodelupdateschangeoutputs.To
addressthis,robustdebuggingmechanismsareessential.Toolsthatcaptureandreplaythesystem’s
stateduringpromptexecution,includingmodelconfigurations,inputcontext,andreproducibility
factorsliketemperaturesettings,canhelpdevelopersreproducebugsandanalyzediscrepancies
acrossdifferentconfigurations.
Once a bug is reproduced, identifying its root cause, i.e., whether in the prompt design or
themodel’sbehavior,becomescrucial.Theblack-boxnatureofLLMs(C6)complicatesthis,as
developerslackvisibilityintothemodel’sinternalprocesses.Additionally,theabsenceofexecution
control(C8)meansdeveloperscannotinspectintermediatestates.Asaresult,promptebugging
oftenreliesonindirecttechniqueslikepromptdecompositionandablationstudies,modifyingparts
oftheprompttoisolatethecause.However,theinherentflakinessofLLMs(C4)makeslocalization
difficult,asthesamepromptmayyielddifferentresultsacrossruns.
Afterlocalization,thenextchallengeisbugfixing,wheretheproblematicsectionoftheprompt
is adjusted while preserving its intended functionality. While bug fixes may resolve one issue,
theycaninadvertentlyintroducenewones,especiallyinmulti-steporCoTprompts.Tomitigate
this,automatedtoolsshouldbeimplementedtosuggestandverifypromptmodificationsbased
onknownpatternsoffailure.Thispattern-basedapproachwouldhelpdevelopersapplyproven
solutionstorecurringproblems,therebystreamliningthedebuggingprocessandreducingerrors.
Additionally,incorporatingerror-handlingmechanismswithinLLMscouldenhancetheirability
toprovideexplicitfeedbackwhenanissuearises.Insteadofleavingdeveloperstoinfertheproblem,
LLMscouldflaguncertaintiesorambiguitiesinthepromptandsuggestimprovements.Thiswould
addressthelackofstructurederrormessages(C7)andmaketheidentificationandresolutionof
issuesmoreefficient.
Finally,forcomplex,multi-stepprompts,maintainingcontinuityacrossinteractionsiscrucial.
SinceLLMslackpersistentmemory(C10),externalmechanismsforcontextualmemorycouldbe
usedtomaintaincoherenceacrossmultipleexchanges.Thiswouldhelpreduceerrorscausedby
thelossofcontextandensuresmootherdebugging,particularlyforlongerchainsofreasoning.
4.5 PromptEvolution
Softwareevolutiontypicallyinvolvesiterativedevelopmentandupdates.Similarly,promptsrequire
proactiveadaptationandcontinuousrefinement,especiallyindynamicenvironments.
O23:Promptevolutiondrivenbycode,LLM,anduserfeedback(C1,C4,C5,C6).Prompt
evolutioninLLM-basedsoftwareisinfluencedbycodechanges,LLMupdates,anduserfeedback.
Unlike programming languages, prompts lack explicit syntax rules, making adaptation more
challenging(C1).Additionally,LLMsgenerateresponsesprobabilistically,complicatingconsistent
,Vol.1,No.1,Article.Publicationdate:March2025.

<!-- Page 16 -->

16 Chenetal.
behaviorfrompromptmodifications(C4).AsLLMsevolvewithupdatesandnewtrainingdata,
promptsmustberevalidatedtopreventperformancedegradation(C6).LLMs’human-likereasoning
(C5) also introduces susceptibility to implicit biases and shifting linguistic patterns, requiring
trackingandadaptation.
Tostreamlinepromptevolution,researchersandpractitionerscandevelopcontext-awareprompt
managementsystemsthatautomaticallydetectshiftsincode,modelbehavior,anduserfeedback,
adjustingpromptsaccordingly.Oneapproachistointroducestructuredprompttemplatesand
metadatatrackingtoimprovecontroloverpromptmodifications.Additionally,automatedvalidation
mechanismscanassesswhetherpromptadjustmentsyieldreliableresults.
O24:Versioningandtraceability(C2,C3,C4,C6,C8,C9).IntraditionalSE,versioncontrol
systemslikeGitareessentialfortrackingcodechangesandmaintainingtraceability.Similarly,
promptware engineering would benefit from specialized version control tools to track prompt
iterations,documentmodifications,andensureaccountability(C3).Suchsystemswouldenable
engineerstocomparepromptversions,ensuringconsistentrefinementandstructuredevolution.
SincepromptsinteractdynamicallywithevolvingLLMs(C6),maintainingcompatibilitybetween
promptversionsandsoftwareupgradesiscritical.Anymodifications,especiallythoseprompted
byLLMupdates,codechanges,userfeedback,orshiftingusecases,shouldbethoroughlydocumented.Giventhenon-deterministicnatureofLLMexecution(C4),preciseversioningstrategies
arenecessarytomitigateunintendedvariationsinmodelbehavior.
Tosupportthese,promptversioningsystemsshouldincorporatedetailedchangelogs,update
metadata,andexplicitcompatibilityrequirements,mirroringtheprinciplesofsemanticversioning
intraditionalsoftware(C2).Additionally,automateddiff-checkingmechanismscouldhighlight
changesinpromptsandtheirimpactonLLMresponses,improvingreliability.
Furthermore,accesscontrolmechanismsshouldbeintegratedintopromptmanagementsystems
(C9) to ensure that modifications are authorized and traceable, preventing unauthorized edits
orsecurityvulnerabilities.Sincedebuggingpromptsremainsexperimentalandlacksstructured
debuggingtools(C8),versioningshouldsupportrollbackmechanismstorestorepreviouslystable
versionswhenregressionsoccur.
5 Conclusion
Inthispaper,wehighlight10uniquecharacteristicsofpromptware,whicharisefromitsnatural
language programming and the use of LLMs as a runtime, in contrast to traditional software
paradigms.Thesecharacteristicsintroducespecificchallengesthatcurrentexperimental,trial-anderrorpracticesfailtoadequatelyaddress.Toovercometheselimitations,weproposepromptware
engineering,asystematicmethodologythatintegratesestablishedsoftwareengineeringprinciples
intopromptcreationandoptimization,movingbeyondthead-hocmethodscurrentlyinuse.To
supportthisvision,wepresentaroadmapwith24researchopportunitiesacrosscriticalareassuch
aspromptrequirementsengineering,design,implementation,testing,debugging,andevolution.

### References

[1] 2025. Enhance results with prompt engineering strategies. https://platform.openai.com/docs/guides/promptengineering.
[2] 2025.IntroducingClaude.https://www.anthropic.com/news/introducing-claude.
[3] 2025.LangChainprompttemplates.https://python.langchain.com/docs/concepts/prompt_templates/.
[4] 2025.Liquidprompt’sdocumentation.https://liquidprompt.readthedocs.io/en/stable/.
[5] 2025. Prompt engineering best practices for ChatGPT. https://help.openai.com/en/articles/10032626-promptengineering-best-practices-for-chatgpt.
[6] 2025.Prompting.https://www.llama.com/docs/how-to-guides/prompting/.
,Vol.1,No.1,Article.Publicationdate:March2025.

<!-- Page 17 -->

PromptwareEngineering:SoftwareEngineeringforLLMPromptDevelopment 17
[7] JoshAchiam,StevenAdler,SandhiniAgarwal,LamaAhmad,IlgeAkkaya,FlorenciaLeoniAleman,DiogoAlmeida,
JankoAltenschmidt,SamAltman,ShyamalAnadkat,etal.2023.GPT-4technicalreport.arXivpreprintarXiv:2303.08774
(2023).
[8] NadiaAlshahwan,MarkHarman,InnaHarper,AlexandruMarginean,ShubhoSengupta,andEddyWang.2024.
AssuredLLM-basedsoftwareengineering.InProceedingsofthe2ndIEEE/ACMInternationalWorkshoponInterpretability,
Robustness,andBenchmarkinginNeuralSoftwareEngineering,InteNSE@ICSE2024.7–12.
[9] EarlT.Barr,MarkHarman,PhilMcMinn,MuzammilShahbaz,andShinYoo.2015.Theoracleprobleminsoftware
testing:Asurvey.IEEETransactionsonSoftwareEngineering41,5(2015),507–525.
[10] XiaoBi,DeliChen,GuantingChen,ShanhuangChen,DamaiDai,ChengqiDeng,HonghuiDing,KaiDong,Qiushi
Du,ZheFu,etal.2024. DeepseekLLM:Scalingopen-sourcelanguagemodelswithlongtermism. arXivpreprint
arXiv:2401.02954(2024).
[11] TomB.Brown,BenjaminMann,NickRyder,MelanieSubbiah,JaredKaplan,PrafullaDhariwal,ArvindNeelakantan,
PranavShyam,GirishSastry,AmandaAskell,SandhiniAgarwal,ArielHerbert-Voss,GretchenKrueger,TomHenighan,
RewonChild,AdityaRamesh,DanielM.Ziegler,JeffreyWu,ClemensWinter,ChristopherHesse,MarkChen,Eric
Sigler,MateuszLitwin,ScottGray,BenjaminChess,JackClark,ChristopherBerner,SamMcCandlish,AlecRadford,
IlyaSutskever,andDarioAmodei.2020.Languagemodelsarefew-shotlearners.InProceedingsofAdvancesinNeural
InformationProcessingSystems33:AnnualConferenceonNeuralInformationProcessingSystems2020,NeurIPS2020.
[12] YupengChang,XuWang,JindongWang,YuanWu,LinyiYang,KaijieZhu,HaoChen,XiaoyuanYi,CunxiangWang,
YidongWang,etal.2024.Asurveyonevaluationoflargelanguagemodels.ACMTransactionsonIntelligentSystems
andTechnology15,3(2024),1–45.
[13] GuimingHardyChen,ShunianChen,ZicheLiu,FengJiang,andBenyouWang.2024.HumansorLLMsasthejudge?
Astudyonjudgementbias.InProceedingsofthe2024ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,
EMNLP2024,YaserAl-Onaizan,MohitBansal,andYun-NungChen(Eds.).8301–8327.
[14] TsongYuehChen,Fei-ChingKuo,HuaiLiu,Pak-LokPoon,DaveTowey,T.H.Tse,andZhiQuanZhou.2018.
Metamorphictesting:Areviewofchallengesandopportunities.Comput.Surveys51,1(2018),4:1–4:27.
[15] GabrieleDeVito.2024.AssessinghealthcaresoftwarebuiltusingIoTandLLMtechnologies.InProceedingsofthe28th
InternationalConferenceonEvaluationandAssessmentinSoftwareEngineering.476–481.
[16] EdoardoDebenedetti,JieZhang,MislavBalunovic,LucaBeurer-Kellner,MarcFischer,andFlorianTramèr.2024.
AgentDojo:AdynamicenvironmenttoevaluatepromptinjectionattacksanddefensesforLLMagents.InProceedings
oftheThirty-eightConferenceonNeuralInformationProcessing,NeurIPS2024,SystemsDatasetsandBenchmarksTrack.
[17] MateuszDolata,NorbertLange,andGerhardSchwabe.2024.Developmentintimesofhype:Howfreelancersexplore
GenerativeAI?.InProceedingsoftheIEEE/ACM46thInternationalConferenceonSoftwareEngineering,ICSE2024.1–13.
[18] AngelaFan,BelizGokkaya,MarkHarman,MityaLyubarskiy,ShubhoSengupta,ShinYoo,andJieM.Zhang.2023.
Largelanguagemodelsforsoftwareengineering:Surveyandopenproblems.InProceedingsofIEEE/ACMInternational
ConferenceonSoftwareEngineering:FutureofSoftwareEngineering,ICSE-FoSE2023.31–53.
[19] TylerGiallanzaandDeclanIainCampbell.2024.Context-sensitivesemanticreasoninginlargelanguagemodels.In
ICLR2024WorkshoponRepresentationalAlignment.
[20] MilosGligoric,AlexGroce,ChaoqiangZhang,RohanSharma,MohammadAminAlipour,andDarkoMarinov.2013.
Comparingnon-adequatetestsuitesusingcoveragecriteria.InProceedingsofthe2013InternationalSymposiumon
SoftwareTestingandAnalysis,ISSTA2013.302–313.
[21] YaoqiGuo,ZhenpengChen,JieM.Zhang,YangLiu,andYunMa.2024. Personality-guidedcodegenerationusing
largelanguagemodels.CoRRabs/2411.00006(2024).
[22] MarkHarmanandBryanFJones.2001.Search-basedsoftwareengineering.InformationandsoftwareTechnology43,
14(2001),833–839.
[23] AhmedE.Hassan,DayiLin,GopiKrishnanRajbahadur,KeheliyaGallaba,FilipeRoseiroCôgo,BoyuanChen,Haoxiang
Zhang,KishanthanThangarajah,GustavoAnsaldiOliva,Jiahuei(Justina)Lin,WaliMohammadAbdullah,andZhen
Ming(Jack)Jiang.2024. Rethinkingsoftwareengineeringintheeraoffoundationmodels:Acuratedcatalogueof
challengesinthedevelopmentoftrustworthyFMware.InCompanionProceedingsofthe32ndACMInternational
ConferenceontheFoundationsofSoftwareEngineering,FSE2024.294–305.
[24] AhmedEHassan,GustavoAOliva,DayiLin,BoyuanChen,andZhenMingJiang.2024. Rethinkingsoftware
engineeringinthefoundationmodelera:Fromtask-drivenAICopilotstogoal-drivenAIpairprogrammers.arXiv
preprintarXiv:2404.10225(2024).
[25] XinyiHou,YanjieZhao,YueLiu,ZhouYang,KailongWang,LiLi,XiapuLuo,DavidLo,JohnGrundy,andHaoyu
Wang.2024.Largelanguagemodelsforsoftwareengineering:Asystematicliteraturereview.ACMTransactionson
SoftwareEngineeringandMethodology33,8(2024),1–79.
[26] Jen-tseHuang,ManHoLam,EricJohnLi,ShujieRen,WenxuanWang,WenxiangJiao,ZhaopengTu,andMichael
Lyu.2024. Apatheticorempathetic?EvaluatingLLMs’emotionalalignmentswithhumans.InProceedingsofthe
,Vol.1,No.1,Article.Publicationdate:March2025.

<!-- Page 18 -->

18 Chenetal.
Thirty-eighthAnnualConferenceonNeuralInformationProcessingSystems.
[27] PatrickS.H.Lewis,EthanPerez,AleksandraPiktus,FabioPetroni,VladimirKarpukhin,NamanGoyal,Heinrich
Küttler,MikeLewis,Wen-tauYih,TimRocktäschel,SebastianRiedel,andDouweKiela.2020.Retrieval-augmented
generationforknowledge-intensiveNLPtasks.InProceedingsofAdvancesinNeuralInformationProcessingSystems33:
AnnualConferenceonNeuralInformationProcessingSystems2020,NeurIPS2020.
[28] XinyueLi,ZhenpengChen,JieM.Zhang,YilingLou,TianlinLi,WeisongSun,YangLiu,andXuanzheLiu.2024.
Benchmarkingbiasinlargelanguagemodelsduringrole-playing.CoRRabs/2411.00585(2024).
[29] YinhengLi,ShaofeiWang,HanDing,andHangChen.2023.Largelanguagemodelsinfinance:Asurvey.InProceedings
ofthefourthACMinternationalconferenceonAIinfinance.374–382.
[30] JennyT.Liang,MelissaLin,NikithaRao,andBradA.Myers.2024.Promptsareprogramstoo!Understandinghow
developersbuildsoftwarecontainingprompts.CoRRabs/2409.12447(2024).
[31] JunweiLiu,KaixinWang,YixuanChen,XinPeng,ZhenpengChen,LingmingZhang,andYilingLou.2024. Large
languagemodel-basedagentsforsoftwareengineering:Asurvey.arXivpreprintarXiv:2409.02977(2024).
[32] QingzhouLuo,FarahHariri,LamyaaEloussi,andDarkoMarinov.2014. Anempiricalanalysisofflakytests.In
Proceedingsofthe22ndACMSIGSOFTinternationalsymposiumonfoundationsofsoftwareengineering,FSE2014.
643–653.
[33] AlinaMailach,SebastianSimon,JohannesDorn,andNorbertSiegmund.2025.Practitioners’discussionsonbuilding
LLM-basedapplicationsforproduction.InProceedingsoftheIEEE/ACM4thInternationalConferenceonAIEngineering
-SoftwareEngineeringforAI,CAIN2025.
[34] NadiaNahar,ChristianKästner,JennaButler,ChrisParnin,ThomasZimmermann,andChristianBird.2024.Beyond
thecomfortzone:EmergingsolutionstoovercomechallengesinintegratingLLMsintosoftwareproducts. arXiv
preprintarXiv:2410.12071(2024).
[35] ShuyinOuyang,JieMZhang,MarkHarman,andMengWang.2024.Anempiricalstudyofthenon-determinismof
ChatGPTincodegeneration.ACMTransactionsonSoftwareEngineeringandMethodology(2024).
[36] ChrisParnin,GustavoSoares,RahulPandita,SumitGulwani,JessicaRich,andAustinZHenley.2023.Buildingyour
ownproductCopilot:Challenges,opportunities,andneeds.arXivpreprintarXiv:2312.14231(2023).
[37] HualiRen,AnliYan,Chong-zhiGao,HongyangYan,ZhenxinZhang,andJinLi.2024.Areyoucopyingmyprompt?
ProtectingthecopyrightofvisionpromptforVPaaSviawatermark.CoRRabs/2405.15161(2024).
[38] PranabSahoo,AyushKumarSingh,SriparnaSaha,VinijaJain,SamratMondal,andAmanChadha.2024.Asystematic
surveyofpromptengineeringinlargelanguagemodels:Techniquesandapplications.arXivpreprintarXiv:2402.07927
(2024).
[39] MahanTafreshipour,AaronImani,EricHuang,EduardoAlmeida,ThomasZimmermann,andIftekharAhmed.2025.
Promptinginthewild:Anempiricalstudyofpromptevolutioninsoftwarerepositories.InProceedingsofthe22nd
IEEE/ACMInternationalConferenceonMiningSoftwareRepositories,MSR2025.
[40] HugoTouvron,ThibautLavril,GautierIzacard,XavierMartinet,Marie-AnneLachaux,TimothéeLacroix,Baptiste
Rozière,NamanGoyal,EricHambro,FaisalAzhar,etal.2023.Llama:Openandefficientfoundationlanguagemodels.
arXivpreprintarXiv:2302.13971(2023).
[41] Yu-MinTseng,Yu-ChaoHuang,Teng-YunHsiao,Yu-ChingHsu,Jia-YinFoo,Chao-WeiHuang,andYun-NungChen.

## Twotalesofpersonainllms:Asurveyofrole-playingandpersonalization. arXivpreprintarXiv:2406.01171

(2024).
[42] YuxuanWan,WenxuanWang,PinjiaHe,JiazhenGu,HaonanBai,andMichaelR.Lyu.2023.BiasAsker:Measuringthe
biasinconversationalAIsystem.InProceedingsofthe31stACMJointEuropeanSoftwareEngineeringConferenceand
SymposiumontheFoundationsofSoftwareEngineering,ESEC/FSE2023.515–527.
[43] JunjieWang,YuchaoHuang,ChunyangChen,ZheLiu,SongWang,andQingWang.2024.Softwaretestingwithlarge
languagemodels:Survey,landscape,andvision.IEEETransactionsonSoftwareEngineering(2024).
[44] ShenWang,TianlongXu,HangLi,ChaoliZhang,JoleenLiang,JiliangTang,PhilipSYu,andQingsongWen.2024.
Largelanguagemodelsforeducation:Asurveyandoutlook.arXivpreprintarXiv:2403.18105(2024).
[45] WeiWang,VincentWZheng,HanYu,andChunyanMiao.2019.Asurveyofzero-shotlearning:Settings,methods,
andapplications.ACMTransactionsonIntelligentSystemsandTechnology(TIST)10,2(2019),1–37.
[46] JasonWei,XuezhiWang,DaleSchuurmans,MaartenBosma,BrianIchter,FeiXia,EdH.Chi,QuocV.Le,andDenny
Zhou.2022.Chain-of-thoughtpromptingelicitsreasoninginlargelanguagemodels.InProceedingsofAdvancesin
NeuralInformationProcessingSystems35:AnnualConferenceonNeuralInformationProcessingSystems2022,NeurIPS
2022.
[47] YongYang,XuhongZhang,YiJiang,XiChen,HaoyuWang,ShoulingJi,andZonghuiWang.2024. PRSA:Prompt
reversestealingattacksagainstlargelanguagemodels.CoRRabs/2402.19200(2024).

### Received2025;revised2025;accepted2025

,Vol.1,No.1,Article.Publicationdate:March2025.