---
title: "Dialogue State Tracking"
original_file: "./Dialogue_State_Tracking.pdf"
document_type: "research"
conversion_date: "2025-11-29"
topics: ["llm", "rag", "chain-of-thought", "fine-tuning", "evaluation"]
keywords: ["cid", "style", "page", "image", "painting", "dublin", "ireland", "structure", "content", "appearance"]
summary: "<!-- Page 1 -->

DiffArtist: Towards Structure and Appearance Controllable Image

### Stylization


### RuixiangJiang ChangWenChen

rui-x.jiang@connect.polyu.hk chen.changwen@polyu.edu.hk
TheHongKongPolytechnicUniversity TheHongKongPolytechnicUniversity

### HongKong,China HongKong,China


### Abstract Structure style strength


### Artisticstylesaredefinedbyboththeirstructuralandappearance

elements.Existingneuralstylizationtechniquesprimarilyfocuson
transferringappearance-levelfeaturessuchasco"
related_documents: []
---

# Dialogue State Tracking

<!-- Page 1 -->

DiffArtist: Towards Structure and Appearance Controllable Image

### Stylization


### RuixiangJiang ChangWenChen

rui-x.jiang@connect.polyu.hk chen.changwen@polyu.edu.hk
TheHongKongPolytechnicUniversity TheHongKongPolytechnicUniversity

### HongKong,China HongKong,China


### Abstract Structure style strength


### Artisticstylesaredefinedbyboththeirstructuralandappearance

elements.Existingneuralstylizationtechniquesprimarilyfocuson
transferringappearance-levelfeaturessuchascolorandtexture,
oftenneglectingtheequallycrucialaspectofstructuralstylization.
Toaddressthisgap,weintroduceDiffArtist,thefirst2Dstylizationmethodtoofferfine-grained,simultaneouscontroloverboth
structureandappearancestylestrength.Thisdualcontrollability
isachievedbyrepresentingstructureandappearancegeneration
as separate diffusion processes, necessitating no further tuning
oradditionaladapters.Toproperlyevaluatethisnewcapability
ofdualstylization,wefurtherproposeaMultimodalLLM-based
stylizationevaluatorthatalignssignificantlybetterwithhuman
preferencesthanexistingmetrics.Extensiveanalysisshowsthat
DiffArtistachievessuperiorstylefidelityanddual-controllability
comparedtostate-of-the-artmethods.Itstext-driven,training-free
designandunprecedenteddualcontrollabilitymakeitapowerfulandinteractivetoolforvariouscreativeapplications.Project
homepage:https://diffusionartist.github.io.

### CCSConcepts

â€¢Computingmethodologiesâ†’Appearanceandtexturerepresentations;Imagemanipulation;â€¢Appliedcomputingâ†’Fine
arts.

### Keywords

Generativeart;Text-drivenstylization;Structureandappearance;
Stylizationevaluation;MultimodalLLMapplications

### ACMReferenceFormat:

RuixiangJiangandChangWenChen.2025.DiffArtist:TowardsStructure
andAppearanceControllableImageStylization.InProceedingsofthe33rd
ACMInternationalConferenceonMultimedia(MMâ€™25),October27â€“31,2025,
Dublin,Ireland.ACM,NewYork,NY,USA,24pages.https://doi.org/10.1145/
3746027.3755010
1 Introduction
Theessenceofanartisticstyleliesnotonlyinitsappearanceâ€”color
andtextureâ€”butalsoitsstructureâ€”geometryandcomposition[17,
18,30].Forexample,thefragmentationoffiguresinPicassoâ€™sCubistworksandtheundulatingskyinVanGoghâ€™sâ€œStarryNightâ€,
eachcontributingdistinctlytotheirartisticexpression.Existing
ThisworkislicensedunderaCreativeCommonsAttribution4.0InternationalLicense.

### MMâ€™25,Dublin,Ireland

Â©2025Copyrightheldbytheowner/author(s).

## Acmisbn979-8-4007-2035-2/2025/10

https://doi.org/10.1145/3746027.3755010
htgnerts
elyts
ecnaraeppA
Figure1:DiffArtistenablesdisentangledandfine-grained
controlofstylestrengthfromtwoorthogonalperspectives:
structureandappearance.Thestylepromptisâ€œTheDream,
byPicasso.â€
neuralstylizationapproaches[10,11,24,25,37,56]predominantly
focusonmanipulatingappearance-levelattributes.Thestructural
elementsinthesourceimage,however,areoftenviewedaspartof
â€œcontentâ€andareexplicitlypreserved[55,59,61,62].Thisfundamentallimitationpreventsthemfromcapturingthetrueessence
ofanartstyle,severelyrestrictingtheirexpressivepotentialand
customizability.

### Therootofthislimitationliesintheinherentcomplexityof

structuralstylization.Unlikeappearance-styletransfer,structural
stylizationrequiresadelicatebalancebetweenthreecompetingobjectives:(1)aligningwiththetargetstyle,(2)harmonizingwiththe
sourceimageâ€™scomposition,and(3)preservingthecoresemantic
integrityofthecontent.Theseobjectivesoperateatahigh-level
semanticplane,exposingacriticalgapincurrentmethods.While
descriptors like AdaIN [25] and Gram loss [15] may suffice for
appearance-stylemodeling,thelackofadequatestructurerepresentationandstructure-styleevaluatorspresentssignificantobstacles
5202
guA
72
]VC.sc[
4v24851.7042:viXra

<!-- Page 2 -->

MMâ€™25,October27â€“31,2025,Dublin,Ireland RuixiangJiangandChangWenChen
inthedevelopmentofstructuralstylizationtechniques.Thischal- (3) WepresentanovelMLLM-basedevaluatorforevaluating
lengeisamplifiedinrecentmultimodalgenerationscenarios,where structureandappearanceinartisticstylization,whichaligns
astylepromptoffersnoexplicitvisualtemplate[10,22,24,53]. betterwithhumanperception.
TheadventofDiffusionModels(DMs)offersapowerfulnew (4) ExtensiveexperimentsdemonstratethatDiffArtistachieves
paradigmforachievingthisdualcontrollability,astheirgenerative superiorstylizationfidelity,controleditability,anddisentansamplingprocessenablesfargreaterstructuralandappearance glementthanexistingapproaches.
diversitythanpriormethods.Thisreframesstylizationasaconditionalgenerationtask,guidedbyasourceimageandastyleprompt
2 RelatedWorks
(imageortext).However,thisgenerativepowercomeswithacritical,unaddressedchallenge:thediffusionprocessinherentlyentan- TheStylizationofStructureand/orAppearance.Structureand
glesthegenerationofstructureandappearance.Weidentifythis appearancecollectivelydefinethestyleofavisualrepresentation.
asafundamentalStructure-Appearance(S-A)Tradeoff:intensi- Existingneuralstylizationmethods[10,11,24,25,37,56]haveprefyingstructuralchangesinadvertentlycorruptsappearancestyle, dominantlyfocusedonappearancestylization,generallyachieved
whilestrengtheningappearancewashesoutstructuraltransforma- viaanencoder-decoderarchitecture.Onlyafewpapers[33,71]
tions.Thistradeoffdirectlyexplainsthecorefailuresofexisting focusontransferringstructuralstylecomponentsbetween2Dimdiffusion-basedmethods,whichareeitherpronetoseverecontent ages.Thisisusuallyaccomplishedbycalculatingacorrespondence
degradation[8,44,55]orsufferfromweak,constrainedstyliza- betweencontentandstyleimageandperforminganon-rigiddetion[58,62].Achievingdualcontrollabilityinthestylizationthus formation.However,thesemethodstypicallyoperateonimages
remainsanopenquestion. inspecificdomainslikeportraits,requiringanin-domainstylized
Tosolvethis,weintroduceDiffArtist,thefirstframeworkto reference.Moreover,theydonotenabledualcontrollability.Very
ourknowledgethatoffersexplicit,disentangledcontroloverboth recently,dualcontrollabilityhasbeenexploredinCtrl-X[42],but
structureandappearancein2Dstylization.Atitscore,DiffArtist itsframeworkisdesignedforlocalized,imageeditsratherthanthe
explicitlydisentanglesthestructuralandappearancegeneration global,harmoniousstyletransformations.Meanwhile,theconcept
asseparateddiffusionprocesses,withsharedsemanticinforma- ofdisentangledcontrolisexploredin3Dsynthesis,whereexplicit
tion.ThisdesigndirectlyovercomesthefundamentalS-Atradeoff representationsofshape(e.g.,meshes[45]andradiancefields[53])
andfunctionsasazero-shot,plug-and-playmoduleforanypre- andappearance(e.g.,texturemapping[5])makeseparationnatural.
trained U-Net-based DM, requiring no costly fine-tuning or ex- Thesuccessin3D,however,isnotdirectlytransferabletothe2D
ternaladapters [63, 66]. As evidencedin thispaper,this design domainduetothelackofexplicitgeometricpriorsinsingleimprovidestruedisentanglementâ€”akeyadvantageoverControlNet- ages.Inthispaper,weexplorethefirstdualcontrollable2Dimage
basedmethods[42,54]whereadjustingonestylefactoradversely stylizationmethod.
impactstheother.AsdemonstratedinFig.1,thisunprecedented Text-Driven Image Stylization. Text-driven image stylizalevelofcontrolallowsDiffArtisttoachievestrong,semantically tion aims to stylize a source image according to style prompts.
coherentstylization,unleashingthefullcreativepotentialofdual- Earlymethodsachieveitbyoptimizingcertainimagerepresenstylecustomization. tation[13,32,37,45,53]withamultimodalalignmentobjective,
Evaluatingthisnovelcapabilityofdualcontrolrequiresunder- typicallyimplementedastheCLIPloss[48].Recently,itwasdisstandingonimagesemantics,whereexistingevaluationmetrics coveredthattext-to-image(T2I)DMscouldalsobeadaptedfor
obsolete.Thisexposesacriticalneedforanewevaluationpara- similaroptimizationschemes[20,29,31,47].Theseoptimizationdigm.Toaddressthis,weintroduceoursecondmajorcontribution: basedmethodsarecostlyandslow,motivatingrecentexploration
aMultimodalLLM(MLLM)-basedevaluatordesignedfordual ofthefeed-forwardparadigm.Instruct-Pix2Pix[4]tunesthedifstylization.Wearguethatanysuchevaluatormustsatisfythree fusionmodelalongwithalanguagemodelforgeneralizedediting
keycriteria:(1)operateatahigh-levelsemanticplanetoassess tasks.Diffstyler[24]learnacontentandstyle-specificdenoiserfor
structure,(2)possesscontextualawarenesstomaintainsemantic disentanglement.FreeStyle[19]modulatestheU-Netfeaturefor
integrity, and (3) perform robust cross-modal association be- training-freestylization.Concurrentwiththisexplorationisthe
tweentextpromptsandvisualforms.Byleveragingthezero-shot stylizedimagegeneration[7,14,22,54,55].Whilerelated,theyforeasoningofMLLMs,ourproposedmetricmeetsthesecriteria.We cusonadifferentsettingwherethestyleisextractedfromanimage
empirically show that it aligns significantly better with human andthecontentisaprompt.Inthiswork,wefocusonthestructure
artisticjudgmentthanexistingstylizationmetrics[34,48,57],es- andappearancecontrolintext-drivenstylizationscenarios.
tablishingamorereliableandhuman-centricstandardforfuture QuantitativeEvaluationofStyleTransfer.Quantitatively
stylizationresearch. evaluating style transfer is a long-standing problem. Initial ap-
Wesummarizeourcontributionsasfollows: proachesrepurposedlow-levelmetrics,includingGramLoss[16],
LPIPS[67],andFID[23].However,recentliteraturefoundthatthese
metricsarefundamentallyincapableofcapturingtheholisticand
semanticqualitiesofhumanartisticperception[3,6,27,50,60,64].
(1) WeidentifytheS-Atradeoffindiffusionmodelsasthekey Inresponsetotheseshortcomings,art-specificevaluatorslikeArtchallengefordisentangleddualcontrollability. FID[60]andArtScore[6]weredevelopedtobetterquantifythe
(2) WeproposeDiffArtist,thefirst2Dstylizationmethodthat abstract concept of "artness". Nevertheless, they cannot handle
enablesthedualcontrollabilityofstructureandappearance. open-vocabularytext-drivenstylizationandlackthemechanismto

<!-- Page 3 -->

DiffArtist:TowardsStructureandAppearanceControllableImageStylization MMâ€™25,October27â€“31,2025,Dublin,Ireland
â€œCartoon doodle
style, bold linesâ€
inject

### Appearance

Style prompt ğ‘¦ Delegation ğœâˆ’1 steps skip hidden skip hidden
ğœ–~ğ’© ğŸ,ğˆ

### Appearance


### Sampled noise control Appearance

Reference Structure delegation Main branch
Structure Control

### Structure

Delegation ğœâˆ’1 steps

### Source image ğ±"

DDIM inversion Structure Structure SelfAttn S2A SelfAttn SelfAttn

### Reference inject AdaIN

control ğ‘„% ğ¾% ğ‘‰% ğ‘‰# ğ¾# ğ‘„# ğ¾$ ğ‘„$ ğ‘‰$

### Main Structure Appearance Main

Branch delegation delegation branch
ğœâˆ’1 steps Appearance Control
Noised image ğ±! Pretrained denoising U-Net(Shared Param) Controlled Stylizationğ¼!
Figure2:OverviewofDiffArtist.Ourmethoddisentanglesstylizationbyprocessingstructureandappearancethroughtwo
independentdiffusiontrajectories(delegations).Ateachdenoisingstep,themainstylizationbranchisconditionedonsemanticlevelfeaturesfromthestructureandappearancedelegations.AllthreebranchessharethesamepretrainedU-Netparameters,
andperformfulldenoisingofğœ steps.Theentireframeworkoperateswithoutrequiringanyfine-tuningoradapters.
evaluatestructureandappearanceseparately.Thispaperpropose astylepromptğ‘¦).Specifically,onemaystartwithanintermediate
asemantic-levelMLLM-basedevaluatortoassessthestructureand stepxğœ (i.e.,controlpoint),whereğœ âˆˆ [1,ğ‘‡] foriterativeDDIM
appearancefidelity,whichalignsbetterwithhumanperception. sampling.Eachdenoisingstepisformulatedasfollows:
3 Methodology âˆš
3.1 Objective:DisentangledDualControllability xğ‘¡âˆ’1 =
âˆš
ğ›¼ ğ‘¡âˆ’1
(cid:18) xğ‘¡ âˆ’ 1âˆ’
âˆš
ğ›¼
ğ›¼
ğ‘¡ ğœ– ğœƒ(xğ‘¡ ,ğ‘¡;ğ‘¦)(cid:19)
ğ‘¡
Givenasourceimageğ¼,atext-basedstylepromptğ‘¦,andapre-
+
âˆš
1âˆ’ğ›¼ ğ‘¡âˆ’1 ğœ– ğœƒ(xğ‘¡ ,ğ‘¡;ğ‘¦), (1)
traineddiffusionmodelG(Â·),ourprimaryobjectiveistogeneratea
stylizedimageğ¼Ë†thatpreservesthesemanticcontentofğ¼ whilehar- whereğœ– ğœƒ isthedenoiser,ğ‘¡ isthetimestep,andğ›¼ 1:ğ‘‡ isapredefined
moniouslyembodyingthestyledescribedbyğ‘¦.Thecoreinnovation
noiseschedule.Theassumptionofthisparadigmisthatwitha
wepursueisdisentangleddualcontrol,meaningthatdecompos- properğœ,theresultingstylizedimageğ¼Ë†:=xË†0harmoniouslyinteingthestylepromptğ‘¦intotwoorthogonalcomponentsâ€”structure
gratesthestructureandappearanceofstyleinpromptğ‘¦withthe
andappearanceâ€”andcontrollingtheirstrengthindependently.Our sourceimageğ¼.
definitionofstructureandappearanceina2Dimageismainly
basedonfineart[17].Aformaldefinitionofthemischallengingas
3.3 StructureandAppearanceinNoiseSpace
itrelatestovisualsemiotics[18,52],extendingbeyondthescopeof
thispaper.Generallyspeaking,structurecorrespondstotheshapes, Prevailingneuralstylizationmethodsarebuiltonaparadigmthat
likecontoursandcurvatures,whileappearancecorrespondstolocal separatesanimageintoâ€œcontentâ€andâ€œstyleâ€[12,25,36,39,49,58,
patterns,likestrokesandcolorpalettes.Wealsoaimtodevelop 68,69].Inthisview,thestyleusuallyreferstothefeaturemaps
anevaluatorE,whichcanevaluatethefidelityofstructureand extractedfromcertainlayersofaneuralnetwork.Toadvancestylappearancestyleinawayalignedwithhumanperception. izationtowardsbothstructureandappearancecontrollability,we
Theremainingpartsofthissectionareorganizedasfollows.In adoptdifferentmodelingthatdecomposesanimageasitsstructure
Sec.3.2,wereviewthebasicsofinversion-basedimagemanipula- andappearancecomponent ğ‘  s:x0 = ğ‘ G 0 (z ğ‘  0 ,z ğ‘ 0 ),where G 0 = (Â·,Â·)
tion.InSec.3.3,3.4,weexplainthemotivationanddesignofcontrol isacompositionfunction,z 0 andz 0 arethelatentstructureand
atahighlevel,anddetailsaredescribedinSec.3.5.Sec.3.6outlines appearancefactorization,respectively.Thisisaâ€œstaticâ€,image-level
theproposedMLLM-basedstructureandappearanceevaluators. perspective.Inthediffusionprocess,thedistributionofimageğ‘¥ 0is
tiedwiththeintermediatedistributionsinx1:ğ‘‡,wherethedenoiser
3.2 Preliminary:DDIMInversion
ğœ–
ğœƒ
learnsthetransitionğ‘ ğœƒ(ğ‘¥
ğ‘¡âˆ’1
|ğ‘¥
ğ‘¡
,ğ‘¦)viağœ–-prediction.Therefore,
wepositsimilarfactorizationofpredictednoiseresidual,whichis
Tostylizeasourceimagex0:=ğ¼ usingDMs,inversion-basedmethaâ€œdynamicâ€decompositionacrossthefullfrequencybands:
odsfirstapproximatethenoiselatentsx1:ğ‘‡ ofğ¼,achievedviatechniquessuchasDDIMinversion[51].Stylizationisthenperformed
throughre-generationwithalteredconditions(usuallyspecifiedas ğœ– ğœƒ(xğ‘¡ ,ğ‘¡;ğ‘¦)=Gğ‘¡ (ğœ… ğ‘¡ ,ğœ“ ğ‘¡), ğ‘¡ âˆˆ [0,ğ‘‡] (2)

<!-- Page 4 -->

MMâ€™25,October27â€“31,2025,Dublin,Ireland RuixiangJiangandChangWenChen
whereğœ… ğ‘¡andğœ“ ğ‘¡denotethestructureandappearancerepresentation 0.8T 0.6T 0.4T 0.2T
atdiffusiontime-stepğ‘¡ (detailedlater),respectively. Gğ‘¡(Â·,Â·) isa
conceptualnoise-spacecompositionfunctionattimeğ‘¡.
3.4 StructureandAppearanceasDelegate

### DiffusionProcess

We argue that the fundamental obstacle to achieving dual controlindiffusion-basedstylizationistheinherententanglementof
structureandappearance.Ouranalysis,detailedinAppendixD,
pinpointsthesourceofthisproblem:therelianceonasinglelatenttrajectoryxğœâ†’âˆ’ x0.Thismonolithicgenerationprocessforces
structuralandappearanceattributestocompeteforinfluenceat
everydenoisingstep,creatingtheS-Atradeoffthatfundamentally
limitscontrollability.

### Tobreakthisbottleneck,weproposeanovelmechanismthat

stylizesanimagewithseparatediffusiontrajectories,asillustrated
inFig.2.Specifically,weleveragetwosupplementarydiffusion
processeswithsharedinformation,calleddelegatebranches.We
initializethestructureandmainbranchfromtheinvertednoisexğ‘‡,
whileappearancedelegationstartsfromaGaussianğœ– âˆ¼ N(0,I).
Thesedelegationsenablecontrollingthestylizationovertheentire
diffusionprocess.Thecontrolledmainbranchcanbedenotedas:
ğœ– ğœƒ ğ‘š (xğ‘¡ ,ğ‘¡;ğ‘¦,ğœ… ğ‘¡ ğ‘ ,ğœ“ ğ‘¡ ğ‘ )=Gğ‘¡ (cid:0)ğœ… ğ‘¡ ğ‘  â—¦ğœ… ğ‘¡ ğ‘š,ğœ“ ğ‘¡ ğ‘ â‹„ğœ“ ğ‘¡ ğ‘š(cid:1), ğ‘¡ âˆˆ [0,ğ‘‡] (3)
wherethesuperscriptsğ‘ ,ğ‘,andğ‘šdenotethefactorizationextracted
fromthestructure,appearancedelegation,andmainbranch,respectively.Theâ—¦andâ‹„aretwonon-commutativecontroloperators.
3.5 StructureandAppearanceRepresentations
inDenoisingU-Net
HavingestablishedthecontrolmechanisminEq.3,wenowformulatetheğœ… andğœ“ inaU-Net-baseddenoiserfordisentangling
structureandappearancecontrol.
PyramidalStructureRepresentationğœ….Toeffectivelycontrol structural stylization, we require a representation that capturesimagesemanticsatmultiplelevelsofabstraction.Weidentify the hidden features in the ResBlock of denoising U-Net as the
idealsubstrateforthispurpose,whichrobustlyencodeappearanceinvariantimagesemanticsacrossvaryingğ‘¡ (seeFig.3).Formally,
wedenotethehiddenfeatureofaResBlockasâ„ ğ‘–(xğ‘¡),whereğ‘– âˆˆ
{1,2,...,ğ‘ ğ‘Ÿğ‘’ğ‘ }indexestheResBlocksuptoğ‘ ğ‘Ÿğ‘’ğ‘ ,withincreasing
spatialresolution.Stackingsuchfeaturefromalllayersformsa
pyramidalstructurerepresentationofx0atğ‘¡:
ğœ… ğ‘¡ ğ‘  :={â„ ğ‘–(xt )}ğ‘–âˆˆğ‘†ğ‘Ÿğ‘’ğ‘  ,
whereâ„ ğ‘– extractedfromğœ– ğœƒ ğ‘  (xğ‘¡ ,ğ‘¡;âˆ…), (4)
andğ‘† ğ‘Ÿğ‘’ğ‘  âŠ†{1,2,...,ğ‘ ğ‘Ÿğ‘’ğ‘ }.
Ourrepresentationisdistinctasitcapturesmulti-scalesemanticsandprovidescontinuousguidanceacrossthefulldenoising
trajectory(ğ‘¡ âˆˆ [0,ğ‘‡]).Thisfundamentallydiffersfrommethods
relyingonsolitarycontrolpoints(e.g.,xğœ)orsingle-scaleconditions
(e.g.,ControlNet,IP-Adapter).Suchapproachesareconstrainedto
afixedresolutionand/orSNR,whicharchitecturallylimitstheir
abilitytogeneratecomplexstructuralstyles.AsevidencedinSec.5,
thisconstraintoftenleadstoundesirablesemantictrade-offs.With
desioN
egami
tnetnoc
)ğ‘¥(â„
)ğ‘¥(ğ‘“
Figure3:ResBlockfeaturemapvisualization.Weapplyt-sne
tovisualizethefeaturemapofdifferentfeaturemapsinU-
Netdecoder.Thehiddenfeaturesâ„(x)betterpreservesthe
semanticsthantheResNetfeatureğ‘“(x)throughoutallğ‘‡.
thispyramidalrepresentation,weimplementthestructurecontrol
operatorâ—¦asinjection(i.e.,ğ‘â—¦ğ‘ =ğ‘).
Semantic-awareAppearanceRepresentationğœ“.Werepresenttheappearanceofthetargetstyleasself-attentionmapsex- tractedfromalllayersofğœ–ğ‘ 
.Forthestyletobeappliedharmoniously,
ğœƒ
itsgenerationmustbeguidedbytheimageâ€™ssemantics.However,
untilnow,wedenoiseappearancedelegationfromGaussiannoise
andhencehasnoinformation-sharingwiththesourceimage.To
compensateforthis,weproposeStructure-to-Appearanceinjection(S2A)thatpropagatesthehigh-levelsemanticsintoappearancegeneration.Specifically,weinjecttheself-attentionvalueğ‘‰
fromearlylayersofğœ– ğœƒ ğ‘  toğœ– ğœƒ ğ‘ .Letğ‘ ğ‘ğ‘¡ğ‘¡ğ‘› denotethetotalnumberof
attentionblockswithintheU-Netdecoder,ğ‘† ğ‘ 2ğ‘ âŠ†{1,2,...,ğ‘ ğ‘ğ‘¡ğ‘¡ğ‘›}
betheselectedblocksforS2Ainjection.Theappearancerepresentationatğ‘¡ is:
ğœ“ ğ‘¡ ğ‘ :={ğ´ ğ‘– ğ‘ } ğ‘– ğ‘ = ğ‘ 1 ğ‘¡ğ‘¡ğ‘›, whereğ´ ğ‘– ğ‘ isextractedfromğœ– ğœƒ ğ‘(cid:16) xğ‘¡ ,ğ‘¡;ğ‘¦,{ğ‘‰ ğ‘— ğ‘  }ğ‘—âˆˆğ‘†ğ‘ 2ğ‘ (cid:17) ,
with{ğ‘‰
ğ‘—
ğ‘  }ğ‘—âˆˆğ‘†ğ‘ 2ğ‘ extractedfromğœ–
ğœƒ
ğ‘  (xğ‘¡ ,ğ‘¡;âˆ…).
(5)
InspiredbyStyleAligned[22]wedesigntheappearance-style
controloperatorâ‹„astheAdaIN[25],
(cid:18)ğ‘âˆ’ğœ‡(ğ‘)(cid:19)
ğ‘â‹„ğ‘ =ğœ(ğ‘) +ğœ‡(ğ‘). (6)
ğœ(ğ‘)
WevisualizethefeatureinteractionsintherightpartofFig.2.
Adjustingthecontrollayerinğ‘† ğ‘Ÿğ‘’ğ‘  andstylestrengthofğœ– ğ‘¡ ğ‘ enables
disentangledcontrolforstructureandappearance,respectively.
3.6 StructureandAppearanceEvaluationvia

### MLLMs

Recentresearchdemonstratesthepowerfulsemantic-levelmultimodalunderstandingofMLLMs[35,38,40,65,70].Weleverage
state-of-the-artMLLMsasazero-shotevaluatortoassesstwokey
axesofourmethod:structurepreservationandappearancefidelity.

<!-- Page 5 -->

DiffArtist:TowardsStructureandAppearanceControllableImageStylization MMâ€™25,October27â€“31,2025,Dublin,Ireland
â€œ8-Bit
Pixel-art,
detailedâ€
â€œRococo
paintingâ€
Content Image StylePrompt Ours DDIM Prompt2Prompt Plug-and-play ControlNet InstructPix2Pix DiffStyler
sdohteM
nevirD-txeT
)a
sdohtem
desab-ecnerefeR
)b
CLIPStyler
â€œVincent
van gogh,
Egon schiele
â€
â€œCubism
painting,
fragmented,
Picasso
â€
Content Image StylePrompt Ours SD AdaIN ArtFlow StyTr2 StyleID StyleAligned InstantStyle
Figure4:Qualitativecomparisonwithexistingmethods.Wecompareourworkwithrepresentativetext-drivenimagemanipulationmethodin(a),andimage-basedstylizationmethodsin(b).StylizedimagesgeneratedbyDiffArtistproducehigh-fidelity
structuralandappearance-levelstylewithsemanticintegrity.WesuggestreadersformorevisualizationsinAppendixA.
Crucially,ourgoalistomeasurefidelityofstylizedimages,not tuning.However,itshouldbenotedthatuserscanadjustthese
subjectivequalitieslikevisualappeal.1. parametersforcustomization.
Giventheinherentsubjectivityandthedifficultyofassigning ComparedMethods.Wecompareourmethodagainstexistabsolutescores,wedesignarelativeevaluationframework.Specif- ingtext-drivenstylizationandmanipulationmethods:DDIMInically, we query MLLM with the tuple (IË†,ğ¼,ğ‘¦,ğ‘¦ ğ‘–), where IË† = version[51],CLIPStyler(optimization-based)[37],DiffStyler[24],

## {ğ¼Ë†

1
,...,ğ¼Ë† ğ‘˜}isthestylizationresultgeneratedbyğ‘˜differentmodels, Plug-and-Play (PnP), Prompt2Prompt (with null text inversion)
ğ¼ â‰”x0isthesourceimage,andğ‘¦ ğ‘– istheinstructiondedicatedfor (P2P)[21,46],ControlNet[66],andInstructPix2Pix[4].Additionstructureorappearancefidelityevaluation.TheMLLMistasked ally,weconsiderabaselinenamedSD,whichgeneratesimages
withrankingtheoutputsofğ‘˜differentmethodsforeachcriteria. withStableDiffusionaccordingtoğ‘¦.
WeshowinSec.5.2thatthisdesignachievessuperioralignment Wealsoindirectlycompareourmethodwithreference-based
withhumanperceptioncomparedwithexistingmetrics. stylizationmethods,includingAdaIN[25],ArtFlow[1],StyTr2[11],
StyleID[8],StyleAligned[22](withControlNet),andInstantStyle[54]
4 Experiments (withControlNet).ImagesgeneratedbySDareusedasreference.
ConventionalMetrics:LPIPS[67]measuresthecontentpreser-
4.1 ExperimentSetup
vationbycalculatingthefeaturedistancebetweenthesourceand
ImplementationDetails. Ourexperimentsarebuiltuponthe stylizedimage.Forstylefidelity,weleverageCLIPScore[48]and
publiclyavailableStableDiffusion2.1model2.WeperformDDIM

### PickScore[34],bothofwhichquantifythealignmentbetween

samplingwithğ‘‡ =50steps.Duringtheinversion,werecordthe thestylizedimageğ¼Ë†andpromptğ‘¦.Wealsoincludeahumanstudy
intermediatenoisepredictionstooverwritetheinputofğœ– ğœƒ ğ‘  during crowd-sourcedfromğ‘› 1 =200usersandreporttheaveragepreferdenoising.FurtherimplementationdetailsareavailableinAppenencerateforourmethod.
dixB.ExperimentswereconductedwithasingleRTX4090-DGPU, MLLM-basedMetrics:WeprompttheMLLMtorankthefiwith an approximate runtime of 2 seconds for inversion and 8 delityofğ‘˜stylizedimagesfrombest(rank1)toworst(rankğ‘˜).We
secondsforthefinalstylization.
normalizetheintegerrankingandaverageitoverthewholeevalu-

### DefaultParameters.Inmainexperiment,wedefaultğ‘† restobe

ationset.Therefore,ascorecloserto1indicatesastrongerfidelity.
thefirstfourResNetlayers([1, 2, 3, 4]),andğ‘† s2aasthefirsttwo WeuseGemini-v2.0-flashforitsstrongmultimodalcapability.
attentionlayerfeatures([1, 2]).Theclassifier-freeguidance(CFG)
ThefullprompttemplatescanbefoundinAppendixC.
scaleissetas7.5.Thesedefaultcontrolparameterscorrespondto
moderatestructuralandappearancevariations,usedtosetafair
comparison with existing works to avoid per-image parameter 4.2 Comparisons
1Notethatvisual-appealisalsonotequivalenttoaestheticquality[17,28] QualitativeComparisons.Wefirstprovideacomprehensivecom-
2https://huggingface.co/stabilityai/stable-diffusion-2-1 parisonagainstpreviousmethods,visualizedinFig.4-(a,b).(a):

<!-- Page 6 -->

MMâ€™25,October27â€“31,2025,Dublin,Ireland RuixiangJiangandChangWenChen
Table1:Quantitativecomparisonagainstexistingmethods.Weshowconventional(ingrayfont)andMLLM-basedmetricsfor
representativemethods.Foreachmetric, indicatesthebestscore, indicatesthesecondbestscore,and indicatesthe
thirdbestscore(bestviewedincolor).Winratemeansthepercentagethatourmethodwinsinpair-wisecomparison.
Metric Ours DDIM SD PnP P2P InstructP2P ControlNet InstantStyle DiffStyler CLIPStyler
Inferencetime(sec) 10.5 9.7 3.9 55.3 29.1 9.2 7.8 7.8 18.2 24.2

### Training&adapterfree âœ“ âœ“ âœ“ âœ“ âœ— âœ— âœ— âœ— âœ— âœ—


### Lpipsâ†“ 0.52 0.57 0.76 0.67 0.47 0.42 0.65 0.59 0.71 0.46

CLIPScore[48]â†‘ 25.91 25.25 27.46 24.89 23.48 21.94 24.93 22.85 25.79 27.14
PickScore[34]â†‘ 20.51 20.58 20.68 20.34 20.50 20.06 20.46 19.97 19.24 20.13
Structure(MLLM)â†‘ 0.61 0.22 0.29 0.52 0.65 0.60 0.58 0.56 0.35 0.51
Appearance(MLLM)â†‘ 0.67 0.46 0.31 0.60 0.47 0.59 0.55 0.67 0.30 0.59
Avg.(MLLM)â†‘ 0.64 0.34 0.30 0.56 0.56 0.60 0.57 0.62 0.33 0.55
StructureWin(Human)â†‘ - 78.2% 62.4% 64.7% 57.3% 62.2% 71.2% 59.8% 81.3% 73.0%
AppearanceWin(Human)â†‘ - 74.2% 86.4% 62.0% 73.7% 68.7% 75.0% 60.1% 85.3% 76.3%
Comparedwithtext-drivenmethods,DiffArtististhebestatfol- 5 AnalysisandDiscussion
lowingthestylepromptwhilemaintainingsemanticintegrity.Our This section provide in-depth analysis on the proposed system.
methodenablesharmoniousstructuralvariations,suchaspixela- InSec.5.1,weanalyzethecontrollabilityofDiffArtistindetail.
tion,withoutcompromisingintricatedetailslikefacialidentityand Sec.5.2validatestheeffectivenessofMLLMsasstyleevaluators.
hair.Bycontrast,thecomparedmethodsmayproducemisaligned Sec.5.3providesablationsondelegationsandtheS2Ainjection.
styles(e.g.,CLIPStyler,Plug-and-Play)orintroduceundesiredmod- WeconcludewithadiscussioninSec.5.4.
ificationsthatviolatesemantics(e.g.,DiffStyler,ControlNet).(b):
Whenbroadlycomparedwithreference-basedmethods,DiffArtist 5.1 DiffArtisthasStrongControllability
stillstandsoutforitshighstylizationfidelityfromtwoperspectives.
Thissubsectionvalidatestheunprecedenteddualcontrollabilityof

### Tofullydemonstratethesuperiority,wehighlysuggestreaders

DiffArtist.Toachievethis,weconductafine-grainedcomparative
foradditionalvisualizationsinAppendixA.
analysisagainstrepresentativemethods,categorizingthembytheir

### QuantitativeComparison.Forourquantitativeevaluation,we

corecontrolmechanism:(a)Semanticpyramid:includeDiffArtist,
firstsample50artstylesfromWikiART,withbothabstract(e.g.,

### DiffArtistimplementedwithPlug-and-Playstructurerepresenta-

â€œCubismâ€)andrealisticstyles(e.g.,â€œHighRenaissanceâ€),whichare
tion,ğ‘“(x)(Ours+PnP),andCtrl-X;(b)Pixel-levelmap:include
furtherdiversifiedbyGPT-4ointermsofdescription.Thisdiversifi-
InstantStyle [10], which is based on ControlNet [66]; (c) Noise
cationsetsabroadspectrumofstylestoalignwithreal-worlduser
inversion,whichcorrespondstotheDDIMbaseline.Forstructure
inputs.Thecontentcomprises50imagesfromMSCOCO[43]and
control,wedefinefivelevelsfromweakesttostrongest.Forgroup(a)
50photorealisticimagesgeneratedbyanothermodel[26].Foreach
weusethefollowingcontrollayers:(âˆ…,[1],[1-4],[1-6],[1-8]);
ofthe100contentimages,werandomlydraw10stylepromptsfrom
allpossiblestyles,resultinginatotalof1,000uniquecombinations forgroup(b),weevenlysampletheirrespectivecontrolstrengthparameters;andweuseğœ = [0,5,10,15,20]forgroup(c).Appearance
forcomparison.Tab.1presentstheresults.
strengthiscontrolledbysamplingCFGweightsin[2.5,5,7.5,10]

### Forconventionalmetrics,DiffArtistachievesanLPIPSof0.52,a

forallgroupsexceptforCtrl-X,whichisachievedbyadjustingits
CLIPScoreof25.91,andaPickScoreof20.51,outperformingmost
appearancescheduleparameter.
ofthecomparedmethods.However,thesemetricsdonotmeasure

### QualitativeComparisononControl.AsvisualizedinFig.5,

stylizationqualityinstructureandappearance.Asasimplecounter-
DiffArtistdemonstratessuperiorcontrollability,withharmonious,
example,thebaselineSDhasthehighestCLIPScoreandPickScore,
consistent,anddisentangledinterpolationsacrossasequenceof
whereasitisnotevenperformingstylization.Weincludethese
controllevels.Itcorrectlycapturestheessentialgeometricprinciscoressolelyforreference.
plesofCubism,whereascompetingmethodsmerelyapplyasu-

### WhenevaluatedwithMLLM-basedmetrics,DiffArtistattainsthe

perficial texture (e.g., Ours+PnP) or fail to produce meaningful
highestaveragescoreof0.64.Specifically,ourmethodachievesthe
structuralvariations(e.g.,InstantStyle).Thisnuancedcontrolisfursecond-higheststructurescoreof0.61,demonstratingDiffArtistâ€™s
therevidentwhenadjustingstylestrength;DiffArtistprovidesan
effectiveness in generating structural styles. While the editingartisticallymeaningfulinterpretationbyproducingbolderstrokes
focusedP2Pmethodscoreshigher,itdoessobysacrificingstylistic
accordingtostyleprompt,whileothermethodsresorttosimplistic
strength,evidencedinqualitativecomparisons.Besides,ourmethod
andoftenundesirableincreasesincolorsaturation.Mostcritically,
achievesthebestappearancefidelityscore,confirmingitssuperior
ourapproachpreservessemanticintegrity.Itavoidsthecatastrophic
abilitytorendertheappearancedetailsfromthetextprompt.In
failuresofpixel-mapmethodslikeInstantStyle,whichcanrender
humanevaluations,ourmethodispreferredbyanaverageof67.8%
thefaceunrecognizable,andalsopreventsthefacialstructurecorofusersinpairwisecomparison,furthervalidatingitssuperiority.
ruptionseenininversion-basedmethodsthatinherentlyentangle
formwithappearance.TheextendedvisualizationsinAppendixA

<!-- Page 7 -->

DiffArtist:TowardsStructureandAppearanceControllableImageStylization MMâ€™25,October27â€“31,2025,Dublin,Ireland
sruO
PnP+sruO
X-lrtC

## Midd

Content Content
& Style & Style
Fauvism

### Cubism

painting,
painting,
bold brush
detailed
strokes
elytStnatsnI

### Structural Style Strength Appearance Style Strength

Figure5:DiffArtistoffersdisentangledandstrongercontrollability.(Left):DiffArtistenablessmoothandartisticallymeaningful
structuralstylizationatvaryingdegree,withoutviolatingappearancestylestrength.(Right):DiffArtistallowsfine-grained
controlofappearance-relatedstylestrengthwhilepreservingstructuralandsemanticintegrity.
withdiversestyleandcontentfurtherconfirmthesuperiorityof Table2:Fidelityofstructureandappearancecontrolviacross-
DiffArtist. methodcomparison.Thevaluescorrespondtothestructure
QuantitativeComparisonsonControl.Weprovidequantita- orappearancescore(MLLM,â†‘).Notethatthemagnitudesof
tiveexperimentstosubstantiateourvisualobservations,evaluat- scoresareonlycomparablewithineachcolumn.Thebest
ingcontrolbasedontwoproperties:fidelityandeditability.We resultforeachcolumnisinbold.
measurethefidelityasstructureandappearanceMLLMscoresat
differentcontrollevels.TheresultsarereportedinTab.2.DiffArtist â€”Structureâ†’ â€”Appearanceâ†’

### Method

outperformsotherssignificantlyandconsistently,demonstrating lv.1 lv.2 lv.3 lv.4 lv.5 lv.1 lv.2 lv.3 lv.4
superiorcontrolfidelity.

### Ours 0.62 0.65 0.74 0.63 0.66 0.70 0.74 0.80 0.78

The editability defines the quality of the manipulation itself, Ours+PnP 0.43 0.38 0.28 0.42 0.34 0.21 0.26 0.27 0.32
whichweassessviathreecriteria:range,monotonicity,anddis- Ctrl-X 0.49 0.46 0.36 0.46 0.47 0.41 0.37 0.33 0.42
entanglement.Anidealcontrolofstylizationshouldcoverawide InstantStyle 0.42 0.42 0.33 0.43 0.35 0.34 0.34 0.35 0.60

### Ddim 0.49 0.52 0.52 0.51 0.55 0.59 0.53 0.50 0.52

rangeofstylisticeffects(alargespreadinMLLMscores),exhibitpredictablemonotonicity(Spearmanâ€™sğœŒ â‰ˆ1forthetargetattribute),
andmaintaindisentanglementfromotherattributes.Wemeasure
thedisentanglementusingKendallâ€™sğ‘Š ontheoff-targetscores, fromhumanfeedback.Toachievethis,wefirstconstructacomwhereastable,unaffectedscoresequenceyieldsğ‘Š â‰ˆ 0.Forinparisonsetof800stylizedimages3,andcomparehowhumanand
stance,whencontrollingstructuralstrength,ğ‘Š fortheappearance MLLMpreferencescorrelate.
Togatherhumanfeedback,weconsidertwogroupsofusers.For
scoreisdesiredtobenear0.AsshowninTab.2,thecontrolof
DiffArtististhemosteditable:itcoversthebroadestrangeofefthenon-expertgroup,werecruitedalarge-scalegroupofğ‘›
1
=200
participantsthroughacrowdsourcingplatform.Eachparticipant
fects,demonstratesthestrongestmonotonicity,andachievesthe
performedaseriesofrandomlysampledrankingtasks.Toensure
bestdisentanglement,reaffirmingthesuperiorcontrolvisualized
theintegrityofthecollecteddata,weimplementedattentionchecks
inFig.5.
andconsistencyfilterstoremoveunreliableresponses.Wealso
recruitedanexpertgroupofğ‘›
2
=12participantswithknowledge
offineart.
5.2 MLLMsareHuman-AlignedStylization We measured the alignment between each metricâ€™s rankings
Evaluators andthehuman-derivedpreferencesusingSpearmanâ€™srankcorrelation(ğœŒ).Theaveraged(ofallcontent-stylepairs)ğœŒ forboth
Weevaluatehoweachstylizationmetricalignswithhumanfeedbackbycalculatingthestatisticalcorrelationwiththerankings 3TheimagesevaluatedheredonotoverlapwiththemainexperimentinTab.1

<!-- Page 8 -->

MMâ€™25,October27â€“31,2025,Dublin,Ireland RuixiangJiangandChangWenChen
Table3:Controleditabilityanddisentanglementviainter-methodcomparison.HigherğœŒindicatesstrongermonotonicitywhile
lowerğ‘Š meansranksareindistinguishable.Whencontrollingfromoneperspective,ahighğœŒisdesiredforeditability,andalow
ğ‘Š fortheotheraspectisexpectedfordisentangledcontrol.ThecontrolsinDiffArtistarethemosteditableanddisentangled.
SequentialStructure-ControlOnly SequentialAppearance-ControlOnly
Ours Ours+PnP Ctrl-X InstantStyle DDIM Ours Ours+PnP Ctrl-X InstantStyle DDIM
ğœŒ(ğ‘†)â†‘ 0.82 0.54 0.32 0.39 0.70 ğ‘Š(ğ‘†)â†“ 0.37 0.32 0.36 0.45 0.69
ğ‘Š(ğ´)â†“ 0.32 0.44 0.45 0.34 0.72 ğœŒ(ğ´)â†‘ 0.71 0.42 0.35 0.26 0.68
Table4:Metricscorrelationwithhumanfeedback.Wereport
correlationğœŒandcombinedsignificanceğ‘.TheMLLMscores
showstrongeralignmentwithbothexpertandnon-expert
users.
Corr.(Non-expert) Corr.(Expert)
Metrics ğœŒâ†‘ p-valueâ†“ ğœŒâ†‘ p-valueâ†“

## Ssim[57] 0.29 0.12 0.25 0.14

S MLLM(GPT-4o) 0.44 0.004 0.34 0.20
MLLM(Gemini2.0) 0.42 0.02 0.45 0.03

### CLIPScore 0.05 0.73 0.01 0.75

PickScore[34] 0.27 0.11 0.25 0.13

## A


### MLLM(GPT-4o) 0.25 0.05 0.22 0.06


### MLLM(Gemini2.0) 0.48 0.04 0.41 0.02

Table5:Ablationondelegationbranches.Theproposedtwo
delegationsarecomplementarytoeachother,andthefull
methodsachievesthehighestfidelity.

### Method

full w/ostructure w/oappearance

### Metric


## Lpipsâ†“ 0.51 0.76 0.42


### CLIPScoreâ†‘ 25.91 27.69 21.75

PickScore[34]â†‘ 20.55 20.57 20.41

### Structure(MLLM)â†‘ 0.72 0.37 0.33


### Appearance(MLLM)â†‘ 0.62 0.59 0.22

groupsisreportedinTab.4.Asthetableshows,theMLLM-based
metricsarebetteralignedwithhumanperception,validating
itseffectivenessasanevaluationmetricforstyletransfer.
5.3 Ablations
Thedelegationsenabledualcontrollability.DiffArtistâ€™scontrollabilitystemsfromdelegatingstructureandappearancegeneration
to separate processes. To test the necessity of each, we created
twoablatedvariantsforcomparisonwherethestructureorappearancedelegationisremoved.Tab.5presentstheresultofthis
ablation.Thefullmethodsachievesthebestresults,demonstrating
thesynergisticeffectofdelegationsfordualcontrollability.

### S2Ainjectionpromotessemantic-alignedspatialdistribution

ofstylestrengthinthestyledelegationprocess,therebyavoiding
artifactsinthefinalstylizationresult.Wevisualizethedenoised
styleimage(fromappearancedelegation)andthefinalstylization

## )A2S

o/w(
sruO
)lluF(
sruO
Content Appearance Stylization Content Appearance Stylization
& Style Delegation Result & Style Delegation) Result
Cartoon An 8-Bit
painting
pixel art,
using detailed
markers
Figure 6: Ablation on S2A injection. S2A injection propagatesthehigh-levelsemantictotheappearancegeneration.
Itavoidsspatialmisalignmentofappearance-stylestrength.
resultinFig.6.WithoutS2Ainjection,theappearancedelegation
failstoalignwithcontentsemantics,generatinganappearance
referenceimagewithundesiredpatternsandanuneventexture
distribution.Theseflawsmanifestdirectlyinthefinaloutputas
distractingvisualartifacts.Incontrast,thefullmodelleveragesS2A
toproduceacoherentstylerepresentation,resultinginacleanand
high-qualityfinalimage.
5.4 Limitations&Futurework
While DiffArtist marks a significant step towards disentangled
structureandappearancecontrol,weidentifyseverallimitations
thatopenexcitingavenuesforfutureresearch.Forinstance,the
structurecontrolinDiffArtistisatagloballevel,anditcannot
controlthestructureforeachobjectseparately.Manyartstyles
exhibitmixedstructurevariation,likeSurrealismandCollageart.
Developingdensestructureevaluatorswith2Dfeedbacksignals
isapromisingdirection[41],whichmaybefurtherutilizedasa
rewardmodelforreinforcementlearning[2,9].
6 Conclusion
We present the first exploration of structure- and appearancecontrollableimagestylization.OurcontributionsincludeDiffArtist,
astylerthatfullydisentanglesstructureandappearanceduringthe
diffusionprocess,andahuman-alignedevaluatortoassessstructuralandappearancefidelityatthesemanticlevel.Ourextensive
analysisprovesthatsemantically-richrepresentationsareessential
forbothstructureandappearancestyle.Wedemonstratedthatour
designallowsforhighstylefidelityandcontrollability,similarto
thatofahumanartist.Webelievetheobjectiveestablishedinthis
paperâ€”tostylizeinbothstructureandappearanceâ€”offeraroadmap
forthenextgenerationofgenerativearttoolstoproduceartistically
meaningfulpaintings.

<!-- Page 9 -->

DiffArtist:TowardsStructureandAppearanceControllableImageStylization MMâ€™25,October27â€“31,2025,Dublin,Ireland
7 Acknowledgment
text-drivenimagestylization.IEEETransactionsonNeuralNetworksandLearning
Systems(2024).

### ThisresearchwassupportedbytheHongKongResearchGrants

[25] XunHuangandSergeBelongie.2017. Arbitrarystyletransferinreal-time
Council(GRF-15229423). withadaptiveinstancenormalization.InProceedingsoftheIEEEinternational
conferenceoncomputervision.1501â€“1510.
References [26] Ideogram.2024. Ideogram:Explore. https://ideogram.ai/t/explore Accessed:
2024-03-20.
[1] JieAn,SiyuHuang,YibingSong,DejingDou,WeiLiu,andJieboLuo.2021. [27] EleftheriosIoannouandSteveMaddock.2024.EvaluationinNeuralStyleTransfer:
Artflow:Unbiasedimagestyletransferviareversibleneuralflows.InProceedings AReview.InComputerGraphicsForum.WileyOnlineLibrary,e15165.
oftheIEEE/CVFconferenceoncomputervisionandpatternrecognition.862â€“871. [28] RuixiangJiangandChangwenChen.2025.MultimodalLLMsCanReasonabout
[2] Kevin Black, Michael Janner, Yilun Du, Ilya Kostrikov, and Sergey Levine. AestheticsinZero-Shot.arXivpreprintarXiv:2501.09012(2025).

## Trainingdiffusionmodelswithreinforcementlearning. arXivpreprint [29] RuixiangJiang,CanWang,JingboZhang,MengleiChai,MingmingHe,Dongdong

arXiv:2305.13301(2023). Chen,andJingLiao.2023. Avatarcraft:Transformingtextintoneuralhuman
[3] YihangBo,JinhuiYu,andKangZhang.2018. Computationalaestheticsand avatarswithparameterizedshapeandposecontrol.InProceedingsoftheIEEE/CVF
applications.Visualcomputingforindustry,biomedicine,andart1(2018),1â€“19. InternationalConferenceonComputerVision.14371â€“14382.
[4] TimBrooks,AleksanderHolynski,andAlexeiAEfros.2023. Instructpix2pix: [30] HyunyoungJung,SeonghyeonNam,NikolaosSarafianos,SungjooYoo,Alexander
Learningtofollowimageeditinginstructions.InProceedingsoftheIEEE/CVF Sorkine-Hornung,andRakeshRanjan.2024. Geometrytransferforstylizing
ConferenceonComputerVisionandPatternRecognition.18392â€“18402. radiancefields.InproceedingsoftheIEEE/CVFConferenceonComputerVisionand
[5] Dave Zhenyu Chen, Yawar Siddiqui, Hsin-Ying Lee, Sergey Tulyakov, and PatternRecognition.8565â€“8575.
MatthiasNieÃŸner.2023. Text2tex:Text-driventexturesynthesisviadiffusion [31] BahjatKawar,ShiranZada,OranLang,OmerTov,HuiwenChang,TaliDekel,
models.InProceedingsoftheIEEE/CVFinternationalconferenceoncomputervision. InbarMosseri,andMichalIrani.2023.Imagic:Text-basedrealimageeditingwith
18558â€“18568. diffusionmodels.InProceedingsoftheIEEE/CVFConferenceonComputerVision
[6] JunyuChen,JieAn,HanjiaLyu,ChristopherKanan,andJieboLuo.2024.Learning andPatternRecognition.6007â€“6017.
toEvaluatetheArtnessofAI-generatedImages.IEEETransactionsonMultimedia [32] GwanghyunKim,TaesungKwon,andJongChulYe.2022.Diffusionclip:Text-
(2024). guideddiffusionmodelsforrobustimagemanipulation.InProceedingsofthe
[7] JingwenChen,YingweiPan,TingYao,andTaoMei.2023.Controlstyle:Text- IEEE/CVFconferenceoncomputervisionandpatternrecognition.2426â€“2435.
drivenstylizedimagegenerationusingdiffusionpriors.InProceedingsofthe31st [33] SunnieSYKim,NicholasKolkin,JasonSalavon,andGregoryShakhnarovich.
ACMInternationalConferenceonMultimedia.7540â€“7548. 2020. Deformablestyletransfer.InEuropeanConferenceonComputerVision.
[8] JiwooChung,SangeekHyun,andJae-PilHeo.2024.Styleinjectionindiffusion: Springer,246â€“261.
Atraining-freeapproachforadaptinglarge-scalediffusionmodelsforstyle [34] YuvalKirstain,AdamPolyak,UrielSinger,ShahbulandMatiana,JoePenna,and
transfer.InProceedingsoftheIEEE/CVFConferenceonComputerVisionandPattern OmerLevy.2023. Pick-a-pic:Anopendatasetofuserpreferencesfortext-to-
Recognition.8795â€“8805. imagegeneration.AdvancesinNeuralInformationProcessingSystems36(2023),
[9] KevinClark,PaulVicol,KevinSwersky,andDavidJFleet.2023.Directlyfine- 36652â€“36663.
tuningdiffusionmodelsondifferentiablerewards.arXivpreprintarXiv:2309.17400 [35] TakeshiKojima,ShixiangShaneGu,MachelReid,YutakaMatsuo,andYusuke
(2023). Iwasawa.2022. Largelanguagemodelsarezero-shotreasoners. Advancesin
[10] XingCui,ZekunLi,PeiPeiLi,HuaiboHuang,andZhaofengHe.2023.InstaStyle: neuralinformationprocessingsystems35(2022),22199â€“22213.
InversionNoiseofaStylizedImageisSecretlyaStyleAdviser.arXivpreprint [36] DmytroKotovenko,ArtsiomSanakoyeu,SabineLang,andBjornOmmer.2019.
arXiv:2311.15040(2023). Contentandstyledisentanglementforartisticstyletransfer.InProceedingsof
[11] YingyingDeng,FanTang,WeimingDong,ChongyangMa,XingjiaPan,LeiWang, theIEEE/CVFinternationalconferenceoncomputervision.4422â€“4431.
andChangshengXu.2022. Stytr2:Imagestyletransferwithtransformers.In [37] GihyunKwonandJongChulYe.2022. Clipstyler:Imagestyletransferwitha
ProceedingsoftheIEEE/CVFconferenceoncomputervisionandpatternrecognition. singletextcondition.InProceedingsoftheIEEE/CVFConferenceonComputer
11326â€“11336. VisionandPatternRecognition.18062â€“18071.
[12] GuanchenDing,LingboLiu,ZhenzhongChen,andChangwenChen.2024. [38] YanshuLi,HongyangHe,YiCao,QisenCheng,XiangFu,andRuixiangTang.
Domain-agnosticcrowdcountingviauncertainty-guidedstylediversityaugmen- 2025.M2iv:Towardsefficientandfine-grainedmultimodalin-contextlearning
tation.InProceedingsofthe32ndACMInternationalConferenceonMultimedia. inlargevision-languagemodels.arXivpreprintarXiv:2504.04633(2025).
1642â€“1651. [39] YanghaoLi,NaiyanWang,JiayingLiu,andXiaodiHou.2017. Demystifying
[13] RinonGal,OrPatashnik,HaggaiMaron,AmitHBermano,GalChechik,and neuralstyletransfer.arXivpreprintarXiv:1701.01036(2017).
DanielCohen-Or.2022.Stylegan-nada:Clip-guideddomainadaptationofimage [40] YanshuLi,TianYun,JianjiangYang,PinyuanFeng,JinfaHuang,andRuixiang
generators.ACMTransactionsonGraphics(TOG)41,4(2022),1â€“13. Tang.2025.TACO:EnhancingMultimodalIn-contextLearningviaTaskMapping-
[14] JunyaoGao,YanchenLiu,YananSun,YinhaoTang,YanhongZeng,KaiChen, GuidedSequenceConfiguration.arXivpreprintarXiv:2505.17098(2025).
andCairongZhao.2024. Styleshot:Asnapshotonanystyle. arXivpreprint [41] YouweiLiang,JunfengHe,GangLi,PeizhaoLi,ArseniyKlimovskiy,Nicholas
arXiv:2407.01414(2024). Carolan,JiaoSun,JordiPont-Tuset,SarahYoung,FengYang,etal.2024.Rich
[15] LeonAGatys,AlexanderSEcker,andMatthiasBethge.2015.Aneuralalgorithm humanfeedbackfortext-to-imagegeneration.InProceedingsoftheIEEE/CVF
ofartisticstyle.arXivpreprintarXiv:1508.06576(2015). ConferenceonComputerVisionandPatternRecognition.19401â€“19411.
[16] LeonAGatys,AlexanderSEcker,andMatthiasBethge.2016.Imagestyletransfer [42] KuanHengLin,SichengMo,BenKlingher,FangzhouMu,andBoleiZhou.2024.
usingconvolutionalneuralnetworks.InProceedingsoftheIEEEconferenceon Ctrl-x:Controllingstructureandappearancefortext-to-imagegenerationwithcomputervisionandpatternrecognition.2414â€“2423. outguidance. AdvancesinNeuralInformationProcessingSystems37(2024),
[17] ErnstHansGombrichandEHGombrich.1995.Thestoryofart.Vol.12.Phaidon 128911â€“128939.
London. [43] Tsung-YiLin,MichaelMaire,SergeBelongie,JamesHays,PietroPerona,Deva
[18] NelsonGoodman.1976. Languagesofart:Anapproachtoatheoryofsymbols. Ramanan,PiotrDollÃ¡r,andCLawrenceZitnick.2014.Microsoftcoco:Common
Hackett. objectsincontext.InComputervisionâ€“ECCV2014:13thEuropeanconference,
[19] FeihongHe,GangLi,MengyuanZhang,LeileiYan,LingyuSi,FanzhangLi,and zurich,Switzerland,September6-12,2014,proceedings,partv13.Springer,740â€“
LiShen.2024.Freestyle:Freelunchfortext-guidedstyletransferusingdiffusion 755.
models.arXivpreprintarXiv:2401.15636(2024). [44] YuemingLyu,YueJiang,BoPeng,andJingDong.2023. InfoStyler:Disentan-
[20] AmirHertz,KfirAberman,andDanielCohen-Or.2023.Deltadenoisingscore.In glementinformationbottleneckforartisticstyletransfer.IEEETransactionson
ProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision.2328â€“ CircuitsandSystemsforVideoTechnology34,4(2023),2070â€“2082.
2337. [45] OscarMichel,RoiBar-On,RichardLiu,SagieBenaim,andRanaHanocka.2022.
[21] AmirHertz,RonMokady,JayTenenbaum,KfirAberman,YaelPritch,andDaniel Text2mesh:Text-drivenneuralstylizationformeshes.InProceedingsofthe
Cohen-Or.2022.Prompt-to-promptimageeditingwithcrossattentioncontrol. IEEE/CVFConferenceonComputerVisionandPatternRecognition.13492â€“13502.
arXivpreprintarXiv:2208.01626(2022). [46] RonMokady,AmirHertz,KfirAberman,YaelPritch,andDanielCohen-Or.2023.
[22] AmirHertz,AndreyVoynov,ShlomiFruchter,andDanielCohen-Or.2024.Style Null-textinversionforeditingrealimagesusingguideddiffusionmodels.In
alignedimagegenerationviasharedattention.InProceedingsoftheIEEE/CVF ProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition.
ConferenceonComputerVisionandPatternRecognition.4775â€“4785. 6038â€“6047.
[23] MartinHeusel,HubertRamsauer,ThomasUnterthiner,BernhardNessler,and [47] BenPoole,AjayJain,JonathanTBarron,andBenMildenhall.2022.Dreamfusion:
SeppHochreiter.2017.Ganstrainedbyatwotime-scaleupdateruleconvergeto Text-to-3dusing2ddiffusion.arXivpreprintarXiv:2209.14988(2022).
alocalnashequilibrium.Advancesinneuralinformationprocessingsystems30 [48] AlecRadford,JongWookKim,ChrisHallacy,AdityaRamesh,GabrielGoh,
(2017). SandhiniAgarwal,GirishSastry,AmandaAskell,PamelaMishkin,JackClark,
[24] NishaHuang,YuxinZhang,FanTang,ChongyangMa,HaibinHuang,Weiming
Dong,andChangshengXu.2024. Diffstyler:Controllabledualdiffusionfor

<!-- Page 10 -->

MMâ€™25,October27â€“31,2025,Dublin,Ireland RuixiangJiangandChangWenChen
etal.2021.Learningtransferablevisualmodelsfromnaturallanguagesupervision. [61] JinchaoYang,FeiGuo,ShuoChen,JunLi,andJianYang.2022.Industrialstyle
InInternationalconferenceonmachinelearning.PMLR,8748â€“8763. transferwithlarge-scalegeometricwarpingandcontentpreservation.InPro-
[49] ArtsiomSanakoyeu,DmytroKotovenko,SabineLang,andBjornOmmer.2018. ceedingsoftheIEEE/CVFconferenceoncomputervisionandpatternrecognition.
Astyle-awarecontentlossforreal-timehdstyletransfer.Inproceedingsofthe 7834â€“7843.
Europeanconferenceoncomputervision(ECCV).698â€“714. [62] SerinYang,HyunminHwang,andJongChulYe.2023. Zero-shotcontrastive
[50] ChaehanSo.2023.Measuringaestheticpreferencesofneuralstyletransfer:More lossfortext-guideddiffusionimagestyletransfer.InProceedingsoftheIEEE/CVF
precisionwiththetwo-alternative-forced-choicetask.InternationalJournalof InternationalConferenceonComputerVision.22873â€“22882.
Humanâ€“ComputerInteraction39,4(2023),755â€“775. [63] HuYe,JunZhang,SiboLiu,XiaoHan,andWeiYang.2023. Ip-adapter:Text
[51] JiamingSong,ChenlinMeng,andStefanoErmon.2020. Denoisingdiffusion compatibleimagepromptadapterfortext-to-imagediffusionmodels. arXiv
implicitmodels.arXivpreprintarXiv:2010.02502(2020). preprintarXiv:2308.06721(2023).
[52] TheoVanLeeuwenandCareyJewitt.2000.Thehandbookofvisualanalysis.Sage. [64] RanYi,HaoyuanTian,ZhihaoGu,Yu-KunLai,andPaulLRosin.2023.Towards
[53] CanWang,RuixiangJiang,MengleiChai,MingmingHe,DongdongChen,and artisticimageaestheticsassessment:alarge-scaledatasetandanewmethod.In
JingLiao.2023. Nerf-art:Text-drivenneuralradiancefieldsstylization. IEEE ProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition.
TransactionsonVisualizationandComputerGraphics(2023). 22388â€“22397.
[54] HaofanWang,QixunWang,XuBai,ZekuiQin,andAnthonyChen.2024. In- [65] DuzhenZhang,YahanYu,JiahuaDong,ChenxingLi,DanSu,ChenhuiChu,and
stantstyle:Freelunchtowardsstyle-preservingintext-to-imagegeneration.arXiv DongYu.2024.Mm-llms:Recentadvancesinmultimodallargelanguagemodels.
preprintarXiv:2404.02733(2024). arXivpreprintarXiv:2401.13601(2024).
[55] HaofanWang,PengXing,RenyuanHuang,HaoAi,QixunWang,andXuBai. [66] LvminZhang,AnyiRao,andManeeshAgrawala.2023.Addingconditionalcon-

## Instantstyle-plus:Styletransferwithcontent-preservingintext-to-image troltotext-to-imagediffusionmodels.InProceedingsoftheIEEE/CVFInternational

generation.arXivpreprintarXiv:2407.00788(2024). ConferenceonComputerVision.3836â€“3847.
[56] XinhaoWang,WenjingWang,ShuaiYang,andJiayingLiu.2022.CLAST:Con- [67] RichardZhang,PhillipIsola,AlexeiAEfros,EliShechtman,andOliverWang.
trastivelearningforarbitrarystyletransfer.IEEETransactionsonImageProcessing 2018. Theunreasonableeffectivenessofdeepfeaturesasaperceptualmetric.
31(2022),6761â€“6772. InProceedingsoftheIEEEconferenceoncomputervisionandpatternrecognition.
[57] ZhouWang,AlanCBovik,HamidRSheikh,andEeroPSimoncelli.2004.Image 586â€“595.
qualityassessment:fromerrorvisibilitytostructuralsimilarity.IEEEtransactions [68] YuxinZhang,FanTang,WeimingDong,HaibinHuang,ChongyangMa,Tong-Yee
onimageprocessing13,4(2004),600â€“612. Lee,andChangshengXu.2023.Aunifiedarbitrarystyletransferframeworkvia
[58] ZhizhongWang,LeiZhao,andWeiXing.2023. Stylediffusion:Controllable adaptivecontrastivelearning.ACMTransactionsonGraphics42,5(2023),1â€“16.
disentangledstyletransferviadiffusionmodels.InProceedingsoftheIEEE/CVF [69] YexunZhang,YaZhang,andWenbinCai.2020.Aunifiedframeworkforgener-
InternationalConferenceonComputerVision.7677â€“7689. alizablestyletransfer:Styleandcontentseparation.IEEETransactionsonImage
[59] LinfengWen,ChengyingGao,andChangqingZou.2023.CAP-VSTNet:Content Processing29(2020),4085â€“4098.
affinitypreservedversatilestyletransfer.InProceedingsoftheIEEE/CVFconference [70] ZhuoshengZhang,AstonZhang,MuLi,HaiZhao,GeorgeKarypis,andAlex
oncomputervisionandpatternrecognition.18300â€“18309. Smola.2023.Multimodalchain-of-thoughtreasoninginlanguagemodels.arXiv
[60] MatthiasWrightandBjÃ¶rnOmmer.2022.Artfid:Quantitativeevaluationofneural preprintarXiv:2302.00923(2023).
styletransfer.InDAGMGermanConferenceonPatternRecognition.Springer,560â€“ [71] YangZhou,ZichongChen,andHuiHuang.2024. Deformableone-shotface
576. stylizationviadinosemanticguidance.InProceedingsoftheIEEE/CVFConference
onComputerVisionandPatternRecognition.7787â€“7796.

<!-- Page 11 -->

DiffArtist:TowardsStructureandAppearanceControllableImageStylization MMâ€™25,October27â€“31,2025,Dublin,Ireland
Figure9:Exampleoffailurecases.
StructuralVariation(experiment)

### Style Variation (experiment)

Structural Variation (Simulation)

### Style Variation (Simulation)


### Figure7:TradeoffbetweenStructureandAppearanceStyle

Control.Wepresenttheexperimental(solidlines)andsimulation(dottedlines)trendsofstructuralandappearance
variationinthediffusionprocess.Duetoquadraticgrowth,
highly noisy steps are required to achieve strong appearancestyles,whichareassociatedwithsignificantstructural
variation,whichcanviolatesemantics.Top:Examplestylizationresultsstartingfromdifferentsteps,usingtheprompt:
â€œFauvismpaintingâ€.Whentheappearancestrengthishigh
(ğ‘¡ =0.8ğ‘‡),thestructure(legsofthehorse)isincorrectlymodified.

### Sunflower by

Vincent van Gogh
egamitnetnoC
tpmorp
elytS
noisuffiDelbatS
dnuorgyalP

### AppendixA AdditionalQualitativeResults

VisualizationAdditionalappearancestylizationisinFig.10,the
sourceimageisinFig.11.Agridofdifferentimageswithdifferent
stylesisinFig.12.AdditionalstructurecontrolisinFig.13and
Fig.14.

### Additionalqualitativecomparisonsonstylization.Weshow

anextendedcomparisonwiththepreviousreference-basedmethod
inFig.15.Morequalitativecomparisonswithexistingtext-driven
imagestylizationandmanipulationmethodscanbefoundinFig.16
andFig.17.
Additionalcomparisonsonfine-grainedcontrol.WeprovideadditionalcomparisonswithothercontrolmethodsinFig.18
andFig.19.TheseresultsdemonstratetheadvantageofDiffArtist
inprovidingdisentangledstructuralandappearance-levelstylecontrol.Inparticular,theCtrl-X,asanimageeditingmethod,produces
lessvisuallypleasingresultswhenappliedtoimagestylization.
Thisisbecausetheyhaveadifferentdefinitionofappearanceand
structureforeditingrealphotos.
AppendixB OntheStructureandAppearance
EntanglementinDiffusionProcess

### B.1 Theoreticalanalysis


### Wenowexplorehowthefactorizationofstructureandappearance

factorization,definedinEq.2,interactandevolvethroughoutthe
denoisingtrajectoryğ‘ ğœƒ(x0 ,x1 ,...,xğ‘‡âˆ’1 ,|xğ‘‡).Specifically,suppose
thecontentimageğ¼ ğ‘ isinvertedintox1:ğ‘‡,inversion-basedstylizationstartsfromanintermediatestepxğœ ,ğœ <ğ‘‡ forDDIMdenoising
process.ByrearrangingEqn.1,weobtain:
âˆš ğ›¼
xğ‘¡âˆ’1 =Ağ‘¡xğ‘¡ +Bğ‘¡ ğœ– ğœƒ(xğ‘¡ ,ğ‘¡;ğ‘¦), Ağ‘¡ := âˆš
ğ›¼
ğ‘¡âˆ’1
ğ‘¡
(7)
Bğ‘¡ :=
âˆš
1âˆ’ğ›¼ ğ‘¡âˆ’1 âˆ’
âˆšï¸ğ›¼ ğ‘¡âˆ’1
âˆš
(1
ğ›¼
âˆ’ğ›¼ ğ‘¡âˆ’1 )
ğ‘¡
Basedonaboveformulation,thefullstylizationprocesscould
beexpressedas:
ğ‘‡ ğ‘‡ ï£® ğ‘˜âˆ’1 ï£¹ xË†0 = (cid:214) Ağ‘— Â·xğ‘‡ + âˆ‘ï¸ ï£¯ ï£¯Bğ‘˜ (cid:214) Ağ‘— ï£º ï£º ğœ–â€²(xğ‘˜âˆ’1 ,ğ‘˜)
ï£¯ ï£º
ğ‘—=1 ğ‘˜=ğœ+1ï£¯ ğ‘—=ğœ+1 ï£º
(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)ï£°(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)ï£»(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)
(cid:124) (cid:123)(cid:122) (cid:125)
A fauvism A traditional Post- Socialist preserveoriginalstructureandappearance (8)
painting, watercolor impressionist realism ğœ ï£® ğ‘˜âˆ’1 ï£¹
d s co t e r l t o o a r k i s l e e s d , v b i r v u i s d h p co a l i o n r t f i u n l g, p P a a i u n l t C in ez g a , n by n e. p d a et i a n i t l i e n d g, + ğ‘˜ âˆ‘ï¸ =1 ï£¯ ï£¯ ï£¯ ï£¯ Bğ‘˜ (cid:214) ğ‘—=1 Ağ‘— ï£º ï£º ï£º ï£º ğœ– ğœƒ(xğ‘˜âˆ’1 ,ğ‘˜;ğ‘¦),
(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)ï£°(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) ï£»(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)
(cid:124) (cid:123)(cid:122) (cid:125)
generatenewstructureandappearance
whereğœ–â€²denotesanidealdenoiserthatperfectlymodelsthetransitiondistributionğ‘(xğ‘¡âˆ’1 |xğ‘¡).InEq.8,theconceptualdenoising
termfromxğ‘‡ toxğœ preservesthestructureandappearanceinğ¼ ğ‘.
Thestylizationtrajectoryfromxğœtoxğ‘¡iswhatisactuallycomputed,
whichintroducesthedesiredappearancebasedonthepromptğ‘¦but
Figure 8: DiffArtist implemented with different diffusion
architecture.WeimplementDiffArtistontheplayground-v2
diffusionmodel.Similarstylizationresultscouldbeachieved,
demonstratingthegeneralizabilityofproposedmethod.

<!-- Page 12 -->

MMâ€™25,October27â€“31,2025,Dublin,Ireland RuixiangJiangandChangWenChen
Figure10:AdditionresultsforDiffArtist(withdefaultcontrolparameters).Theimagesemanticsarepreservedwithstrongand
high-fidelitystylesharmoniouslyintegrated.

<!-- Page 13 -->

DiffArtist:TowardsStructureandAppearanceControllableImageStylization MMâ€™25,October27â€“31,2025,Dublin,Ireland
Figure11:ThecorrespondingsourceimagesofFigure10.

<!-- Page 14 -->

MMâ€™25,October27â€“31,2025,Dublin,Ireland RuixiangJiangandChangWenChen
â€œPencil sketch, â€œCyberpunk â€œStarry-night â€œFuturism â€œNeo- â€œCubism
detailed cross- style concept â€œAmerican comic, style painting, â€œPainting by painting, expressionism painting,
Content image hatchingâ€ art, detailedâ€ western styleâ€ by van Goghâ€ Edvard Munchâ€ detailedâ€ painting â€ detailed
Figure12:Agridexperimentwithdifferentcontentandstyles.
mayalsoleadtouncontrolledstructuregeneration.Inthisparadigm, unweighteddenoisingstepğœ–(xğ‘¡ ,ğ‘¡;ğ‘¦) onthefinalstylizedimage
preservingoriginalappearanceandgeneratingnewstructureare remainsconsistentacrossdifferenttimestepsforbothstructureand
undesirablesideeffects.Intuitively,alargerğœ leadstoashortertra- appearance.Inotherwords,weassumetheSNRofstructureand
jectoryofxğ‘‡ â†’xğœ,resultinginastrongerappearanceinxË†0with appearancehasalinearrelationshipwiththatofthexğ‘¡ attimeğ‘¡ as
weakerstructurepreservation(uncontrolledstructurestylization), characterizedbythenoisescheduleğ›¼ 1:ğ‘‡:
w
pr
h
e
i
s
le
er
a
v
l
a
o
t
w
io
e
n
r
.
ğœ
In
sa
o
c
t
r
h
ifi
e
c
r
e
w
s
o
st
r
y
d
l
s
iz
,
a
o
t
n
io
e
n
c
s
a
t
n
re
n
n
o
g
t
th
ar
fo
b
r
it
s
r
t
a
r
r
o
i
n
ly
ge
c
r
on
st
t
r
r
u
o
c
l
t
t
u
h
r
e
e SNR(z ğ‘ ğ‘¡)âˆ
1âˆ’
ğ›¼ ğ‘¡
ğ›¼ ğ‘¡
;SNR(z ğ‘  ğ‘¡)âˆ
1âˆ’
ğ›¼ ğ‘¡
ğ›¼ ğ‘¡
, (10)
strengthofappearanceandstructurewithoutaffectingtheother. Itisimportanttonotethatwedonotassumethattherelativepro-
BycombiningEqn.2andEqn.8,wecanquantitativelyassess portionsofstructureandappearanceareidenticalateachdenoising
thestrengthofcontentpreservationandstylizationinthediffusion step.
process under a particular noise scheduleğ›¼ 1:ğ‘‡. Specifically, we Withtheaboveassumption,theeffectofvaryingğœ onthestrucfurtherassumetheSNRofstructureandappearancehasalinear tureandappearanceofthefinalstylizedimagecouldbederived
relationshipwiththatofthexğ‘¡ forğ‘¡: inclosedform.Inpractice,weusethefollowingcodetocalculate
ğ›¼ ğ›¼
SNR(z ğ‘ ğ‘¡)âˆ
1âˆ’
ğ‘¡
ğ›¼ ğ‘¡
;SNR(z ğ‘  ğ‘¡)âˆ
1âˆ’
ğ‘¡
ğ›¼ ğ‘¡
(9) i
d
t
e
e
f
rat
c
i
u
v
m
e
_
ly
s
:
core(low_t, hi_t, alphas):
res = 0

### B.2 Simulation

for k in range(low_t + 1, hi_t):
Toderivethetheoreticaltrendsofstructureandappearancestrength for j in range(low_t + 1, k - 1):
res += A_t(j, alphas) * B_t(k, alphas)
duringthediffusionprocess,weintroduceanadditionalassumpreturn res
tion.Specifically,weassumethattherelativesignificanceofeach

<!-- Page 15 -->

DiffArtist:TowardsStructureandAppearanceControllableImageStylization MMâ€™25,October27â€“31,2025,Dublin,Ireland
Figure13:Additionalresultonstructurecontrol-1.
struct_scores = [] â€¢ "pointillismstyle"
appear_scores = [] â€¢ "artdecostyle"
â€¢ "impressionismstyle"
for tau in range(0, 50):
â€¢ "surrealismstyle"
crt_struct = cum_score(50 - tau, 50, sampled_alphas)
crt_appear = cum_score(0, tau, sampled_alphas) â€¢ "popartstyle"
struct.append(crt_struct) â€¢ "cubismstyle"
appear_scores.append(crt_appear) â€¢ "abstractexpressionismstyle"
TheresultsforbothsimulationandempiricalresultsareinFig.7.

### B.3 EmpiricalResult

The result shows a good fit, and it turns out that the structure
DuetotheinherentinaccuracyofDDIMinversion,theestimation modification appears to be linear, with the stylization strength
ofxğœmaybeimperfect,resultinginunintendedmodificationsinthe being quadratic with respect toğœ. Moreover, this result further
finalsampledimageevenifnostylepromptğ‘¦isused.Toaddress evidencedtheissueofS-Aentanglementinthediffusionprocess.
thisissue,weadoptanalternativestrategybyrandomlysampling
500Gaussiannoiseasthexğ‘‡ ofcontent,whicharepairedwith AppendixC DetailsonMLLM-basedmetrics
500contentprompts.Wetreattheimagesdenoisedusingcontent C.1 ImplementationDetails
promptsforğœ =ğ‘‡ stepsasthecontentimage,whichsimulatesa
Thestylizedimages,styleprompt,andtheinstructionpromptsare
perfectinversiontechnique.Tostylizeanimage,wefirstdenoise
thexğ‘‡ withthecontentpromptforğœ steps,whichissubsequently fedtoMLLMforinference.Wecomposestylizedimagesasagrid
denoisedwiththestylepromptforğ‘‡ âˆ’ğœ steps.TheLPIPSbetween imagewithnumbersatthetop-leftcorner.Thefullprompttemplate
forstructureandappearancescoreisavailableinTab.6.
thestylizedimageandthecontentimageisusedastheempirical
structuralstrength.Incontrast,theCLIPDeceptionscore(correct

### C.2 CorrelationwithHumanPreference

classificationrateamongasetofstyles)isusedastheempirical
appearancestrength.Thefollowing10stylepromptsareused: HumanQuestionCollectionWedistributedthequestionnaireon
acrowd-sourcingplatform,whereeachparticipantwasrequiredto
â€¢ "watercolorstyle"
completeupto20randomlysampledrankingtasks.Anexampleof
â€¢ "fauvismstyle"
theuserinterfaceisprovidedinFig.20.Atotalof200participants
â€¢ "pencilsketchstyle"
took part in this study. To ensure the validity of the responses,

<!-- Page 16 -->

MMâ€™25,October27â€“31,2025,Dublin,Ireland RuixiangJiangandChangWenChen
Figure14:Additionalresultonstructurecontrol-2.
weincludedattention-checkquestions.Ifaparticipantanswersan AppendixD AdditionalDiscussionand
attention-checkquestionincorrectly,alloftheirresponseswillbe Analysis
markedinvalid.Responsesthataremadewithlessthan20seconds
D.1 GeneralizabilityofDiffArtist
arealsoremoved.
TodemonstratethegeneralizabilityofDiffArtistacrossdifferent

### U-Net-baseddiffusionarchitectures,weimplementourmethodon

Playgroundv24,whichutilizestheSDXLarchitecture,distinctfrom

### StableDiffusion2.1.SeveralresultsareprovidedinFig.8.These

4https://huggingface.co/playgroundai/playground-v2-1024px-aesthetic

<!-- Page 17 -->

DiffArtist:TowardsStructureandAppearanceControllableImageStylization MMâ€™25,October27â€“31,2025,Dublin,Ireland

### By pascal

campion and

### Rembrandt,

pastel colors,
Futurism
painting
Manga
comic
illustration
artwork by
Nicholas

### Roerich

Content imageStyleprompt Ours SD (reference) AdaIN ArtFlow StyTr2 StyleID StyleAligned InstantStyle
Figure15:Extendedcomparisonwithreference-basedstyletransfermethods.
resultsvalidatethatDiffArtistservesasaversatilecontrolmethod low-frequencystylefeaturessuchastonesandsmallobjects,while
applicabletovariousU-Net-baseddiffusionmodels,regardlessof addingmorelayersfacilitatesthecreationofhigh-frequencystyle
theirunderlyingarchitecturaldifferences. detailslikestrokeshapes.Empirically,wesettheS2Ainjection
layersto[1, 2]bydefault,asusingadditionallayerstypically
D.2 AdditionalAblationsonS2AInjection resultsinblurrinessinthestylizedoutputs.
Inthissection,weprovideadditionalablationstostudytheeffect

### D.3 FailureCase

ofproposedS2Adesign.
AblationonS2Alayersğ‘† ğ‘†2ğ´.Weablatethenumberofinjection Inourexperiment,weidentifyarare(<1%)andspecialfailurecase
layerusedintheS2Ainjection(i.e.,ğ‘† ğ‘†2ğ´).AsillustratedinFig.21, intheproposedmethods.Specifically,forcertaincontentimage,
theS2Alayersinfluencethefrequencybandsofstyledelegation. its stylization result will consistently contains black and white
Incorporatingonlyearlylayers(e.g.,[1, 2])focusesongenerating chessboard-patternartifacts.WeprovideoneexampleinFig.9.

<!-- Page 18 -->

MMâ€™25,October27â€“31,2025,Dublin,Ireland RuixiangJiangandChangWenChen
Postimpressionist,
van Gogh

### Ink-wash

gradient,
traditional
Regency era
painting,

### Thomas


### Gainsborough


### Art Brut style

Content image Styleprompt Ours DDIM Prompt2Prompt Plug-and-play CLIPStyler ControlNet InstructPix2Pix DiffStyler
Figure16:Extendedcomparisonwithexistingtext-drivenstylizationandmanipulationmethods.

<!-- Page 19 -->

DiffArtist:TowardsStructureandAppearanceControllableImageStylization MMâ€™25,October27â€“31,2025,Dublin,Ireland

### Pixel-art,


### Retrospective

Minimalist art,
monochrome
Comic book,

### Retro vibe


### Neo-classical

Illustrative art,
retrospective
palette

### Magazine

vintage cover
illustration

### Gothic

intricate
patterns and
dark tones
Art Deco artwork
elegant,
streamlined lines,
with bold color
palette inspired by
Tamara de

### Lempicka

Content image Styleprompt Ours DDIM Prompt2Prompt Plug-and-play CLIPStyler ControlNet InstructPix2Pix DiffStyler
Figure17:Extendedcomparisonwithexistingtext-drivenstylizationandmanipulationmethods.

<!-- Page 20 -->

MMâ€™25,October27â€“31,2025,Dublin,Ireland RuixiangJiangandChangWenChen
sruO
PnP+sruO

### X-lrtC

relytsffiD
Content Content
& Style & Style
Traditional

### Chinese

landscape
painting
elytStnatsnI
Structural Style Strength Appearance Style Strength
sruO
PnP+sruO

### X-lrtC

elytStnatsnI
relytsffiD
Still-Life
painting,
Cezanne
Starry

### Rococo

Nightstyle,
painting
van Gogh
Figure18:Extendedcomparisononfine-grainedstructuralandappearance-basedstylecontrol

<!-- Page 21 -->

DiffArtist:TowardsStructureandAppearanceControllableImageStylization MMâ€™25,October27â€“31,2025,Dublin,Ireland
sruO
PnP+sruO

### X-lrtC

relytsffiD
Content Content
& Style & Style

### Cartoon

painting
using
markers.
Art Deco,
Geometric
design
elytStnatsnI
Structural Style Strength Appearance Style Strength
Neoexpressionist
painting,
bold stokes

### Medieval

portrait, oil
on canvas
sruO
PnP+sruO

### X-lrtC

elytStnatsnI
relytsffiD
Figure19:Extendedcomparisononfine-grainedstructuralandappearance-basedstylecontrol

<!-- Page 22 -->

MMâ€™25,October27â€“31,2025,Dublin,Ireland RuixiangJiangandChangWenChen
Table6:PrompttemplatesforMLLM-basedmetrics.[IMG],[STYLE]and[NUM_METHOD]istheplaceholderforcombined
image,styleandnumberofmethods,respectively.

### StructureScore AppearanceScore

"[IMAGE] A content (source) image (top left) and "[IMAGE] A content (source) image (top left) and
[NUM_METHOD] stylized images in the style of [STYLE] [NUM_METHOD]stylizedimagesinthestyleof[STYLE]are
areplacedasagrid.""Thestylizedimagesareindexedfrom placedasagrid.""Thestylizedimagesareindexedfromleftto
left to right, and from top to bottom. " "Compare, analyze right,andfromtoptobottom.""Compare,analyzeanddiscrimand discriminately rank the fidelity to which the structure inatelyrankthefidelitytowhichtheappearancedescribedin
describedinthestyleof[STYLE]istransferredtothesource thestyleof[STYLE]istransferredandtothesourceimage."
image.""Youshouldfocusonthefidelityofstructure-related "Youshouldfocusonthefidelityofappearance-relatedartstyle
style component only, such as the lines, shapes, geometry, componentonly,suchasthetexture,color,stroke,andpattern.
layout, and perspective. You should not consider the style Notethatitdoesnotsimplymeanscolorpalletteandsaturation.
relatedtoappearance(e.g.,texture,color,stroke,andpattern). Youshouldnotconsiderthestylerelatedtostructure(e.g.,lines,
You should also consider how the structure of [STYLE] is shapes,geometry,layout,andperspective),unlesstheoriginal
integrated with the source image." "Stylized image that has scenebecomeunrecognizable.Youshouldalsoconsiderhow
(1) limited style strength, (2) structure that is mis-aligned theappearanceof[STYLE]isintegratedwiththesourceimage."
with the style, or (3) significant artifacts and distortions of "Stylizedimagethathas(1)limitedstylestrength,(2)visual
the semantic integrity (e.g., the original object and scene appearancethatismis-alignedwiththestyle,(3)significant
become unrecognizable) unless the distortion is explicitly artifacts and distortions of the semantic integrity (e.g., the
intended by the style of [STYLE], and (4) un-harmonious originalobjectandscenebecomeunrecognizable)unlessthe
integration with the source image should be considered of distortionisexplicitlyintendedbythestyleof[STYLE]and
in lower rank. In other words, if a stylized image is not an (4)un-harmoniousintegrationwiththesourceimageshould
artisticallymeaningfulpaintingofthesourceimageintarget beconsideredofinlowerrank.Inotherwords,ifastylized
style,thenitshouldberatedlower.Imagesthatharmoniously imageisnotanartisticallymeaningfulpaintingofthesource
integrate the structure of [STYLE] with the source image image in target style, then it should be rated lower. Images
shouldberatedhigher.""Rankthe[NUM_METHOD]images thatharmoniouslyintegratetexture,color,stroke,andpattern
in ascending order from 1 to [NUM_METHOD], where the shouldberatedhigher.""Rankthe[NUM_METHOD]images
highestrankof[NUM_METHOD]meansthebeststructural in ascending order from 1 to [NUM_METHOD], where the
fidelity.Noimagesshallhavethesameranking.""Asanexpert highestrankof[NUM_METHOD]meansthebestappearance
inart,returnyourthinkinginshort(whatstructureisdesired, fidelity.Noimagesshallhavethesameranking.""Asanexpert
and how the ranking is decided for each image in short), inart,returnyourthinking(whatappearanceisdesired,and
andranksforeachimageidinaPythonDict,[â€™thinkingâ€™:str, how the ranking is decided for each image in short), and
â€™rankâ€™:List[[NUM_METHOD]]]. Do not include any other ranks for each image id in a Python Dict, [â€™thinkingâ€™:str,
stringinyourresponse." â€™rankâ€™:List[[NUM_METHOD]]]. Do not include any other
stringinyourresponse."

<!-- Page 23 -->

DiffArtist:TowardsStructureandAppearanceControllableImageStylization MMâ€™25,October27â€“31,2025,Dublin,Ireland
Figure20:Exampleuserinterfaceincollectinghumanpreference.Thesystemwillpreventuserfromselectingthesame
ranking.

<!-- Page 24 -->

MMâ€™25,October27â€“31,2025,Dublin,Ireland RuixiangJiangandChangWenChen
[1] [1,2] [1,2,3,4] [1,2,3,4,5,6] [1,2,3,4,5,6,7,8]
noitageled
elytS
hcnarb
niaM
noitageled
elytS
hcnarb
niaM

### C2S layer

Traditional

### Chinese

painting
Pointillism
painting
Figure21:AblationStudyonS2ALayersğ‘† ğ‘†2ğ´.IncreasingthenumberofS2Alayerscompelstheappearancedelegationto
generatehigher-frequencystylefeatures(stokes,points)whilediminishinglow-frequencytonalcomponents(largecolor
fields).Empirically,ourdefaultconfiguration[1,2]strikesanoptimalbalancebetweenenhancingstyledetailandpreserving
essentialcontentstructure.

## Tables

**Table (Page 1):**

|  |  |  |
|---|---|---|
|  | Structure style strength |  |
|  |  |  |


**Table (Page 1):**

|  |  |
|---|---|
| htgnerts elyts ecnaraeppA |  |


**Table (Page 5):**

| â€œ8-Bit Pixel-art, detailedâ€ |
|---|
| â€œRococo paintingâ€ |


**Table (Page 5):**

| â€œVincent van gogh, Egon schiele â€ |
|---|
| â€œCubism painting, fragmented, Picasso |


**Table (Page 6):**

| 0.46 |
|---|
| 27.14 |


**Table (Page 6):**

| 25.91 |  | 27.46 |  |  |  |  |  |
|---|---|---|---|---|---|---|---|
| 20.51 | 20.58 | 20.68 |  |  |  |  |  |
| 0.61 | 0.22 0.29 0.52 0.65 0.60 0.46 0.31 0.60 0.47 0.59 0.34 0.30 0.56 0.56 0.60 |  |  | 0.65 | 0.60 |  |  |
| 0.67 |  |  | 0.60 |  | 0.59 |  | 0.67 |
| 0.64 |  |  |  |  |  | 0.57 | 0.62 |


**Table (Page 7):**

|  |  |  |
|---|---|---|
|  | Structural Style Strength |  |
|  |  |  |


**Table (Page 7):**

|  | Appearance Style Strength |
|---|---|
|  |  |


**Table (Page 8):**

| Content Appearance Stylization Content Appearance Stylization & Style Delegation Result & Style Delegation) Result )A2S o/w( sruO )lluF( Cartoon An 8-Bit painting pixel art, sruO using detailed markers |  |  |  |  |  |  |  |  |
|---|---|---|---|---|---|---|---|---|
|  |  |  |  |  |  |  |  |  |
|  |  |  |  |  |  |  |  |  |
|  | Cartoon painting using markers |  |  | An 8-Bit pixel art, detailed |  |  |  |  |


**Table (Page 8):**

| 0.29 0.12 0.44 0.004 0.42 0.02 |
|---|
| 0.05 0.73 0.27 0.11 0.25 0.05 0.48 0.04 |


**Table (Page 14):**

| â€œPencil sketch, â€œCyberpunk â€œStarry-night â€œFuturism â€œNeo- â€œCubism detailed cross- style concept â€œAmerican comic, style painting, â€œPainting by painting, expressionism painting, Content image hatchingâ€ art, detailedâ€ western styleâ€ by van Goghâ€ Edvard Munchâ€ detailedâ€ painting â€ detailed |
|---|
|  |
|  |
|  |
|  |
|  |
|  |


**Table (Page 14):**

| def cum_score(low_t, hi_t, alphas): |
|---|
| res = 0 |
| for k in range(low_t + 1, hi_t): |
| for j in range(low_t + 1, k - 1): |
| res += A_t(j, alphas) * B_t(k, alphas) |
| return res |
|  |


**Table (Page 15):**

| struct_scores = [] |
|---|
| appear_scores = [] |
|  |
| for tau in range(0, 50): |
| crt_struct = cum_score(50 - tau, 50, sampled_alphas) |
| crt_appear = cum_score(0, tau, sampled_alphas) |
| struct.append(crt_struct) |
| appear_scores.append(crt_appear) |


**Table (Page 18):**

|  |
|---|
| Post- impressionist, van Gogh |


**Table (Page 18):**

|  |  |
|---|---|
| Ink-wash gradient, traditional |  |


**Table (Page 18):**

|  |
|---|
| Regency era painting, Thomas Gainsborough |


**Table (Page 18):**

|  |  |
|---|---|
| Art Brut style |  |


**Table (Page 20):**

|  |  |
|---|---|
|  | Structural Style Strength |
|  |  |


**Table (Page 20):**

|  |  |
|---|---|
|  | Appearance Style Strength |
|  |  |


**Table (Page 21):**

|  |  |
|---|---|
|  | Structural Style Strength |
|  |  |


**Table (Page 21):**

|  |  |
|---|---|
|  | Appearance Style Strength |
|  |  |


**Table (Page 22):**

| StructureScore | AppearanceScore |
|---|---|
| "[IMAGE] A content (source) image (top left) and [NUM_METHOD] stylized images in the style of [STYLE] areplacedasagrid.""Thestylizedimagesareindexedfrom left to right, and from top to bottom. " "Compare, analyze and discriminately rank the fidelity to which the structure describedinthestyleof[STYLE]istransferredtothesource image.""Youshouldfocusonthefidelityofstructure-related style component only, such as the lines, shapes, geometry, layout, and perspective. You should not consider the style relatedtoappearance(e.g.,texture,color,stroke,andpattern). You should also consider how the structure of [STYLE] is integrated with the source image." "Stylized image that has (1) limited style strength, (2) structure that is mis-aligned with the style, or (3) significant artifacts and distortions of the semantic integrity (e.g., the original object and scene become unrecognizable) unless the distortion is explicitly intended by the style of [STYLE], and (4) un-harmonious integration with the source image should be considered of in lower rank. In other words, if a stylized image is not an artisticallymeaningfulpaintingofthesourceimageintarget style,thenitshouldberatedlower.Imagesthatharmoniously integrate the structure of [STYLE] with the source image shouldberatedhigher.""Rankthe[NUM_METHOD]images in ascending order from 1 to [NUM_METHOD], where the highestrankof[NUM_METHOD]meansthebeststructural fidelity.Noimagesshallhavethesameranking.""Asanexpert inart,returnyourthinkinginshort(whatstructureisdesired, and how the ranking is decided for each image in short), andranksforeachimageidinaPythonDict,[â€™thinkingâ€™:str, â€™rankâ€™:List[[NUM_METHOD]]]. Do not include any other stringinyourresponse." | "[IMAGE] A content (source) image (top left) and [NUM_METHOD]stylizedimagesinthestyleof[STYLE]are placedasagrid.""Thestylizedimagesareindexedfromleftto right,andfromtoptobottom.""Compare,analyzeanddiscrim- inatelyrankthefidelitytowhichtheappearancedescribedin thestyleof[STYLE]istransferredandtothesourceimage." "Youshouldfocusonthefidelityofappearance-relatedartstyle componentonly,suchasthetexture,color,stroke,andpattern. Notethatitdoesnotsimplymeanscolorpalletteandsaturation. Youshouldnotconsiderthestylerelatedtostructure(e.g.,lines, shapes,geometry,layout,andperspective),unlesstheoriginal scenebecomeunrecognizable.Youshouldalsoconsiderhow theappearanceof[STYLE]isintegratedwiththesourceimage." "Stylizedimagethathas(1)limitedstylestrength,(2)visual appearancethatismis-alignedwiththestyle,(3)significant artifacts and distortions of the semantic integrity (e.g., the originalobjectandscenebecomeunrecognizable)unlessthe distortionisexplicitlyintendedbythestyleof[STYLE]and (4)un-harmoniousintegrationwiththesourceimageshould beconsideredofinlowerrank.Inotherwords,ifastylized imageisnotanartisticallymeaningfulpaintingofthesource image in target style, then it should be rated lower. Images thatharmoniouslyintegratetexture,color,stroke,andpattern shouldberatedhigher.""Rankthe[NUM_METHOD]images in ascending order from 1 to [NUM_METHOD], where the highestrankof[NUM_METHOD]meansthebestappearance fidelity.Noimagesshallhavethesameranking.""Asanexpert inart,returnyourthinking(whatappearanceisdesired,and how the ranking is decided for each image in short), and ranks for each image id in a Python Dict, [â€™thinkingâ€™:str, â€™rankâ€™:List[[NUM_METHOD]]]. Do not include any other stringinyourresponse." |


**Table (Page 24):**

| [1] C2S layer noitageled Traditional Chinese painting elytS hcnarb niaM noitageled Pointillism painting elytS hcnarb niaM | [1,2] | [1,2,3,4] [1,2,3,4,5,6] [1,2,3,4,5,6,7,8] |
|---|---|---|
|  |  |  |
|  |  |  |
|  |  |  |
|  |  |  |
